<testsuite errors="0" failures="0" tests="7" skipped="0" name="org.elasticsearch.indices.settings.UpdateSettingsIT" hostname="nohost.nodomain" time="2.548" timestamp="2016-04-18T03:07:30">
   <properties class="java.util.ArrayList">
      <property name="awt.toolkit" value="sun.lwawt.macosx.LWCToolkit"/>
      <property name="es.logger.level" value="WARN"/>
      <property name="file.encoding" value="UTF-8"/>
      <property name="file.encoding.pkg" value="sun.io"/>
      <property name="file.separator" value="/"/>
      <property name="ftp.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16"/>
      <property name="gopherProxySet" value="false"/>
      <property name="http.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16"/>
      <property name="java.awt.graphicsenv" value="sun.awt.CGraphicsEnvironment"/>
      <property name="java.awt.headless" value="true"/>
      <property name="java.awt.printerjob" value="sun.lwawt.macosx.CPrinterJob"/>
      <property name="java.class.path" value="/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/classes/test:/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/resources/test:/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/classes/main:/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/resources/main:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-core/5.5.0-snapshot-1721183/f6854c65c7f4c6d9de583f4daa4fd3ae8a3800f1/lucene-core-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-analyzers-common/5.5.0-snapshot-1721183/69e187ef1d2d9c9570363eb4186821e0341df5b8/lucene-analyzers-common-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-backward-codecs/5.5.0-snapshot-1721183/fa00a45ff9bc6a4df44db81f2e4e44ea94bf88e/lucene-backward-codecs-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-grouping/5.5.0-snapshot-1721183/e996e6c723eb415ba2cfa7f5e98bbf194a4918dd/lucene-grouping-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-highlighter/5.5.0-snapshot-1721183/3b7a5d97b10885f16eb53deb15d64c942b9f9fdb/lucene-highlighter-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-join/5.5.0-snapshot-1721183/e4dda3eeb76e340aa4713a3b20d68c4a1504e505/lucene-join-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-memory/5.5.0-snapshot-1721183/800442a5d7612ce4c8748831871b4d436a50554e/lucene-memory-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-misc/5.5.0-snapshot-1721183/bdf184de9b5773c7af3ae908af78eeb1e512470c/lucene-misc-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queries/5.5.0-snapshot-1721183/fc59de52bd2c7e420edfd235723cb8b0dd44e92d/lucene-queries-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queryparser/5.5.0-snapshot-1721183/1d341e6a4f11f3170773ccffdbe6815b45967e3d/lucene-queryparser-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-sandbox/5.5.0-snapshot-1721183/a1b02c2b595ac92f45f0d2be03841a3a7fcae1f1/lucene-sandbox-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial/5.5.0-snapshot-1721183/e3ea422b56734329fb6974e9cf9f66478adb5793/lucene-spatial-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial3d/5.5.0-snapshot-1721183/5eadbd4e63120b59ab6445e39489205f98420471/lucene-spatial3d-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-suggest/5.5.0-snapshot-1721183/a336287e65d082535f02a8427666dbe46b1b9b74/lucene-suggest-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securesm/1.0/c0c6cf986ba0057390bfcc80c366a0e3157f944b/securesm-1.0.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.3.1/1303efbc4b181e5a58bf2e967dc156a3132b97c0/commons-cli-1.3.1.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.carrotsearch/hppc/0.7.1/8b5057f74ea378c0150a1860874a3ebdcb713767/hppc-0.7.1.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.8.2/d27c24204c5e507b16fec01006b3d0f1ec42aed4/joda-time-2.8.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.joda/joda-convert/1.2/35ec554f0cd00c956cc69051514d9488b1374dec/joda-convert-1.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.2/123f29333b2c6b3516b14252b6e93226bfcd6e37/jackson-core-2.6.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-smile/2.6.2/395d18c1a1dd730b8026ee59c4067e5d2b45ba6e/jackson-dataformat-smile-2.6.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-yaml/2.6.2/4ae23088dd3fae47c66843f2e4251d7255ee140e/jackson-dataformat-yaml-2.6.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-cbor/2.6.2/1e13c575f914c83761bb8e2aca7dfd9e4c647579/jackson-dataformat-cbor-2.6.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.10.5.Final/9ca7d55d246092bddd29b867706e2f6c7db701a0/netty-3.10.5.Final.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.tdunning/t-digest/3.0/84ccf145ac2215e6bfa63baa3101c0af41017cfc/t-digest-3.0.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.hdrhistogram/HdrHistogram/2.1.6/7495feb7f71ee124bd2a7e7d83590e296d71d80e/HdrHistogram-2.1.6.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.spatial4j/spatial4j/0.5/6e16edaf6b1ba76db7f08c2f3723fce3b358ecc3/spatial4j-0.5.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.vividsolutions/jts/1.13/3ccfb9b60f04d71add996a666ceb8902904fd805/jts-1.13.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/log4j/apache-log4j-extras/1.2.17/85863614d82185d7e51fe21c00aa9117a523a8b6/apache-log4j-extras-1.2.17.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.2/8619e95939167fb37245b5670135e4feb0ec7d50/slf4j-api-1.6.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/net.java.dev.jna/jna/4.1.0/1c12d070e602efd8021891cdd7fd18bc129372d4/jna-4.1.0.jar:/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/test/framework/build/libs/framework-3.0.0-SNAPSHOT.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/randomizedtesting-runner/2.3.2/307965917fe8a22b7ee72deba39ef4b8e6ebc069/randomizedtesting-runner-2.3.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-test-framework/5.5.0-snapshot-1721183/a8d851d0ad82182b3a02f4b30c336e7aa0e173cb/lucene-test-framework-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-codecs/5.5.0-snapshot-1721183/8aa59442b028c7a2c1a516accb6142a8910ba5fc/lucene-codecs-5.5.0-snapshot-1721183.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.3.6/4c47155e3e6c9a41a28db36680b828ced53b8af4/httpclient-4.3.6.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.3.3/f91b7a4aadc5cf486df6e4634748d7dd7a73f06d/httpcore-4.3.3.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.3/f6f66e966c70a83ffbdb6f17a0919eaf7c8aca7f/commons-logging-1.1.3.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.10/4b95f4897fa13f2cd904aee711aeafc0c5295cd8/commons-codec-1.10.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securemock/1.2/98201d4ad5ac93f6b415ae9172d52b5e7cda490e/securemock-1.2.jar:/Users/lwiskowski/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/junit4-ant/2.3.2/dc8f03f6111974092491f35b8269eb0fc57f52f7/junit4-ant-2.3.2.jar"/>
      <property name="java.class.version" value="52.0"/>
      <property name="java.endorsed.dirs" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/endorsed"/>
      <property name="java.ext.dirs" value="/Users/lwiskowski/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java"/>
      <property name="java.home" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre"/>
      <property name="java.io.tmpdir" value="./temp"/>
      <property name="java.library.path" value="/Users/lwiskowski/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:."/>
      <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
      <property name="java.runtime.version" value="1.8.0_71-b15"/>
      <property name="java.specification.name" value="Java Platform API Specification"/>
      <property name="java.specification.vendor" value="Oracle Corporation"/>
      <property name="java.specification.version" value="1.8"/>
      <property name="java.vendor" value="Oracle Corporation"/>
      <property name="java.vendor.url" value="http://java.oracle.com/"/>
      <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
      <property name="java.version" value="1.8.0_71"/>
      <property name="java.vm.info" value="mixed mode"/>
      <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
      <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
      <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
      <property name="java.vm.specification.version" value="1.8"/>
      <property name="java.vm.vendor" value="Oracle Corporation"/>
      <property name="java.vm.version" value="25.71-b15"/>
      <property name="junit4.childvm.count" value="4"/>
      <property name="junit4.childvm.cwd" value="/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1"/>
      <property name="junit4.childvm.id" value="1"/>
      <property name="junit4.memory.total" value="514850816"/>
      <property name="junit4.pidString" value="3682@host238-95.aruba.fit.edu"/>
      <property name="junit4.processors" value="8"/>
      <property name="line.separator" value="
"/>
      <property name="os.arch" value="x86_64"/>
      <property name="os.name" value="Mac OS X"/>
      <property name="os.version" value="10.11.4"/>
      <property name="path.separator" value=":"/>
      <property name="socksNonProxyHosts" value="local|*.local|169.254/16|*.169.254/16"/>
      <property name="sun.arch.data.model" value="64"/>
      <property name="sun.boot.class.path" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/classes"/>
      <property name="sun.boot.library.path" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre/lib"/>
      <property name="sun.cpu.endian" value="little"/>
      <property name="sun.cpu.isalist" value=""/>
      <property name="sun.io.unicode.encoding" value="UnicodeBig"/>
      <property name="sun.java.command" value="com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe -eventsfile /Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160418_030118_670.events @/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160418_030118_670.suites -stdin"/>
      <property name="sun.java.launcher" value="SUN_STANDARD"/>
      <property name="sun.jnu.encoding" value="UTF-8"/>
      <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
      <property name="sun.os.patch.level" value="unknown"/>
      <property name="tests.artifact" value="core"/>
      <property name="tests.ifNoTests" value="fail"/>
      <property name="tests.maven" value="true"/>
      <property name="tests.prefix" value="tests"/>
      <property name="tests.security.manager" value="true"/>
      <property name="tests.seed" value="AF876320E2D19F69"/>
      <property name="tests.task" value=":core:integTest"/>
      <property name="user.country" value="US"/>
      <property name="user.dir" value="/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1"/>
      <property name="user.home" value="/Users/lwiskowski"/>
      <property name="user.language" value="en"/>
      <property name="user.name" value="lwiskowski"/>
      <property name="user.timezone" value=""/>
   </properties>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testUpdateMergeMaxThreadCount" time="0.055"/>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testUpdateAutoThrottleSettings" time="0.033"/>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testEngineGCDeletesSetting" time="0.329"/>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testOpenCloseUpdateSettings" time="0.023"/>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testResetDefault" time="0.052"/>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testUpdateThrottleSettings" time="1.96"/>
   <testcase classname="org.elasticsearch.indices.settings.UpdateSettingsIT" name="testUpdateSettingsWithBlocks" time="0.084"/>
   <system-out><![CDATA[[2016-04-18 03:07:30,622][TRACE][org.elasticsearch.tasks  ] [node_s0] register 8 [transport] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@4b86131a]
[2016-04-18 03:07:30,623][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [create-index [test], cause [api]]
[2016-04-18 03:07:30,623][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: execute
[2016-04-18 03:07:30,623][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,623][DEBUG][org.elasticsearch.indices] [node_s0] creating Index [test], shards [1]/[0]
[2016-04-18 03:07:30,623][DEBUG][org.elasticsearch.index.store] [node_s0] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]
[2016-04-18 03:07:30,624][TRACE][org.elasticsearch.index.mapper] [node_s0] [test] using dynamic[true], default mapping source[{"_default_":{}}], default percolator mapping source[{
"_default_":{
"properties" : {
"query" : {
"type" : "percolator"
}
}
}
}]
[2016-04-18 03:07:30,624][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling translog_sync every 3.9s
[2016-04-18 03:07:30,624][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling refresh every 1s
[2016-04-18 03:07:30,624][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test] creating index, cause [api], templates [random_index_template], shards [1]/[0], mappings [_default_]
[2016-04-18 03:07:30,625][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start balancing cluster
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] only a single data node is present, allowing allocation
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[null], [P], v[0], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]] to [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=8PxzmbqNSESy20U8ymhB6g], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]] to node [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,625][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
[2016-04-18 03:07:30,625][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing ... (reason [cleaning up after validating index on master])
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing index service (reason [cleaning up after validating index on master])
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.index.cache.query.index] [node_s0] [test] full cache clear, reason [close]
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.indices] [node_s0] [test] closed... (reason [cleaning up after validating index on master])
[2016-04-18 03:07:30,626][TRACE][org.elasticsearch.cluster.service] expecting 1 acknowledgements for cluster_state update (version: 4)
[2016-04-18 03:07:30,626][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [create-index [test], cause [api]]
version: 4
state uuid: Mq-V5ZdES_aaq2mXJJ72cA
from_diff: false
meta data version: 3
nodes: 
   {node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local], local, master
routing_table (version 2):
-- index [test]
----shard_id [test][0]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=8PxzmbqNSESy20U8ymhB6g], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]

routing_nodes:
-----node_id[EKywQe7UTT2Znlm1LbUz_Q][V]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=8PxzmbqNSESy20U8ymhB6g], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]
---- unassigned

[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [4]
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 4
[2016-04-18 03:07:30,626][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]
[2016-04-18 03:07:30,626][DEBUG][org.elasticsearch.indices.cluster] [node_s0] [test] creating index
[2016-04-18 03:07:30,627][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,627][DEBUG][org.elasticsearch.indices] [node_s0] creating Index [test], shards [1]/[0]
[2016-04-18 03:07:30,627][DEBUG][org.elasticsearch.index.store] [node_s0] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]
[2016-04-18 03:07:30,627][TRACE][org.elasticsearch.index.mapper] [node_s0] [test] using dynamic[true], default mapping source[{"_default_":{}}], default percolator mapping source[{
"_default_":{
"properties" : {
"query" : {
"type" : "percolator"
}
}
}
}]
[2016-04-18 03:07:30,627][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling translog_sync every 3.9s
[2016-04-18 03:07:30,627][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling refresh every 1s
[2016-04-18 03:07:30,627][DEBUG][org.elasticsearch.indices.cluster] [node_s0] [test] adding mapping [_default_], source [{"_default_":{"dynamic_templates":[{"template-strings":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"string"}},{"template-longs":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"long"}},{"template-doubles":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"double"}},{"template-geo_points":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"geo_point"}},{"template-booleans":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"boolean"}}]}}]
[2016-04-18 03:07:30,627][DEBUG][org.elasticsearch.indices.cluster] [node_s0] [test][0] creating shard
[2016-04-18 03:07:30,627][TRACE][org.elasticsearch.env    ] [node_s0] acquiring node shardlock on [[test][0]], timeout [5000]
[2016-04-18 03:07:30,627][TRACE][org.elasticsearch.env    ] [node_s0] successfully acquired shardlock for [[test][0]]
[2016-04-18 03:07:30,628][DEBUG][org.elasticsearch.index  ] [node_s0] [test] [test][0] creating using a new path [ShardPath{path=/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_AF876320E2D19F69-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[4850830618144658996]-HASH=[267CBAA93826]-cluster/nodes/0/indices/test/0, indexUUID='BgUa38j6T2ipyY5A1mkV6g', shard=[test][0]}]
[2016-04-18 03:07:30,628][DEBUG][org.elasticsearch.index  ] [node_s0] [test] creating shard_id [test][0]
[2016-04-18 03:07:30,630][DEBUG][org.elasticsearch.index.store] [node_s0] [test][0] store stats are refreshed with refresh_interval [10s]
[2016-04-18 03:07:30,630][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] state: [CREATED]
[2016-04-18 03:07:30,630][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] state: [CREATED]->[RECOVERING], reason [from store]
[2016-04-18 03:07:30,630][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] starting recovery from store ...
[2016-04-18 03:07:30,631][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,631][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [freshly created]
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: init: current segments file is "segments"; deletionPolicy=org.apache.lucene.index.SnapshotDeletionPolicy@1a7ff05d
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: now checkpoint "" [0 segments ; isCommit = false]
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: 0 msec to checkpoint
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: init: create=true
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]], cluster_state update (version: 4)
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 4)
[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: 
dir=store(default(mmapfs(/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_AF876320E2D19F69-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[4850830618144658996]-HASH=[267CBAA93826]-cluster/nodes/0/indices/test/0/index),niofs(/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_AF876320E2D19F69-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[4850830618144658996]-HASH=[267CBAA93826]-cluster/nodes/0/indices/test/0/index)))
index=
version=5.5.0
analyzer=org.elasticsearch.index.mapper.MapperService$MapperAnalyzerWrapper
ramBufferSizeMB=256.0
maxBufferedDocs=-1
maxBufferedDeleteTerms=-1
mergedSegmentWarmer=org.elasticsearch.index.engine.InternalEngine$1@3529786
delPolicy=org.apache.lucene.index.SnapshotDeletionPolicy
commit=null
openMode=CREATE
similarity=org.elasticsearch.index.similarity.SimilarityService$PerFieldSimilarity
mergeScheduler=EngineMergeScheduler: maxThreadCount=10000, maxMergeCount=10000, ioThrottle=false
default WRITE_LOCK_TIMEOUT=0
writeLockTimeout=5000
codec=Asserting(Lucene54): {}, docValues:{}
infoStream=org.elasticsearch.common.lucene.LoggerInfoStream
mergePolicy=ElasticsearchMergePolicy([TieredMergePolicy: maxMergeAtOnce=2, maxMergeAtOnceExplicit=30, maxMergedSegmentMB=5120.0, floorSegmentMB=2.0, forceMergeDeletesPctAllowed=10.0, segmentsPerTier=2.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.3300441039495746)
indexerThreadPool=org.apache.lucene.index.DocumentsWriterPerThreadPool@127dbe62
readerPooling=false
perThreadHardLimitMB=1945
useCompoundFile=true
commitOnClose=false
writer=org.apache.lucene.index.IndexWriter@2d50e361

[2016-04-18 03:07:30,632][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 8
[2016-04-18 03:07:30,633][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: MMapDirectory.UNMAP_SUPPORTED=true
[2016-04-18 03:07:30,632][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: took 9ms done applying updated cluster_state (version: 4, uuid: Mq-V5ZdES_aaq2mXJJ72cA)
[2016-04-18 03:07:30,633][TRACE][org.elasticsearch.tasks  ] [node_s0] register 9 [transport] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@332e07f]
[2016-04-18 03:07:30,633][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [update-settings]
[2016-04-18 03:07:30,633][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: execute
[2016-04-18 03:07:30,633][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards
[2016-04-18 03:07:30,634][DEBUG][org.elasticsearch.index.translog] [node_s0] [test][0] wipe translog location - creating new translog
[2016-04-18 03:07:30,634][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,634][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=8PxzmbqNSESy20U8ymhB6g], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]] to node [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,634][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
[2016-04-18 03:07:30,634][TRACE][org.elasticsearch.cluster.service] expecting 1 acknowledgements for cluster_state update (version: 5)
[2016-04-18 03:07:30,634][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [update-settings]
version: 5
state uuid: zL1B9bsTTJuOVZ6heIUC5w
from_diff: false
meta data version: 4
nodes: 
   {node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local], local, master
routing_table (version 3):
-- index [test]
----shard_id [test][0]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=8PxzmbqNSESy20U8ymhB6g], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]

routing_nodes:
-----node_id[EKywQe7UTT2Znlm1LbUz_Q][V]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=8PxzmbqNSESy20U8ymhB6g], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.624Z]]
---- unassigned

[2016-04-18 03:07:30,634][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [5]
[2016-04-18 03:07:30,634][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 5
[2016-04-18 03:07:30,634][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.indices.cluster] [node_s0] ignoring recovery instruction for an existing shard [test][0] (shard state: [RECOVERING])
[2016-04-18 03:07:30,635][DEBUG][org.elasticsearch.index.engine] [node_s0] [test][0] no translog ID present in the current generation - creating one
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine] [node_s0] [test][0] committing writer with translog id [1]  and sync id [null] 
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: start
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: enter lock
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: now prepare
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: prepareCommit: flush
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW:   index before flush 
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: startFullFlush
[2016-04-18 03:07:30,635][INFO ][org.elasticsearch.common.settings] [node_s0] updating [index.merge.scheduler.max_thread_count] from [10000] to [1]
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: apply all deletes during flush
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: now apply all deletes for all segments maxDoc=0
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] BD: prune sis=segments:  minGen=9223372036854775807 packetCount=0
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: elasticsearch[node_s0][generic][T#1] finishFullFlush success=true
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: startCommit(): start
[2016-04-18 03:07:30,635][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: startCommit index= changeCount=3
[2016-04-18 03:07:30,636][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,636][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [version changed from [1] to [2]]
[2016-04-18 03:07:30,636][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: startCommit: wrote pending segments file "pending_segments_1"
[2016-04-18 03:07:30,636][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: done all syncs: []
[2016-04-18 03:07:30,636][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: pendingCommit != null
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: done writing segments file "segments_1"
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: now checkpoint "" [0 segments ; isCommit = true]
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: 0 msec to checkpoint
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: took 2.0 msec
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: done
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: flush at getReader
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: startFullFlush
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: apply all deletes during flush
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]], cluster_state update (version: 5)
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 5)
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: now apply all deletes for all segments maxDoc=0
[2016-04-18 03:07:30,637][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: took 4ms done applying updated cluster_state (version: 5, uuid: zL1B9bsTTJuOVZ6heIUC5w)
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] BD: prune sis=segments_1:  minGen=9223372036854775807 packetCount=0
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 9
[2016-04-18 03:07:30,637][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: incRefDeleter for NRT reader version=3 segments=
[2016-04-18 03:07:30,638][TRACE][org.elasticsearch.tasks  ] [node_s0] register 10 [transport] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@7562170e]
[2016-04-18 03:07:30,638][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: return reader version=3 reader=StandardDirectoryReader(segments_1:3:nrt)
[2016-04-18 03:07:30,638][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: elasticsearch[node_s0][generic][T#1] finishFullFlush success=true
[2016-04-18 03:07:30,638][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 10
[2016-04-18 03:07:30,638][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: getReader took 1 msec
[2016-04-18 03:07:30,658][TRACE][org.elasticsearch.tasks  ] [node_s0] register 29 [transport] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@446a0bb4]
[2016-04-18 03:07:30,658][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [create-index [test], cause [api]]
[2016-04-18 03:07:30,658][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: execute
[2016-04-18 03:07:30,659][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,659][DEBUG][org.elasticsearch.indices] [node_s0] creating Index [test], shards [1]/[0]
[2016-04-18 03:07:30,659][DEBUG][org.elasticsearch.index.store] [node_s0] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]
[2016-04-18 03:07:30,659][TRACE][org.elasticsearch.index.mapper] [node_s0] [test] using dynamic[true], default mapping source[{"_default_":{}}], default percolator mapping source[{
"_default_":{
"properties" : {
"query" : {
"type" : "percolator"
}
}
}
}]
[2016-04-18 03:07:30,659][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling translog_sync every 5s
[2016-04-18 03:07:30,659][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling refresh every 1s
[2016-04-18 03:07:30,660][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test] creating index, cause [api], templates [random_index_template], shards [1]/[0], mappings [_default_]
[2016-04-18 03:07:30,660][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,660][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start balancing cluster
[2016-04-18 03:07:30,660][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,660][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
[2016-04-18 03:07:30,660][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] only a single data node is present, allowing allocation
[2016-04-18 03:07:30,660][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[null], [P], v[0], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]] to [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]] to node [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing ... (reason [cleaning up after validating index on master])
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing index service (reason [cleaning up after validating index on master])
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.index.cache.query.index] [node_s0] [test] full cache clear, reason [close]
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.indices] [node_s0] [test] closed... (reason [cleaning up after validating index on master])
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.service] expecting 1 acknowledgements for cluster_state update (version: 10)
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [create-index [test], cause [api]]
version: 10
state uuid: ehEGa_F-Tw60sYi9MMcRtA
from_diff: false
meta data version: 9
nodes: 
   {node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local], local, master
routing_table (version 6):
-- index [test]
----shard_id [test][0]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]

routing_nodes:
-----node_id[EKywQe7UTT2Znlm1LbUz_Q][V]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]
---- unassigned

[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [10]
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 10
[2016-04-18 03:07:30,661][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]
[2016-04-18 03:07:30,661][DEBUG][org.elasticsearch.indices.cluster] [node_s0] [test] creating index
[2016-04-18 03:07:30,662][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,662][DEBUG][org.elasticsearch.indices] [node_s0] creating Index [test], shards [1]/[0]
[2016-04-18 03:07:30,662][DEBUG][org.elasticsearch.index.store] [node_s0] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]
[2016-04-18 03:07:30,662][TRACE][org.elasticsearch.index.mapper] [node_s0] [test] using dynamic[true], default mapping source[{"_default_":{}}], default percolator mapping source[{
"_default_":{
"properties" : {
"query" : {
"type" : "percolator"
}
}
}
}]
[2016-04-18 03:07:30,662][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling translog_sync every 5s
[2016-04-18 03:07:30,662][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling refresh every 1s
[2016-04-18 03:07:30,662][DEBUG][org.elasticsearch.indices.cluster] [node_s0] [test] adding mapping [_default_], source [{"_default_":{"dynamic_templates":[{"template-strings":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"string"}},{"template-longs":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"long"}},{"template-doubles":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"double"}},{"template-geo_points":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"geo_point"}},{"template-booleans":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"boolean"}}]}}]
[2016-04-18 03:07:30,662][DEBUG][org.elasticsearch.indices.cluster] [node_s0] [test][0] creating shard
[2016-04-18 03:07:30,663][TRACE][org.elasticsearch.env    ] [node_s0] acquiring node shardlock on [[test][0]], timeout [5000]
[2016-04-18 03:07:30,663][TRACE][org.elasticsearch.env    ] [node_s0] successfully acquired shardlock for [[test][0]]
[2016-04-18 03:07:30,663][DEBUG][org.elasticsearch.index  ] [node_s0] [test] [test][0] creating using a new path [ShardPath{path=/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_AF876320E2D19F69-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[4850830618144658996]-HASH=[267CBAA93826]-cluster/nodes/0/indices/test/0, indexUUID='26LfoOhKSu-4BKvQyfXhMQ', shard=[test][0]}]
[2016-04-18 03:07:30,663][DEBUG][org.elasticsearch.index  ] [node_s0] [test] creating shard_id [test][0]
[2016-04-18 03:07:30,663][DEBUG][org.elasticsearch.index.store] [node_s0] [test][0] store stats are refreshed with refresh_interval [10s]
[2016-04-18 03:07:30,664][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] state: [CREATED]
[2016-04-18 03:07:30,664][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] state: [CREATED]->[RECOVERING], reason [from store]
[2016-04-18 03:07:30,664][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] starting recovery from store ...
[2016-04-18 03:07:30,664][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,664][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [freshly created]
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: init: current segments file is "segments"; deletionPolicy=org.apache.lucene.index.SnapshotDeletionPolicy@67c32fd
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: now checkpoint "" [0 segments ; isCommit = false]
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: 0 msec to checkpoint
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: init: create=true
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]], cluster_state update (version: 10)
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 10)
[2016-04-18 03:07:30,665][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: took 6ms done applying updated cluster_state (version: 10, uuid: ehEGa_F-Tw60sYi9MMcRtA)
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 29
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: 
dir=store(default(mmapfs(/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_AF876320E2D19F69-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[4850830618144658996]-HASH=[267CBAA93826]-cluster/nodes/0/indices/test/0/index),niofs(/Users/lwiskowski/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_AF876320E2D19F69-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[4850830618144658996]-HASH=[267CBAA93826]-cluster/nodes/0/indices/test/0/index)))
index=
version=5.5.0
analyzer=org.elasticsearch.index.mapper.MapperService$MapperAnalyzerWrapper
ramBufferSizeMB=256.0
maxBufferedDocs=-1
maxBufferedDeleteTerms=-1
mergedSegmentWarmer=org.elasticsearch.index.engine.InternalEngine$1@4b5ce995
delPolicy=org.apache.lucene.index.SnapshotDeletionPolicy
commit=null
openMode=CREATE
similarity=org.elasticsearch.index.similarity.SimilarityService$PerFieldSimilarity
mergeScheduler=EngineMergeScheduler: maxThreadCount=1, maxMergeCount=2, ioThrottle=true
default WRITE_LOCK_TIMEOUT=0
writeLockTimeout=5000
codec=Asserting(Lucene54): {}, docValues:{}
infoStream=org.elasticsearch.common.lucene.LoggerInfoStream
mergePolicy=ElasticsearchMergePolicy([TieredMergePolicy: maxMergeAtOnce=2, maxMergeAtOnceExplicit=30, maxMergedSegmentMB=5120.0, floorSegmentMB=2.0, forceMergeDeletesPctAllowed=10.0, segmentsPerTier=2.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.1)
indexerThreadPool=org.apache.lucene.index.DocumentsWriterPerThreadPool@4f902b22
readerPooling=false
perThreadHardLimitMB=1945
useCompoundFile=true
commitOnClose=false
writer=org.apache.lucene.index.IndexWriter@976b4bc

[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.test   ] Using transport client for node [node_s0] sniff: [false]
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: MMapDirectory.UNMAP_SUPPORTED=true
[2016-04-18 03:07:30,665][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s0] [3][indices:admin/settings/update] sent to [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]] (timeout: [null])
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.transport.tracer] [node_s0] [3][indices:admin/settings/update] received request
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.tasks  ] [node_s0] register 30 [local] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@471564d]
[2016-04-18 03:07:30,666][DEBUG][org.elasticsearch.index.translog] [node_s0] [test][0] wipe translog location - creating new translog
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.tasks  ] [node_s0] register 31 [transport] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@471564d]
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [update-settings]
[2016-04-18 03:07:30,666][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: execute
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]] to node [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,666][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
[2016-04-18 03:07:30,666][DEBUG][org.elasticsearch.index.engine] [node_s0] [test][0] no translog ID present in the current generation - creating one
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine] [node_s0] [test][0] committing writer with translog id [1]  and sync id [null] 
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: start
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: enter lock
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: now prepare
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: prepareCommit: flush
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW:   index before flush 
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.cluster.service] expecting 1 acknowledgements for cluster_state update (version: 11)
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: startFullFlush
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: apply all deletes during flush
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [update-settings]
version: 11
state uuid: JYYmPm1wQPOfah-yi-L5mA
from_diff: false
meta data version: 10
nodes: 
   {node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local], local, master
routing_table (version 7):
-- index [test]
----shard_id [test][0]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]

routing_nodes:
-----node_id[EKywQe7UTT2Znlm1LbUz_Q][V]
--------[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]
---- unassigned

[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: now apply all deletes for all segments maxDoc=0
[2016-04-18 03:07:30,667][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [11]
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] BD: prune sis=segments:  minGen=9223372036854775807 packetCount=0
[2016-04-18 03:07:30,667][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 11
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: elasticsearch[node_s0][generic][T#1] finishFullFlush success=true
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: startCommit(): start
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.indices.cluster] [node_s0] ignoring recovery instruction for an existing shard [test][0] (shard state: [RECOVERING])
[2016-04-18 03:07:30,667][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: startCommit index= changeCount=3
[2016-04-18 03:07:30,668][INFO ][org.elasticsearch.common.settings] [node_s0] updating [index.merge.scheduler.auto_throttle] from [true] to [false]
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: startCommit: wrote pending segments file "pending_segments_1"
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: done all syncs: []
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: pendingCommit != null
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: done writing segments file "segments_1"
[2016-04-18 03:07:30,668][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [version changed from [1] to [2]]
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: now checkpoint "" [0 segments ; isCommit = true]
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IFD: 0 msec to checkpoint
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: took 1.6 msec
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: commit: done
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: flush at getReader
[2016-04-18 03:07:30,668][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: startFullFlush
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: apply all deletes during flush
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: now apply all deletes for all segments maxDoc=0
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] BD: prune sis=segments_1:  minGen=9223372036854775807 packetCount=0
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: incRefDeleter for NRT reader version=3 segments=
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: return reader version=3 reader=StandardDirectoryReader(segments_1:3:nrt)
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] DW: elasticsearch[node_s0][generic][T#1] finishFullFlush success=true
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] IW: getReader took 1 msec
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.indices] [node_s0] [test][0] warming [ElasticsearchDirectoryReader()]
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.warmer] [node_s0] [test][0] warming took [47.4micros]
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.indices] [node_s0] [test][0] top warming [ElasticsearchDirectoryReader()]
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.warmer] [node_s0] [test][0] top warming took [9micros]
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]], cluster_state update (version: 11)
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 11)
[2016-04-18 03:07:30,669][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: took 3ms done applying updated cluster_state (version: 11, uuid: JYYmPm1wQPOfah-yi-L5mA)
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 31
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.index.engine] [node_s0] [test][0] created new InternalEngine
[2016-04-18 03:07:30,669][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 30
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.transport.tracer] [node_s0] [3][indices:admin/settings/update] sent response
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s0] [3][indices:admin/settings/update] received response from [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]]
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s0] [test][0] elasticsearch[node_s0][generic][T#1] MS: updateMergeThreads ioThrottle=false targetMBPerSec=20.0 MB/sec
[2016-04-18 03:07:30,670][DEBUG][org.elasticsearch.index.shard] [node_s0] [test][0] state: [RECOVERING]->[POST_RECOVERY], reason [post recovery from shard_store]
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.test   ] Using transport client for node [node_s0] sniff: [false]
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s0] [4][indices:monitor/settings/get] sent to [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]] (timeout: [null])
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.index.shard] [node_s0] [test][0] recovery completed from shard_store, took [6ms]
    index    : files           [0] with total_size [0b], took[0s]
             : recovered_files [0] with total_size [0b]
             : reusing_files   [0] with total_size [0b]
    verify_index    : took [0s], check_index [0s]
    translog : number_of_operations [0], took [5ms]
[2016-04-18 03:07:30,670][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 0 sending [internal:cluster/shard/started] to [EKywQe7UTT2Znlm1LbUz_Q] for shard [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]], indexUUID [26LfoOhKSu-4BKvQyfXhMQ], message [after recovery from store], failure [Unknown]]
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.tasks  ] [node_s0] register 32 [direct] [internal:cluster/shard/started] [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]], indexUUID [26LfoOhKSu-4BKvQyfXhMQ], message [after recovery from store], failure [Unknown]]
[2016-04-18 03:07:30,670][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test][0] received shard started for [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]], indexUUID [26LfoOhKSu-4BKvQyfXhMQ], message [after recovery from store], failure [Unknown]]
[2016-04-18 03:07:30,670][TRACE][org.elasticsearch.transport.tracer] [node_s0] [4][indices:monitor/settings/get] received request
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [shard-started ([test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]), reason [after recovery from store]]
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.tasks  ] [node_s0] register 33 [local] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@11caf41c]
[2016-04-18 03:07:30,671][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]]), reason [after recovery from store]]: execute
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.tasks  ] [node_s0] register 34 [transport] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@11caf41c]
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 32
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.routing.allocation] [node_s0] [test][0] marked shard as started (routing: [test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[1], s[INITIALIZING], a[id=5Bc3t57QSxqWt_NZwfnNPg], unassigned_info[[reason=INDEX_CREATED], at[2016-04-18T07:07:30.660Z]])
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.transport.tracer] [node_s0] [4][internal:cluster/shard/started] received response from [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]]
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 34
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] only a single data node is present, allowing allocation
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 33
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.transport.tracer] [node_s0] [4][indices:monitor/settings/get] sent response
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[EKywQe7UTT2Znlm1LbUz_Q], [P], v[2], s[STARTED], a[id=5Bc3t57QSxqWt_NZwfnNPg]] to node [EKywQe7UTT2Znlm1LbUz_Q]
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s0] [4][indices:monitor/settings/get] received response from [{node_s0}{EKywQe7UTT2Znlm1LbUz_Q}{local}{local[470]}[mode=>local]]
[2016-04-18 03:07:30,671][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards
]]></system-out>
   <system-err><![CDATA[]]></system-err>
</testsuite>