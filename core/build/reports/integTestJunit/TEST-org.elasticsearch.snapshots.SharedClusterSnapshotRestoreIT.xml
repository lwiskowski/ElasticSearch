<testsuite errors="0" failures="0" tests="35" skipped="0" name="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" hostname="nohost.nodomain" time="89.723" timestamp="2016-03-29T17:27:57">
   <properties class="java.util.ArrayList">
      <property name="awt.toolkit" value="sun.lwawt.macosx.LWCToolkit"/>
      <property name="es.logger.level" value="WARN"/>
      <property name="file.encoding" value="UTF-8"/>
      <property name="file.encoding.pkg" value="sun.io"/>
      <property name="file.separator" value="/"/>
      <property name="ftp.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16"/>
      <property name="gopherProxySet" value="false"/>
      <property name="http.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16"/>
      <property name="java.awt.graphicsenv" value="sun.awt.CGraphicsEnvironment"/>
      <property name="java.awt.headless" value="true"/>
      <property name="java.awt.printerjob" value="sun.lwawt.macosx.CPrinterJob"/>
      <property name="java.class.path" value="/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/classes/test:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/resources/test:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/classes/main:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/resources/main:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-core/5.5.0-snapshot-1721183/f6854c65c7f4c6d9de583f4daa4fd3ae8a3800f1/lucene-core-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-analyzers-common/5.5.0-snapshot-1721183/69e187ef1d2d9c9570363eb4186821e0341df5b8/lucene-analyzers-common-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-backward-codecs/5.5.0-snapshot-1721183/fa00a45ff9bc6a4df44db81f2e4e44ea94bf88e/lucene-backward-codecs-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-grouping/5.5.0-snapshot-1721183/e996e6c723eb415ba2cfa7f5e98bbf194a4918dd/lucene-grouping-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-highlighter/5.5.0-snapshot-1721183/3b7a5d97b10885f16eb53deb15d64c942b9f9fdb/lucene-highlighter-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-join/5.5.0-snapshot-1721183/e4dda3eeb76e340aa4713a3b20d68c4a1504e505/lucene-join-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-memory/5.5.0-snapshot-1721183/800442a5d7612ce4c8748831871b4d436a50554e/lucene-memory-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-misc/5.5.0-snapshot-1721183/bdf184de9b5773c7af3ae908af78eeb1e512470c/lucene-misc-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queries/5.5.0-snapshot-1721183/fc59de52bd2c7e420edfd235723cb8b0dd44e92d/lucene-queries-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queryparser/5.5.0-snapshot-1721183/1d341e6a4f11f3170773ccffdbe6815b45967e3d/lucene-queryparser-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-sandbox/5.5.0-snapshot-1721183/a1b02c2b595ac92f45f0d2be03841a3a7fcae1f1/lucene-sandbox-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial/5.5.0-snapshot-1721183/e3ea422b56734329fb6974e9cf9f66478adb5793/lucene-spatial-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial3d/5.5.0-snapshot-1721183/5eadbd4e63120b59ab6445e39489205f98420471/lucene-spatial3d-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-suggest/5.5.0-snapshot-1721183/a336287e65d082535f02a8427666dbe46b1b9b74/lucene-suggest-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securesm/1.0/c0c6cf986ba0057390bfcc80c366a0e3157f944b/securesm-1.0.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.3.1/1303efbc4b181e5a58bf2e967dc156a3132b97c0/commons-cli-1.3.1.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch/hppc/0.7.1/8b5057f74ea378c0150a1860874a3ebdcb713767/hppc-0.7.1.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.8.2/d27c24204c5e507b16fec01006b3d0f1ec42aed4/joda-time-2.8.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.joda/joda-convert/1.2/35ec554f0cd00c956cc69051514d9488b1374dec/joda-convert-1.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.2/123f29333b2c6b3516b14252b6e93226bfcd6e37/jackson-core-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-smile/2.6.2/395d18c1a1dd730b8026ee59c4067e5d2b45ba6e/jackson-dataformat-smile-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-yaml/2.6.2/4ae23088dd3fae47c66843f2e4251d7255ee140e/jackson-dataformat-yaml-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-cbor/2.6.2/1e13c575f914c83761bb8e2aca7dfd9e4c647579/jackson-dataformat-cbor-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.10.5.Final/9ca7d55d246092bddd29b867706e2f6c7db701a0/netty-3.10.5.Final.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.tdunning/t-digest/3.0/84ccf145ac2215e6bfa63baa3101c0af41017cfc/t-digest-3.0.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.hdrhistogram/HdrHistogram/2.1.6/7495feb7f71ee124bd2a7e7d83590e296d71d80e/HdrHistogram-2.1.6.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.spatial4j/spatial4j/0.5/6e16edaf6b1ba76db7f08c2f3723fce3b358ecc3/spatial4j-0.5.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.vividsolutions/jts/1.13/3ccfb9b60f04d71add996a666ceb8902904fd805/jts-1.13.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/log4j/apache-log4j-extras/1.2.17/85863614d82185d7e51fe21c00aa9117a523a8b6/apache-log4j-extras-1.2.17.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.2/8619e95939167fb37245b5670135e4feb0ec7d50/slf4j-api-1.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/net.java.dev.jna/jna/4.1.0/1c12d070e602efd8021891cdd7fd18bc129372d4/jna-4.1.0.jar:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/test/framework/build/libs/framework-3.0.0-SNAPSHOT.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/randomizedtesting-runner/2.3.2/307965917fe8a22b7ee72deba39ef4b8e6ebc069/randomizedtesting-runner-2.3.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-test-framework/5.5.0-snapshot-1721183/a8d851d0ad82182b3a02f4b30c336e7aa0e173cb/lucene-test-framework-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-codecs/5.5.0-snapshot-1721183/8aa59442b028c7a2c1a516accb6142a8910ba5fc/lucene-codecs-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.3.6/4c47155e3e6c9a41a28db36680b828ced53b8af4/httpclient-4.3.6.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.3.3/f91b7a4aadc5cf486df6e4634748d7dd7a73f06d/httpcore-4.3.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.3/f6f66e966c70a83ffbdb6f17a0919eaf7c8aca7f/commons-logging-1.1.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.10/4b95f4897fa13f2cd904aee711aeafc0c5295cd8/commons-codec-1.10.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securemock/1.2/98201d4ad5ac93f6b415ae9172d52b5e7cda490e/securemock-1.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/junit4-ant/2.3.2/dc8f03f6111974092491f35b8269eb0fc57f52f7/junit4-ant-2.3.2.jar"/>
      <property name="java.class.version" value="52.0"/>
      <property name="java.endorsed.dirs" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/endorsed"/>
      <property name="java.ext.dirs" value="/Users/ogbonnayacngwu/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java"/>
      <property name="java.home" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre"/>
      <property name="java.io.tmpdir" value="./temp"/>
      <property name="java.library.path" value="/Users/ogbonnayacngwu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:."/>
      <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
      <property name="java.runtime.version" value="1.8.0_11-b12"/>
      <property name="java.specification.name" value="Java Platform API Specification"/>
      <property name="java.specification.vendor" value="Oracle Corporation"/>
      <property name="java.specification.version" value="1.8"/>
      <property name="java.vendor" value="Oracle Corporation"/>
      <property name="java.vendor.url" value="http://java.oracle.com/"/>
      <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
      <property name="java.version" value="1.8.0_11"/>
      <property name="java.vm.info" value="mixed mode"/>
      <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
      <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
      <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
      <property name="java.vm.specification.version" value="1.8"/>
      <property name="java.vm.vendor" value="Oracle Corporation"/>
      <property name="java.vm.version" value="25.11-b03"/>
      <property name="junit4.childvm.count" value="4"/>
      <property name="junit4.childvm.cwd" value="/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1"/>
      <property name="junit4.childvm.id" value="1"/>
      <property name="junit4.memory.total" value="514850816"/>
      <property name="junit4.pidString" value="27395@host37-246.aruba.fit.edu"/>
      <property name="junit4.processors" value="8"/>
      <property name="line.separator" value="
"/>
      <property name="os.arch" value="x86_64"/>
      <property name="os.name" value="Mac OS X"/>
      <property name="os.version" value="10.11.4"/>
      <property name="path.separator" value=":"/>
      <property name="socksNonProxyHosts" value="local|*.local|169.254/16|*.169.254/16"/>
      <property name="sun.arch.data.model" value="64"/>
      <property name="sun.boot.class.path" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/classes"/>
      <property name="sun.boot.library.path" value="/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib"/>
      <property name="sun.cpu.endian" value="little"/>
      <property name="sun.cpu.isalist" value=""/>
      <property name="sun.io.unicode.encoding" value="UnicodeBig"/>
      <property name="sun.java.command" value="com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe -eventsfile /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160329_172724_554.events @/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160329_172724_554.suites -stdin"/>
      <property name="sun.java.launcher" value="SUN_STANDARD"/>
      <property name="sun.jnu.encoding" value="UTF-8"/>
      <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
      <property name="sun.os.patch.level" value="unknown"/>
      <property name="tests.artifact" value="core"/>
      <property name="tests.ifNoTests" value="fail"/>
      <property name="tests.maven" value="true"/>
      <property name="tests.prefix" value="tests"/>
      <property name="tests.security.manager" value="true"/>
      <property name="tests.seed" value="4AA6DECDBC490785"/>
      <property name="tests.task" value=":core:integTest"/>
      <property name="user.country" value="US"/>
      <property name="user.dir" value="/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1"/>
      <property name="user.home" value="/Users/ogbonnayacngwu"/>
      <property name="user.language" value="en"/>
      <property name="user.name" value="ogbonnayacngwu"/>
      <property name="user.timezone" value="America/New_York"/>
   </properties>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteIndexDuringSnapshot" time="5.175"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testRestoreAliases" time="4.068"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testFreshIndexUUID" time="2.558"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotStatus" time="1.521"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testBatchingShardUpdateTask" time="2.287"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotName" time="0.109"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotMoreThanOnce" time="0.7"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testRenameOnRestore" time="4.868"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteSnapshotWithCorruptedSnapshotFile" time="1.645"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDataFileFailureDuringSnapshot" time="1.323"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteSnapshot" time="5.043"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteRepositoryWhileSnapshotting" time="1.222"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testListCorruptedSnapshot" time="1.409"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testUnallocatedShards" time="0.148"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotClosedIndex" time="0.44"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeletionOfFailingToRecoverIndexShouldStopRestore" time="1.1"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testUrlRepository" time="1.915"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testBasicWorkFlow" time="6.936"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotFileFailureDuringSnapshot" time="1.715"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testEmptySnapshot" time="0.12"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testReadonlyRepository" time="1.614"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDataFileFailureDuringRestore" time="2.891"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testRestoreWithDifferentMappingsAndSettings" time="1.021"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testIncludeGlobalState" time="0.802"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteSnapshotWithMissingMetadata" time="1.951"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteSnapshotWithMissingIndexAndShardMetadata" time="0.817"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testRestoreTemplates" time="0.182"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotSingleClosedIndex" time="1.091"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testMoveShardWhileSnapshotting" time="1.421"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSnapshotRelocatingPrimary" time="5.342"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testDeleteOrphanSnapshot" time="0.882"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testThrottling" time="23.885"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testChangeSettingsOnRestore" time="0.953"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testRecreateBlocksOnRestore" time="1.049"/>
   <testcase classname="org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT" name="testSingleGetAfterRestore" time="1.012"/>
   <system-out><![CDATA[[2016-03-29 17:28:10,706][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: execute
[2016-03-29 17:28:10,707][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: took 0s no change in cluster_state
[2016-03-29 17:28:10,708][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index-template [random_index_template], cause [api]]: execute
[2016-03-29 17:28:10,708][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [136], source [create-index-template [random_index_template], cause [api]]
[2016-03-29 17:28:10,708][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [136]
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [136], source [local-disco-receive(from master)]
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [136], source [local-disco-receive(from master)]
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 136
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 136, uuid: yG487qMWRlu3pgfXKIvm5g)
[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 136
[2016-03-29 17:28:10,715][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 136, uuid: yG487qMWRlu3pgfXKIvm5g)
[2016-03-29 17:28:10,715][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 136
[2016-03-29 17:28:10,719][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index-template [random_index_template], cause [api]]: took 11ms done applying updated cluster_state (version: 136, uuid: yG487qMWRlu3pgfXKIvm5g)
[2016-03-29 17:28:10,720][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put_repository [test-repo]]: execute
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [137], source [put_repository [test-repo]]
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [137]
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [137], source [local-disco-receive(from master)]
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 137
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 137, uuid: 3ch5diOYT7G9J7qwCysxhw)
[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [137], source [local-disco-receive(from master)]
[2016-03-29 17:28:10,723][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 137
[2016-03-29 17:28:10,728][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 137, uuid: 3ch5diOYT7G9J7qwCysxhw)
[2016-03-29 17:28:10,728][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 137
[2016-03-29 17:28:10,736][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put_repository [test-repo]]: took 15ms done applying updated cluster_state (version: 137, uuid: 3ch5diOYT7G9J7qwCysxhw)
[2016-03-29 17:28:10,737][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test-idx], cause [api]]: execute
[2016-03-29 17:28:10,740][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] creating index, cause [api], templates [random_index_template], shards [7]/[0], mappings [_default_]
[2016-03-29 17:28:10,742][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [138], source [create-index [test-idx], cause [api]]
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [138]
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [138], source [local-disco-receive(from master)]
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 138
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [138], source [local-disco-receive(from master)]
[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 138
[2016-03-29 17:28:10,744][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 138, uuid: _JiHk6JXQyqwkejzGKgsAA)
[2016-03-29 17:28:10,868][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 2 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:10,869][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard started for [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:10,952][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 208ms done applying updated cluster_state (version: 138, uuid: _JiHk6JXQyqwkejzGKgsAA)
[2016-03-29 17:28:10,952][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 138
[2016-03-29 17:28:10,953][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 4 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:10,953][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard started for [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,022][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 6 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,023][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard started for [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,027][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,027][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,028][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,029][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,046][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test-idx], cause [api]]: took 309ms done applying updated cluster_state (version: 138, uuid: _JiHk6JXQyqwkejzGKgsAA)
[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store]]: execute
[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 3 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard started for [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [139], source [shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store]]
[2016-03-29 17:28:11,048][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [139]
[2016-03-29 17:28:11,049][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [139], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 139
[2016-03-29 17:28:11,049][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [139], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 139
[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 139, uuid: Gl18JFAoT3yELUoyIV1YDQ)
[2016-03-29 17:28:11,057][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 5 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,057][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard started for [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]
[2016-03-29 17:28:11,061][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 11ms done applying updated cluster_state (version: 139, uuid: Gl18JFAoT3yELUoyIV1YDQ)
[2016-03-29 17:28:11,062][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 139
[2016-03-29 17:28:11,063][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 3 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]
[2016-03-29 17:28:11,063][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard started for [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]
[2016-03-29 17:28:11,063][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 5 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]
[2016-03-29 17:28:11,064][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard started for [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]
[2016-03-29 17:28:11,069][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store]]: took 22ms done applying updated cluster_state (version: 139, uuid: Gl18JFAoT3yELUoyIV1YDQ)
[2016-03-29 17:28:11,070][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute
[2016-03-29 17:28:11,070][INFO ][org.elasticsearch.cluster.routing.allocation] [node_s0] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test-idx][3], [test-idx][5], [test-idx][3], [test-idx][5]] ...]).
[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [140], source [shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]
[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [140]
[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [140], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 140
[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [140], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 140
[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 140, uuid: 9amE80iXQuGYKOFG9CEX_Q)
[2016-03-29 17:28:11,078][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 140, uuid: 9amE80iXQuGYKOFG9CEX_Q)
[2016-03-29 17:28:11,078][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,078][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 140
[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 8ms no change in cluster_state
[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 16ms done applying updated cluster_state (version: 140, uuid: 9amE80iXQuGYKOFG9CEX_Q)
[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:11,088][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,088][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:11,088][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,095][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:11,095][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,096][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:11,096][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,104][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:11,104][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:11,104][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,111][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:11,111][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute
[2016-03-29 17:28:11,118][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 6ms no change in cluster_state
[2016-03-29 17:28:11,118][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_health (wait_for_events [LANGUID])]: execute
[2016-03-29 17:28:11,119][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state
[2016-03-29 17:28:11,124][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]: execute
[2016-03-29 17:28:11,127][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] create_mapping [RANDOM_BOGUS_TYPE______] with source [{"RANDOM_BOGUS_TYPE______":{"_timestamp":{"enabled":false},"dynamic_templates":[{"template-strings":{"mapping":{"fielddata":{"loading":"eager_global_ordinals"}},"match_mapping_type":"string"}},{"template-longs":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"long"}},{"template-doubles":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"double"}},{"template-geo_points":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"geo_point"}},{"template-booleans":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"boolean"}}]}}]
[2016-03-29 17:28:11,133][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] create_mapping [type1] with source [{"type1":{"_timestamp":{"enabled":false},"dynamic_templates":[{"template-strings":{"mapping":{"fielddata":{"loading":"eager_global_ordinals"}},"match_mapping_type":"string"}},{"template-longs":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"long"}},{"template-doubles":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"double"}},{"template-geo_points":{"mapping":{"fielddata":{"loading":"eager"}},"match_mapping_type":"geo_point"}},{"template-booleans":{"mapping":{"fielddata":{"loading":"lazy"}},"match_mapping_type":"boolean"}}],"properties":{"field1":{"type":"string","fielddata":{"loading":"eager_global_ordinals"}}}}}]
[2016-03-29 17:28:11,141][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [141], source [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]
[2016-03-29 17:28:11,141][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [141]
[2016-03-29 17:28:11,142][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,143][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [141], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,143][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 141
[2016-03-29 17:28:11,143][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 141, uuid: 8X9mF9gRSZ-DZhiKMS1iTA)
[2016-03-29 17:28:11,142][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,144][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [141], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,144][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 141
[2016-03-29 17:28:11,152][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 8ms done applying updated cluster_state (version: 141, uuid: 8X9mF9gRSZ-DZhiKMS1iTA)
[2016-03-29 17:28:11,157][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 141
[2016-03-29 17:28:11,162][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]: took 37ms done applying updated cluster_state (version: 141, uuid: 8X9mF9gRSZ-DZhiKMS1iTA)
[2016-03-29 17:28:11,185][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1]]: execute
[2016-03-29 17:28:11,206][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1]]: took 20ms no change in cluster_state
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create_snapshot [test-snap]]: execute
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [142], source [create_snapshot [test-snap]]
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [142]
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [142], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [142], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 142
[2016-03-29 17:28:11,924][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 142
[2016-03-29 17:28:11,924][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 142, uuid: lK95ctCGRsqCfCrr5wxNpA)
[2016-03-29 17:28:11,926][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 2ms done applying updated cluster_state (version: 142, uuid: lK95ctCGRsqCfCrr5wxNpA)
[2016-03-29 17:28:11,926][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 142
[2016-03-29 17:28:11,928][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create_snapshot [test-snap]]: took 4ms done applying updated cluster_state (version: 142, uuid: lK95ctCGRsqCfCrr5wxNpA)
[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update_snapshot [test-snap]]: execute
[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [143], source [update_snapshot [test-snap]]
[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [143]
[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [143], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [143], source [local-disco-receive(from master)]
[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 143
[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 143
[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 143, uuid: VK3ffK9YRBya2UfesAUiDg)
[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 143, uuid: VK3ffK9YRBya2UfesAUiDg)
[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 143
[2016-03-29 17:28:11,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update_snapshot [test-snap]]: took 2ms done applying updated cluster_state (version: 143, uuid: VK3ffK9YRBya2UfesAUiDg)
[2016-03-29 17:28:11,935][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute
[2016-03-29 17:28:12,207][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 272ms no change in cluster_state
[2016-03-29 17:28:12,207][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [144], source [update snapshot state]
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [144]
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [144], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [144], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 144
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 144
[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 144, uuid: QTPZSYPeRkmh5zX92WLGvQ)
[2016-03-29 17:28:12,210][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 144
[2016-03-29 17:28:12,210][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 144, uuid: QTPZSYPeRkmh5zX92WLGvQ)
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 3ms done applying updated cluster_state (version: 144, uuid: QTPZSYPeRkmh5zX92WLGvQ)
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove snapshot metadata]: execute
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [145], source [remove snapshot metadata]
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [145]
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [145], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [145], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 145
[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 145
[2016-03-29 17:28:12,213][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 145, uuid: 7TsUjeS6QVWeB08-jZ86FA)
[2016-03-29 17:28:12,213][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 145, uuid: 7TsUjeS6QVWeB08-jZ86FA)
[2016-03-29 17:28:12,213][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 145
[2016-03-29 17:28:12,214][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove snapshot metadata]: took 1ms done applying updated cluster_state (version: 145, uuid: 7TsUjeS6QVWeB08-jZ86FA)
[2016-03-29 17:28:12,214][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [close-indices [test-idx]]: execute
[2016-03-29 17:28:12,214][INFO ][org.elasticsearch.cluster.metadata] [node_s0] closing indices [[test-idx]]
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [146], source [close-indices [test-idx]]
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [146]
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [146], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 146
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [146], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 146
[2016-03-29 17:28:12,216][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 146, uuid: rpKSK5acQEa--KGz87l21g)
[2016-03-29 17:28:12,328][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 146
[2016-03-29 17:28:12,328][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 112ms done applying updated cluster_state (version: 146, uuid: rpKSK5acQEa--KGz87l21g)
[2016-03-29 17:28:12,370][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [close-indices [test-idx]]: took 155ms done applying updated cluster_state (version: 146, uuid: rpKSK5acQEa--KGz87l21g)
[2016-03-29 17:28:12,372][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [restore_snapshot[test-snap]]: execute
[2016-03-29 17:28:12,377][DEBUG][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] skipping rebalance due to in-flight shard/store fetches
[2016-03-29 17:28:12,377][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [147], source [restore_snapshot[test-snap]]
[2016-03-29 17:28:12,378][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [147]
[2016-03-29 17:28:12,381][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,378][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [147], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 147
[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [147], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 147, uuid: iwY7Qlj-Tc6V6m8bq9zGlw)
[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 147
[2016-03-29 17:28:12,388][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 6ms done applying updated cluster_state (version: 147, uuid: iwY7Qlj-Tc6V6m8bq9zGlw)
[2016-03-29 17:28:12,388][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 147
[2016-03-29 17:28:12,393][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [restore_snapshot[test-snap]]: took 20ms done applying updated cluster_state (version: 147, uuid: iwY7Qlj-Tc6V6m8bq9zGlw)
[2016-03-29 17:28:12,393][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_reroute(async_shard_fetch)]: execute
[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [148], source [cluster_reroute(async_shard_fetch)]
[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [148]
[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [148], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 148
[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,397][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 148, uuid: UO-y2AtgQkWvXqtLGT2J3A)
[2016-03-29 17:28:12,397][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [148], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,397][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 148
[2016-03-29 17:28:12,429][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 31ms done applying updated cluster_state (version: 148, uuid: UO-y2AtgQkWvXqtLGT2J3A)
[2016-03-29 17:28:12,429][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 148
[2016-03-29 17:28:12,460][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 4 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,460][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard started for [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,464][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 2 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,464][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard started for [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,472][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_reroute(async_shard_fetch)]: took 78ms done applying updated cluster_state (version: 148, uuid: UO-y2AtgQkWvXqtLGT2J3A)
[2016-03-29 17:28:12,473][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: execute
[2016-03-29 17:28:12,474][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [149], source [shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]
[2016-03-29 17:28:12,474][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [149]
[2016-03-29 17:28:12,474][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [149], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [149], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 149
[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 149
[2016-03-29 17:28:12,476][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 149, uuid: 9of1pkgRTRqBW2CQL6sH6w)
[2016-03-29 17:28:12,484][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 9ms done applying updated cluster_state (version: 149, uuid: 9of1pkgRTRqBW2CQL6sH6w)
[2016-03-29 17:28:12,484][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 149
[2016-03-29 17:28:12,490][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: took 17ms done applying updated cluster_state (version: 149, uuid: 9of1pkgRTRqBW2CQL6sH6w)
[2016-03-29 17:28:12,491][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute
[2016-03-29 17:28:12,533][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 5 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,534][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard started for [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,538][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,538][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,559][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 6 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,560][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard started for [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,588][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 3 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,589][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard started for [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,593][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 102ms no change in cluster_state
[2016-03-29 17:28:12,594][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: execute
[2016-03-29 17:28:12,594][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,594][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]
[2016-03-29 17:28:12,595][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [150], source [shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]
[2016-03-29 17:28:12,596][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [150]
[2016-03-29 17:28:12,596][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,596][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [150], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [150], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 150
[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 150
[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 150, uuid: CAC7dwrsQoS7i31fkflPrQ)
[2016-03-29 17:28:12,599][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]
[2016-03-29 17:28:12,599][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]
[2016-03-29 17:28:12,605][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 8ms done applying updated cluster_state (version: 150, uuid: CAC7dwrsQoS7i31fkflPrQ)
[2016-03-29 17:28:12,606][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 150
[2016-03-29 17:28:12,621][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: took 27ms done applying updated cluster_state (version: 150, uuid: CAC7dwrsQoS7i31fkflPrQ)
[2016-03-29 17:28:12,621][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute
[2016-03-29 17:28:12,622][INFO ][org.elasticsearch.cluster.routing.allocation] [node_s0] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test-idx][0], [test-idx][0]] ...]).
[2016-03-29 17:28:12,622][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [151], source [shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]
[2016-03-29 17:28:12,622][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [151]
[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [151], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 151
[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [151], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 151
[2016-03-29 17:28:12,624][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 151, uuid: _Bnqp7cQTHGqCa4GrCDnTQ)
[2016-03-29 17:28:12,634][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 11ms done applying updated cluster_state (version: 151, uuid: _Bnqp7cQTHGqCa4GrCDnTQ)
[2016-03-29 17:28:12,634][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 151
[2016-03-29 17:28:12,634][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,642][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:12,642][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 21ms done applying updated cluster_state (version: 151, uuid: _Bnqp7cQTHGqCa4GrCDnTQ)
[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute
[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 0s no change in cluster_state
[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute
[2016-03-29 17:28:12,649][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 6ms no change in cluster_state
[2016-03-29 17:28:12,650][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,653][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 9ms no change in cluster_state
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [152], source [update snapshot state]
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [152]
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [152], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 152
[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 152, uuid: 9sISmQFaRJaZ-2wn3iYUiw)
[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: took 7ms no change in cluster_state
[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [152], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 152
[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 152, uuid: 9sISmQFaRJaZ-2wn3iYUiw)
[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 152
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 5ms done applying updated cluster_state (version: 152, uuid: 9sISmQFaRJaZ-2wn3iYUiw)
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute
[2016-03-29 17:28:12,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 0s no change in cluster_state
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete-index [test-idx]]: execute
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] deleting index
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [153], source [delete-index [test-idx]]
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [153]
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [153], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 153
[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,677][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 153, uuid: bVkafU97RwqzjXlMmO6P5g)
[2016-03-29 17:28:12,677][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [153], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,677][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 153
[2016-03-29 17:28:12,834][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 157ms done applying updated cluster_state (version: 153, uuid: bVkafU97RwqzjXlMmO6P5g)
[2016-03-29 17:28:12,835][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 153
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete-index [test-idx]]: took 246ms done applying updated cluster_state (version: 153, uuid: bVkafU97RwqzjXlMmO6P5g)
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove-index-template [random_index_template]]: execute
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [154], source [remove-index-template [random_index_template]]
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [154]
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [154], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 154
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 154, uuid: U-04imVpRSKK49cI6glpaw)
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [154], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 154
[2016-03-29 17:28:12,929][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 154, uuid: U-04imVpRSKK49cI6glpaw)
[2016-03-29 17:28:12,929][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 154
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove-index-template [random_index_template]]: took 10ms done applying updated cluster_state (version: 154, uuid: U-04imVpRSKK49cI6glpaw)
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: execute
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [155], source [delete_repository [*]]
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [155]
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [155], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [155], source [local-disco-receive(from master)]
[2016-03-29 17:28:12,935][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 155
[2016-03-29 17:28:12,935][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 155, uuid: M7mgktV_QzKi9SjrJcZtuA)
[2016-03-29 17:28:12,935][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 155
[2016-03-29 17:28:12,939][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 155, uuid: M7mgktV_QzKi9SjrJcZtuA)
[2016-03-29 17:28:12,939][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 155
[2016-03-29 17:28:12,944][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: took 10ms done applying updated cluster_state (version: 155, uuid: M7mgktV_QzKi9SjrJcZtuA)
[2016-03-29 17:28:17,729][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo][test-snap] failed to restore snapshot
SnapshotRestoreException[[test-repo:test-snap] indices [test-idx-2] and [test-idx-1] are renamed into the same index [same-name]]
	at org.elasticsearch.snapshots.RestoreService.renamedIndices(RestoreService.java:694)
	at org.elasticsearch.snapshots.RestoreService.restoreSnapshot(RestoreService.java:209)
	at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:82)
	at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:41)
	at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)
	at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:17,733][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo][test-snap] failed to restore snapshot
SnapshotRestoreException[[test-repo:test-snap] indices [test-idx-2] and [test-idx-1] are renamed into the same index [test-idx-1]]
	at org.elasticsearch.snapshots.RestoreService.renamedIndices(RestoreService.java:694)
	at org.elasticsearch.snapshots.RestoreService.restoreSnapshot(RestoreService.java:209)
	at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:82)
	at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:41)
	at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)
	at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:17,773][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot
[__WRONG__] InvalidIndexNameException[Invalid index name [__WRONG__], must not start with '_']
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:152)
	at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:253)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:17,777][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot
[alias-3] InvalidIndexNameException[Invalid index name [alias-3], already exists as alias]
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:170)
	at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:253)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:17,780][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot
SnapshotRestoreException[[test-repo:test-snap] cannot rename index [test-idx-1] into [alias-1] because of conflict with an alias with the same name]
	at org.elasticsearch.snapshots.RestoreService$1.checkAliasNameConflicts(RestoreService.java:336)
	at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:314)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:17,784][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot
SnapshotRestoreException[[test-repo:test-snap] cannot rename index [test-idx-1] into [alias-2] because of conflict with an alias with the same name]
	at org.elasticsearch.snapshots.RestoreService$1.checkAliasNameConflicts(RestoreService.java:336)
	at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:314)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:19,555][WARN ][org.elasticsearch.repositories.fs] [node_s0] cannot read snapshot file [test-repo:test-snap-1]
java.lang.IllegalStateException: class org.apache.lucene.store.BufferedChecksumIndexInput cannot seek backwards (pos=-10 getFilePointer()=0)
	at org.apache.lucene.store.ChecksumIndexInput.seek(ChecksumIndexInput.java:50)
	at org.apache.lucene.codecs.CodecUtil.checksumEntireFile(CodecUtil.java:448)
	at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:106)
	at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshot(BlobStoreRepository.java:438)
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.deleteSnapshot(BlobStoreRepository.java:298)
	at org.elasticsearch.snapshots.SnapshotsService$8.run(SnapshotsService.java:1009)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:21,320][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][5]] [test-repo:test-snap] failed to create snapshot
[test-idx][[test-idx][5]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)
	at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)
	at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)
	at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)
	... 8 more
[2016-03-29 17:28:21,324][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][2]] [test-repo:test-snap] failed to create snapshot
[test-idx][[test-idx][2]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)
	at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)
	at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)
	at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)
	... 8 more
[2016-03-29 17:28:21,325][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][4]] [test-repo:test-snap] failed to create snapshot
[test-idx][[test-idx][4]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)
	at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)
	at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)
	at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)
	... 8 more
[2016-03-29 17:28:21,328][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][3]] [test-repo:test-snap] failed to create snapshot
[test-idx][[test-idx][3]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)
	at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)
	at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)
	at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)
	... 8 more
[2016-03-29 17:28:21,331][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][0]] [test-repo:test-snap] failed to create snapshot
[test-idx][[test-idx][0]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)
	at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)
	at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)
	at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)
	... 8 more
[2016-03-29 17:28:21,339][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][1]] [test-repo:test-snap] failed to create snapshot
[test-idx][[test-idx][1]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)
	at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)
	at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)
	at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)
	... 8 more
[2016-03-29 17:28:27,097][WARN ][org.elasticsearch.repositories] [node_s0] failed to create repository [test-repo]
java.lang.IllegalStateException: trying to modify or unregister repository that is currently used 
	at org.elasticsearch.repositories.RepositoriesService.ensureRepositoryNotInUse(RepositoriesService.java:421)
	at org.elasticsearch.repositories.RepositoriesService.access$000(RepositoriesService.java:60)
	at org.elasticsearch.repositories.RepositoriesService$1.execute(RepositoriesService.java:113)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:28,735][WARN ][org.elasticsearch.snapshots] [node_s0] failed to get snapshot [test-repo:test-snap-2]
java.lang.IllegalStateException: class org.apache.lucene.store.BufferedChecksumIndexInput cannot seek backwards (pos=-12 getFilePointer()=0)
	at org.apache.lucene.store.ChecksumIndexInput.seek(ChecksumIndexInput.java:50)
	at org.apache.lucene.codecs.CodecUtil.checksumEntireFile(CodecUtil.java:448)
	at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:106)
	at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshot(BlobStoreRepository.java:438)
	at org.elasticsearch.snapshots.SnapshotsService.snapshots(SnapshotsService.java:153)
	at org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.masterOperation(TransportGetSnapshotsAction.java:80)
	at org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.masterOperation(TransportGetSnapshotsAction.java:49)
	at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)
	at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:41,127][WARN ][org.elasticsearch.snapshots] [node_s0] failed to create snapshot [test-repo:test-snap]
SnapshotCreationException[[test-repo:test-snap] failed to create snapshot]; nested: IOException[Random IOException];
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:283)
	at org.elasticsearch.snapshots.mockstore.MockRepository.initializeSnapshot(MockRepository.java:147)
	at org.elasticsearch.snapshots.SnapshotsService.beginSnapshot(SnapshotsService.java:309)
	at org.elasticsearch.snapshots.SnapshotsService.access$600(SnapshotsService.java:95)
	at org.elasticsearch.snapshots.SnapshotsService$1$1.run(SnapshotsService.java:231)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:293)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:357)
	at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.writeBlob(ChecksumBlobStoreFormat.java:182)
	at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.write(ChecksumBlobStoreFormat.java:154)
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:275)
	... 7 more
[2016-03-29 17:28:43,118][WARN ][org.elasticsearch.snapshots] [node_s0] failed to create snapshot [readonly-repo:test-snap-2]
RepositoryException[[readonly-repo] cannot create snapshot in a readonly repository]
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:267)
	at org.elasticsearch.snapshots.SnapshotsService.beginSnapshot(SnapshotsService.java:309)
	at org.elasticsearch.snapshots.SnapshotsService.access$600(SnapshotsService.java:95)
	at org.elasticsearch.snapshots.SnapshotsService$1$1.run(SnapshotsService.java:231)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:28:44,770][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,783][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=E7tXHvYuQe2IjirhNpwCMw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-03-29T21:28:44.684Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,819][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,832][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Tu2o-TxURruH1W98WMmf6w], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-03-29T21:28:44.684Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,884][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,896][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=gGjbWo3GQbeTSOWNS0L5ZQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.787Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,959][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,962][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=QA-y37LTRbWRKiTDFlyKyA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.907Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,977][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,979][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2vhs67oeT-SeCfGvDtXVCw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.841Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,980][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,980][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2vhs67oeT-SeCfGvDtXVCw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.841Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:44,985][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WTgyRZpuR3yKllT4jY4oEw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.963Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:44,991][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WTgyRZpuR3yKllT4jY4oEw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.963Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:44,999][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2vhs67oeT-SeCfGvDtXVCw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.841Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,026][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,032][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=s3Zy87LiRXm8_Hb9U8WFPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,035][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=s3Zy87LiRXm8_Hb9U8WFPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,038][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,039][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ZSckgv_NST-FlJjq6CX8bA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,040][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ZSckgv_NST-FlJjq6CX8bA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,083][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,085][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Hz5FAdLhRqmEQG-Yx5MmeQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.036Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,136][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,153][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=-_XaUSUWSpaeugwmeygucQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.042Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,204][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,208][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=uUmSQj2EQZ2yQJHwqyHJoA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.092Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,257][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,258][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=FvZrfk8GSAmOWDIlMEqPXA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.170Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,272][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,273][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=iIIF35OQQN-uAS0yG3MaDA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.219Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,308][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=iIIF35OQQN-uAS0yG3MaDA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.219Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,336][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,350][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=0P27PVX8R_ylIHvomD0yAg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.266Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,355][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,359][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pS3S1NwvS2C3xYryD4XDbQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.310Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,363][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pS3S1NwvS2C3xYryD4XDbQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.310Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,372][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pS3S1NwvS2C3xYryD4XDbQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.310Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,385][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,387][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=uOuHgA35TtSELYl0S_I7Eg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.355Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,410][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=uOuHgA35TtSELYl0S_I7Eg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.355Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,417][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,418][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l_ogvAiLRg-S50-5pj8pNA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.380Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,440][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l_ogvAiLRg-S50-5pj8pNA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.380Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,444][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,448][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=k-KYtiQgRnqjJeAAqDDMoA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,452][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=k-KYtiQgRnqjJeAAqDDMoA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]
[2016-03-29 17:28:45,481][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,482][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[21], restoring[test-repo:test-snap], s[INITIALIZING], a[id=z13YA4MaQYGCBMzfhyn14g], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.454Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,513][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,518][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[23], restoring[test-repo:test-snap], s[INITIALIZING], a[id=NHpb3CzdQNeJi7w_TVtiQg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.484Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,613][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,614][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=oonwWq-HSFqKhLOwMWfF7A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.521Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,735][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:45,738][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[27], restoring[test-repo:test-snap], s[INITIALIZING], a[id=YnZfFYQcRZOyxo-geJUGcQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.614Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]
[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)
	at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)
	at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)
	... 7 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)
	at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)
	... 10 more
Caused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)
	... 11 more
Caused by: java.io.IOException: Random IOException
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)
	at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)
	at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)
	at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)
	... 12 more
[2016-03-29 17:28:49,287][WARN ][org.elasticsearch.repositories.fs] [node_s0] cannot read metadata for snapshot [test-repo:test-snap-1]
SnapshotMissingException[[test-repo:test-snap-1] is missing]; nested: NoSuchFileException[/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT_4AA6DECDBC490785-001/tempDir-001/repos/GhiXNtcjWT/meta-test-snap-1.dat];
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshotMetaData(BlobStoreRepository.java:470)
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.deleteSnapshot(BlobStoreRepository.java:308)
	at org.elasticsearch.snapshots.SnapshotsService$8.run(SnapshotsService.java:1009)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.file.NoSuchFileException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT_4AA6DECDBC490785-001/tempDir-001/repos/GhiXNtcjWT/meta-test-snap-1.dat
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)
	at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)
	at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)
	at org.apache.lucene.mockfile.HandleTrackingFS.newInputStream(HandleTrackingFS.java:93)
	at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)
	at org.apache.lucene.mockfile.HandleTrackingFS.newInputStream(HandleTrackingFS.java:93)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.elasticsearch.common.blobstore.fs.FsBlobContainer.readBlob(FsBlobContainer.java:93)
	at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:100)
	at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)
	at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshotMetaData(BlobStoreRepository.java:468)
	... 5 more
[2016-03-29 17:29:23,943][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot
SnapshotRestoreException[[test-repo:test-snap] cannot modify setting [index.number_of_shards] on restore]
	at org.elasticsearch.snapshots.RestoreService$1.updateIndexSettings(RestoreService.java:416)
	at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:241)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-03-29 17:29:23,947][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot
java.lang.IllegalArgumentException: must specify non-negative number of shards for index [test-idx]
	at org.elasticsearch.cluster.metadata.IndexMetaData$Builder.build(IndexMetaData.java:753)
	at org.elasticsearch.snapshots.RestoreService$1.updateIndexSettings(RestoreService.java:422)
	at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:241)
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
]]></system-out>
   <system-err><![CDATA[]]></system-err>
</testsuite>