[
 "BOOTSTRAP",
 {
  "defaultCharset": "UTF-8",
  "pidString": "97863@host37-163.aruba.fit.edu",
  "systemProperties": {
   "awt.toolkit": "sun.lwawt.macosx.LWCToolkit",
   "es.logger.level": "WARN",
   "file.encoding": "UTF-8",
   "file.encoding.pkg": "sun.io",
   "file.separator": "/",
   "ftp.nonProxyHosts": "local|*.local|169.254/16|*.169.254/16",
   "gopherProxySet": "false",
   "http.nonProxyHosts": "local|*.local|169.254/16|*.169.254/16",
   "java.awt.graphicsenv": "sun.awt.CGraphicsEnvironment",
   "java.awt.headless": "true",
   "java.awt.printerjob": "sun.lwawt.macosx.CPrinterJob",
   "java.class.path": "/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/classes/test:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/resources/test:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/classes/main:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/resources/main:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-core/5.5.0-snapshot-1721183/f6854c65c7f4c6d9de583f4daa4fd3ae8a3800f1/lucene-core-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-analyzers-common/5.5.0-snapshot-1721183/69e187ef1d2d9c9570363eb4186821e0341df5b8/lucene-analyzers-common-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-backward-codecs/5.5.0-snapshot-1721183/fa00a45ff9bc6a4df44db81f2e4e44ea94bf88e/lucene-backward-codecs-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-grouping/5.5.0-snapshot-1721183/e996e6c723eb415ba2cfa7f5e98bbf194a4918dd/lucene-grouping-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-highlighter/5.5.0-snapshot-1721183/3b7a5d97b10885f16eb53deb15d64c942b9f9fdb/lucene-highlighter-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-join/5.5.0-snapshot-1721183/e4dda3eeb76e340aa4713a3b20d68c4a1504e505/lucene-join-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-memory/5.5.0-snapshot-1721183/800442a5d7612ce4c8748831871b4d436a50554e/lucene-memory-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-misc/5.5.0-snapshot-1721183/bdf184de9b5773c7af3ae908af78eeb1e512470c/lucene-misc-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queries/5.5.0-snapshot-1721183/fc59de52bd2c7e420edfd235723cb8b0dd44e92d/lucene-queries-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queryparser/5.5.0-snapshot-1721183/1d341e6a4f11f3170773ccffdbe6815b45967e3d/lucene-queryparser-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-sandbox/5.5.0-snapshot-1721183/a1b02c2b595ac92f45f0d2be03841a3a7fcae1f1/lucene-sandbox-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial/5.5.0-snapshot-1721183/e3ea422b56734329fb6974e9cf9f66478adb5793/lucene-spatial-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial3d/5.5.0-snapshot-1721183/5eadbd4e63120b59ab6445e39489205f98420471/lucene-spatial3d-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-suggest/5.5.0-snapshot-1721183/a336287e65d082535f02a8427666dbe46b1b9b74/lucene-suggest-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securesm/1.0/c0c6cf986ba0057390bfcc80c366a0e3157f944b/securesm-1.0.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.3.1/1303efbc4b181e5a58bf2e967dc156a3132b97c0/commons-cli-1.3.1.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch/hppc/0.7.1/8b5057f74ea378c0150a1860874a3ebdcb713767/hppc-0.7.1.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.8.2/d27c24204c5e507b16fec01006b3d0f1ec42aed4/joda-time-2.8.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.joda/joda-convert/1.2/35ec554f0cd00c956cc69051514d9488b1374dec/joda-convert-1.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.2/123f29333b2c6b3516b14252b6e93226bfcd6e37/jackson-core-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-smile/2.6.2/395d18c1a1dd730b8026ee59c4067e5d2b45ba6e/jackson-dataformat-smile-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-yaml/2.6.2/4ae23088dd3fae47c66843f2e4251d7255ee140e/jackson-dataformat-yaml-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-cbor/2.6.2/1e13c575f914c83761bb8e2aca7dfd9e4c647579/jackson-dataformat-cbor-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.10.5.Final/9ca7d55d246092bddd29b867706e2f6c7db701a0/netty-3.10.5.Final.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.tdunning/t-digest/3.0/84ccf145ac2215e6bfa63baa3101c0af41017cfc/t-digest-3.0.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.hdrhistogram/HdrHistogram/2.1.6/7495feb7f71ee124bd2a7e7d83590e296d71d80e/HdrHistogram-2.1.6.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.spatial4j/spatial4j/0.5/6e16edaf6b1ba76db7f08c2f3723fce3b358ecc3/spatial4j-0.5.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.vividsolutions/jts/1.13/3ccfb9b60f04d71add996a666ceb8902904fd805/jts-1.13.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/log4j/apache-log4j-extras/1.2.17/85863614d82185d7e51fe21c00aa9117a523a8b6/apache-log4j-extras-1.2.17.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.2/8619e95939167fb37245b5670135e4feb0ec7d50/slf4j-api-1.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/net.java.dev.jna/jna/4.1.0/1c12d070e602efd8021891cdd7fd18bc129372d4/jna-4.1.0.jar:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/test/framework/build/libs/framework-3.0.0-SNAPSHOT.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/randomizedtesting-runner/2.3.2/307965917fe8a22b7ee72deba39ef4b8e6ebc069/randomizedtesting-runner-2.3.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-test-framework/5.5.0-snapshot-1721183/a8d851d0ad82182b3a02f4b30c336e7aa0e173cb/lucene-test-framework-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-codecs/5.5.0-snapshot-1721183/8aa59442b028c7a2c1a516accb6142a8910ba5fc/lucene-codecs-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.3.6/4c47155e3e6c9a41a28db36680b828ced53b8af4/httpclient-4.3.6.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.3.3/f91b7a4aadc5cf486df6e4634748d7dd7a73f06d/httpcore-4.3.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.3/f6f66e966c70a83ffbdb6f17a0919eaf7c8aca7f/commons-logging-1.1.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.10/4b95f4897fa13f2cd904aee711aeafc0c5295cd8/commons-codec-1.10.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securemock/1.2/98201d4ad5ac93f6b415ae9172d52b5e7cda490e/securemock-1.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/junit4-ant/2.3.2/dc8f03f6111974092491f35b8269eb0fc57f52f7/junit4-ant-2.3.2.jar",
   "java.class.version": "52.0",
   "java.endorsed.dirs": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/endorsed",
   "java.ext.dirs": "/Users/ogbonnayacngwu/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java",
   "java.home": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre",
   "java.io.tmpdir": "./temp",
   "java.library.path": "/Users/ogbonnayacngwu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.",
   "java.runtime.name": "Java(TM) SE Runtime Environment",
   "java.runtime.version": "1.8.0_11-b12",
   "java.specification.name": "Java Platform API Specification",
   "java.specification.vendor": "Oracle Corporation",
   "java.specification.version": "1.8",
   "java.vendor": "Oracle Corporation",
   "java.vendor.url": "http://java.oracle.com/",
   "java.vendor.url.bug": "http://bugreport.sun.com/bugreport/",
   "java.version": "1.8.0_11",
   "java.vm.info": "mixed mode",
   "java.vm.name": "Java HotSpot(TM) 64-Bit Server VM",
   "java.vm.specification.name": "Java Virtual Machine Specification",
   "java.vm.specification.vendor": "Oracle Corporation",
   "java.vm.specification.version": "1.8",
   "java.vm.vendor": "Oracle Corporation",
   "java.vm.version": "25.11-b03",
   "junit4.childvm.count": "4",
   "junit4.childvm.cwd": "/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1",
   "junit4.childvm.id": "1",
   "junit4.memory.total": "514850816",
   "junit4.pidString": "97863@host37-163.aruba.fit.edu",
   "junit4.processors": "8",
   "line.separator": "\n",
   "os.arch": "x86_64",
   "os.name": "Mac OS X",
   "os.version": "10.11.2",
   "path.separator": ":",
   "socksNonProxyHosts": "local|*.local|169.254/16|*.169.254/16",
   "sun.arch.data.model": "64",
   "sun.boot.class.path": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/classes",
   "sun.boot.library.path": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib",
   "sun.cpu.endian": "little",
   "sun.cpu.isalist": "",
   "sun.io.unicode.encoding": "UnicodeBig",
   "sun.java.command": "com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe -eventsfile /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160125_124232_660.events @/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160125_124232_660.suites -stdin",
   "sun.java.launcher": "SUN_STANDARD",
   "sun.jnu.encoding": "UTF-8",
   "sun.management.compiler": "HotSpot 64-Bit Tiered Compilers",
   "sun.os.patch.level": "unknown",
   "tests.artifact": "core",
   "tests.ifNoTests": "fail",
   "tests.maven": "true",
   "tests.prefix": "tests",
   "tests.security.manager": "true",
   "tests.seed": "DEE1149085A36D88",
   "tests.task": ":core:integTest",
   "user.country": "US",
   "user.dir": "/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1",
   "user.home": "/Users/ogbonnayacngwu",
   "user.language": "en",
   "user.name": "ogbonnayacngwu",
   "user.timezone": "America/New_York"
  }
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.termvectors.GetTermVectorsIT",
   "displayName": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
   "methodName": null,
   "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
   "children": [
    {
     "id": "ID#testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testFilterDocFreq",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testPerFieldAnalyzer",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testArtificialVsExisting",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testSimpleTermVectors",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testRandomSingleTermVectors",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testFilterTermFreq",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testSimpleWildCards",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testArtificialNoDoc",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testDfs",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testArtificialNonExistingField",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testNoSuchDoc",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testFilterLength",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testSimpleTermVectorsWithGenerate",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testExistingFieldWithNoTermVectorsNoNPE",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testTermVectorsWithVersion",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testNotIndexedField",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testRandomPayloadWithDelimitedPayloadTokenFilter",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testExistingFieldButNotInDocNPE",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testDuelESLucene",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testDuelWithAndWithoutTermVectors",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743753429
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:42:33,737][WARN ][org.elasticsearch.bootstrap] Unable to lock JVM Memory: error=78,reason=Function not implemented%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:42:33,738][WARN ][org.elasticsearch.bootstrap] This can result in part of the JVM being swapped out.%0A"
 }
]

[
 "TEST_STARTED",
 "ID#testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743756268,
  "executionTime": 13486
 }
]

[
 "TEST_STARTED",
 "ID#testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743769755,
  "executionTime": 342
 }
]

[
 "TEST_STARTED",
 "ID#testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743770098,
  "executionTime": 911
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743771009,
  "executionTime": 968
 }
]

[
 "TEST_STARTED",
 "ID#testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743771977,
  "executionTime": 887
 }
]

[
 "TEST_STARTED",
 "ID#testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743772864,
  "executionTime": 231
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743773095,
  "executionTime": 252
 }
]

[
 "TEST_STARTED",
 "ID#testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743773347,
  "executionTime": 225
 }
]

[
 "TEST_STARTED",
 "ID#testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743773572,
  "executionTime": 1142
 }
]

[
 "TEST_STARTED",
 "ID#testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743774715,
  "executionTime": 268
 }
]

[
 "TEST_STARTED",
 "ID#testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743774983,
  "executionTime": 145
 }
]

[
 "TEST_STARTED",
 "ID#testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743775129,
  "executionTime": 297
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743775426,
  "executionTime": 665
 }
]

[
 "TEST_STARTED",
 "ID#testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743776091,
  "executionTime": 155
 }
]

[
 "TEST_STARTED",
 "ID#testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743776247,
  "executionTime": 448
 }
]

[
 "TEST_STARTED",
 "ID#testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743776695,
  "executionTime": 254
 }
]

[
 "TEST_STARTED",
 "ID#testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743776949,
  "executionTime": 142
 }
]

[
 "TEST_STARTED",
 "ID#testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743777091,
  "executionTime": 449
 }
]

[
 "TEST_STARTED",
 "ID#testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743777541,
  "executionTime": 224
 }
]

[
 "TEST_STARTED",
 "ID#testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1453743777766,
  "executionTime": 566
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.termvectors.GetTermVectorsIT",
  "startTimestamp": 1453743753429,
  "executionTime": 24970
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.client.node.NodeClientIT",
   "displayName": "org.elasticsearch.client.node.NodeClientIT",
   "methodName": null,
   "className": "org.elasticsearch.client.node.NodeClientIT",
   "children": [
    {
     "id": "ID#testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)",
     "displayName": "testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)",
     "methodName": "testThatClientTypeSettingCannotBeChanged",
     "className": "org.elasticsearch.client.node.NodeClientIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743778411
 }
]

[
 "TEST_STARTED",
 "ID#testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)",
  "startTimestamp": 1453743778497,
  "executionTime": 631
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.client.node.NodeClientIT",
  "startTimestamp": 1453743778411,
  "executionTime": 792
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
   "displayName": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
   "methodName": null,
   "className": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
   "children": [
    {
     "id": "ID#testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "displayName": "testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "methodName": "testRestoreOldSnapshots",
     "className": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
     "children": []
    },
    {
     "id": "ID#testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "displayName": "testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "methodName": "testRestoreUnsupportedSnapshots",
     "className": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743779222
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:01,897][WARN ][org.elasticsearch.bwcompat] Old repositories tests contain extra repo: 2.0.0-beta1%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
  "startTimestamp": 1453743779257,
  "executionTime": 2754
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,575][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0.beta2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0.beta2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0.beta2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,658][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,659][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,691][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,694][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.5.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.5.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.5.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,747][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,801][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,801][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.6] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.6] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.6] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,856][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,856][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.5] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,920][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,920][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.4] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,976][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:02,977][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.5.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.5.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.5.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,023][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0.rc2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0.rc2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0.rc2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,089][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,089][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.7] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.7] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.7] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,141][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,141][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.1.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.1.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.1.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,191][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,191][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.6.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.6.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.6.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,241][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,241][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,294][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,294][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.6.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.6.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.6.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,379][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,379][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.9] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.9] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.9] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,404][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,404][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,428][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,429][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,520][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,573][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,573][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,615][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,615][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.8] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.8] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.8] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,653][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,654][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,682][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,682][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,707][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,707][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.1.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.1.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.1.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,738][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,762][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,762][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,793][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,793][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,826][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-0.20.6-and-1.1.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-0.20.6-and-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-0.20.6-and-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,854][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,854][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,877][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,877][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.5.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.5.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.5.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,912][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,938][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,938][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,961][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,961][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.6.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.6.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.6.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,987][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:03,987][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.4] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,021][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,021][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,045][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,045][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,079][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,079][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.1.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,103][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,103][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.4] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,136][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0.rc1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0.rc1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0.rc1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,165][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,165][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.5] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,189][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,190][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,222][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,223][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,248][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,248][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.0.beta1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.0.beta1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.0.beta1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,273][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:04,273][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
  "startTimestamp": 1453743782012,
  "executionTime": 2373
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
  "startTimestamp": 1453743779222,
  "executionTime": 5181
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.recovery.SimpleRecoveryIT",
   "displayName": "org.elasticsearch.recovery.SimpleRecoveryIT",
   "methodName": null,
   "className": "org.elasticsearch.recovery.SimpleRecoveryIT",
   "children": [
    {
     "id": "ID#testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)",
     "displayName": "testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)",
     "methodName": "testSimpleRecovery",
     "className": "org.elasticsearch.recovery.SimpleRecoveryIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743784412
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)",
  "startTimestamp": 1453743784454,
  "executionTime": 2180
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:06,657][WARN ][org.elasticsearch.transport] [node_s1] Transport response handler not found of id [61]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.recovery.SimpleRecoveryIT",
  "startTimestamp": 1453743784412,
  "executionTime": 2269
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.state.SimpleIndexStateIT",
   "displayName": "org.elasticsearch.indices.state.SimpleIndexStateIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
   "children": [
    {
     "id": "ID#testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "displayName": "testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "methodName": "testFastCloseAfterCreateContinuesCreateAfterOpen",
     "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
     "children": []
    },
    {
     "id": "ID#testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "displayName": "testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "methodName": "testConsistencyAfterIndexCreationFailure",
     "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
     "children": []
    },
    {
     "id": "ID#testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "displayName": "testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "methodName": "testSimpleOpenClose",
     "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743786690
 }
]

[
 "TEST_STARTED",
 "ID#testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)",
  "startTimestamp": 1453743786707,
  "executionTime": 3105
 }
]

[
 "TEST_STARTED",
 "ID#testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)",
  "startTimestamp": 1453743789812,
  "executionTime": 146
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:11,630][WARN ][org.elasticsearch.action.index] [node_s2] unexpected error during the primary phase for action [indices:data/write/index], request [index {[test][type1][1], source[{\"field1\":\"value1\"}]}]%0A[test] IndexClosedException[closed]%0A%09at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:170)%0A%09at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:93)%0A%09at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteSingleIndex(IndexNameExpressionResolver.java:206)%0A%09at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:425)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:137)%0A%09at org.elasticsearch.action.index.TransportIndexAction.innerExecute(TransportIndexAction.java:133)%0A%09at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:117)%0A%09at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:64)%0A%09at org.elasticsearch.action.support.TransportAction.doExecute(TransportAction.java:113)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:101)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:65)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:57)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:86)%0A%09at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:60)%0A%09at org.elasticsearch.action.ActionRequestBuilder.get(ActionRequestBuilder.java:68)%0A%09at org.elasticsearch.indices.state.SimpleIndexStateIT.testSimpleOpenClose(SimpleIndexStateIT.java:76)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)",
  "startTimestamp": 1453743789959,
  "executionTime": 3505
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:13,478][WARN ][org.elasticsearch.test.transport] [node_s1] Transport response handler not found of id [161]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.state.SimpleIndexStateIT",
  "startTimestamp": 1453743786690,
  "executionTime": 6817
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.UpdateSettingsValidationIT",
   "displayName": "org.elasticsearch.cluster.UpdateSettingsValidationIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.UpdateSettingsValidationIT",
   "children": [
    {
     "id": "ID#testUpdateSettingsValidation(org.elasticsearch.cluster.UpdateSettingsValidationIT)",
     "displayName": "testUpdateSettingsValidation(org.elasticsearch.cluster.UpdateSettingsValidationIT)",
     "methodName": "testUpdateSettingsValidation",
     "className": "org.elasticsearch.cluster.UpdateSettingsValidationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743793515
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateSettingsValidation(org.elasticsearch.cluster.UpdateSettingsValidationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateSettingsValidation(org.elasticsearch.cluster.UpdateSettingsValidationIT)",
  "startTimestamp": 1453743793532,
  "executionTime": 505
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.UpdateSettingsValidationIT",
  "startTimestamp": 1453743793515,
  "executionTime": 534
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.query.ExistsIT",
   "displayName": "org.elasticsearch.search.query.ExistsIT",
   "methodName": null,
   "className": "org.elasticsearch.search.query.ExistsIT",
   "children": [
    {
     "id": "ID#testEmptyIndex(org.elasticsearch.search.query.ExistsIT)",
     "displayName": "testEmptyIndex(org.elasticsearch.search.query.ExistsIT)",
     "methodName": "testEmptyIndex",
     "className": "org.elasticsearch.search.query.ExistsIT",
     "children": []
    },
    {
     "id": "ID#testExists(org.elasticsearch.search.query.ExistsIT)",
     "displayName": "testExists(org.elasticsearch.search.query.ExistsIT)",
     "methodName": "testExists",
     "className": "org.elasticsearch.search.query.ExistsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743794056
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyIndex(org.elasticsearch.search.query.ExistsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyIndex(org.elasticsearch.search.query.ExistsIT)",
  "startTimestamp": 1453743794073,
  "executionTime": 743
 }
]

[
 "TEST_STARTED",
 "ID#testExists(org.elasticsearch.search.query.ExistsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExists(org.elasticsearch.search.query.ExistsIT)",
  "startTimestamp": 1453743794817,
  "executionTime": 1305
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.query.ExistsIT",
  "startTimestamp": 1453743794056,
  "executionTime": 2110
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.broadcast.BroadcastActionsIT",
   "displayName": "org.elasticsearch.broadcast.BroadcastActionsIT",
   "methodName": null,
   "className": "org.elasticsearch.broadcast.BroadcastActionsIT",
   "children": [
    {
     "id": "ID#testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)",
     "displayName": "testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)",
     "methodName": "testBroadcastOperations",
     "className": "org.elasticsearch.broadcast.BroadcastActionsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743796181
 }
]

[
 "TEST_STARTED",
 "ID#testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)",
  "startTimestamp": 1453743796204,
  "executionTime": 440
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.broadcast.BroadcastActionsIT",
  "startTimestamp": 1453743796181,
  "executionTime": 480
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.bulk.BulkProcessorIT",
   "displayName": "org.elasticsearch.action.bulk.BulkProcessorIT",
   "methodName": null,
   "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
   "children": [
    {
     "id": "ID#testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorConcurrentRequestsReadOnlyIndex",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorConcurrentRequestsNoNodeAvailableException",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorConcurrentRequests",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorWaitOnClose",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorFlush",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testThatBulkProcessorCountIsCorrect",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743796675
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1453743796692,
  "executionTime": 585
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:17,701][WARN ][org.elasticsearch.action.bulk] [Gladiator] Failed to execute bulk request 1.%0ANoNodeAvailableException[None of the configured nodes are available: []]%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:289)%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:206)%0A%09at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:62)%0A%09at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:283)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:464)%0A%09at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:209)%0A%09at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72)%0A%09at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:315)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:306)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:253)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.indexDocs(BulkProcessorIT.java:298)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.testBulkProcessorConcurrentRequestsNoNodeAvailableException(BulkProcessorIT.java:180)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:17,704][WARN ][org.elasticsearch.action.bulk] [Gladiator] Failed to execute bulk request 2.%0ANoNodeAvailableException[None of the configured nodes are available: []]%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:289)%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:206)%0A%09at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:62)%0A%09at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:283)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:464)%0A%09at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:209)%0A%09at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72)%0A%09at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:315)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:306)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:253)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.indexDocs(BulkProcessorIT.java:298)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.testBulkProcessorConcurrentRequestsNoNodeAvailableException(BulkProcessorIT.java:180)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:17,706][WARN ][org.elasticsearch.action.bulk] [Gladiator] Failed to execute bulk request 3.%0ANoNodeAvailableException[None of the configured nodes are available: []]%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:289)%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:206)%0A%09at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:62)%0A%09at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:283)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:464)%0A%09at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:209)%0A%09at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72)%0A%09at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:315)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.awaitClose(BulkProcessor.java:243)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.close(BulkProcessor.java:215)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.testBulkProcessorConcurrentRequestsNoNodeAvailableException(BulkProcessorIT.java:188)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1453743797277,
  "executionTime": 448
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1453743797725,
  "executionTime": 147
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1453743797873,
  "executionTime": 191
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1453743798064,
  "executionTime": 201
 }
]

[
 "TEST_STARTED",
 "ID#testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1453743798266,
  "executionTime": 84
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.bulk.BulkProcessorIT",
  "startTimestamp": 1453743796675,
  "executionTime": 1684
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.query.plugin.CustomQueryParserIT",
   "displayName": "org.elasticsearch.index.query.plugin.CustomQueryParserIT",
   "methodName": null,
   "className": "org.elasticsearch.index.query.plugin.CustomQueryParserIT",
   "children": [
    {
     "id": "ID#testBooleanParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "displayName": "testBooleanParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "methodName": "testBooleanParsesFilter",
     "className": "org.elasticsearch.index.query.plugin.CustomQueryParserIT",
     "children": []
    },
    {
     "id": "ID#testCustomDummyQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "displayName": "testCustomDummyQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "methodName": "testCustomDummyQuery",
     "className": "org.elasticsearch.index.query.plugin.CustomQueryParserIT",
     "children": []
    },
    {
     "id": "ID#testConstantScoreParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "displayName": "testConstantScoreParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "methodName": "testConstantScoreParsesFilter",
     "className": "org.elasticsearch.index.query.plugin.CustomQueryParserIT",
     "children": []
    },
    {
     "id": "ID#testCustomDummyQueryWithinBooleanQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "displayName": "testCustomDummyQueryWithinBooleanQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
     "methodName": "testCustomDummyQueryWithinBooleanQuery",
     "className": "org.elasticsearch.index.query.plugin.CustomQueryParserIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743798366
 }
]

[
 "TEST_STARTED",
 "ID#testBooleanParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBooleanParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
  "startTimestamp": 1453743798383,
  "executionTime": 542
 }
]

[
 "TEST_STARTED",
 "ID#testCustomDummyQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCustomDummyQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
  "startTimestamp": 1453743798925,
  "executionTime": 402
 }
]

[
 "TEST_STARTED",
 "ID#testConstantScoreParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testConstantScoreParsesFilter(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
  "startTimestamp": 1453743799327,
  "executionTime": 318
 }
]

[
 "TEST_STARTED",
 "ID#testCustomDummyQueryWithinBooleanQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCustomDummyQueryWithinBooleanQuery(org.elasticsearch.index.query.plugin.CustomQueryParserIT)",
  "startTimestamp": 1453743799645,
  "executionTime": 402
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.query.plugin.CustomQueryParserIT",
  "startTimestamp": 1453743798366,
  "executionTime": 1717
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.admin.indices.create.CreateIndexIT",
   "displayName": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
   "methodName": null,
   "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
   "children": [
    {
     "id": "ID#testCreationDateGenerated(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testCreationDateGenerated(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testCreationDateGenerated",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testCreateIndexWithBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testCreateIndexWithBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testCreateIndexWithBlocks",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testCreationDateGivenFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testCreationDateGivenFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testCreationDateGivenFails",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testInvalidShardCountSettingsWithoutPrefix(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testInvalidShardCountSettingsWithoutPrefix(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testInvalidShardCountSettingsWithoutPrefix",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testCreateAndDeleteIndexConcurrently(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testCreateAndDeleteIndexConcurrently(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testCreateAndDeleteIndexConcurrently",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testUnknownSettingFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testUnknownSettingFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testUnknownSettingFails",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testCreateIndexWithMetadataBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testCreateIndexWithMetadataBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testCreateIndexWithMetadataBlocks",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testRestartIndexCreationAfterFullClusterRestart(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testRestartIndexCreationAfterFullClusterRestart(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testRestartIndexCreationAfterFullClusterRestart",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testInvalidShardCountSettings(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testInvalidShardCountSettings(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testInvalidShardCountSettings",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testMappingConflictRootCause(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testMappingConflictRootCause(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testMappingConflictRootCause",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    },
    {
     "id": "ID#testDoubleAddMapping(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "displayName": "testDoubleAddMapping(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
     "methodName": "testDoubleAddMapping",
     "className": "org.elasticsearch.action.admin.indices.create.CreateIndexIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743800106
 }
]

[
 "TEST_STARTED",
 "ID#testCreationDateGenerated(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreationDateGenerated(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743800139,
  "executionTime": 416
 }
]

[
 "TEST_STARTED",
 "ID#testCreateIndexWithBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateIndexWithBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743800555,
  "executionTime": 156
 }
]

[
 "TEST_STARTED",
 "ID#testCreationDateGivenFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreationDateGivenFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743800711,
  "executionTime": 401
 }
]

[
 "TEST_STARTED",
 "ID#testInvalidShardCountSettingsWithoutPrefix(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testInvalidShardCountSettingsWithoutPrefix(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743801112,
  "executionTime": 241
 }
]

[
 "TEST_STARTED",
 "ID#testCreateAndDeleteIndexConcurrently(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testCreateAndDeleteIndexConcurrently(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743801356,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testCreateAndDeleteIndexConcurrently(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "message": "'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/14932,https://github.com/elastic/elasticsearch/pull/15853))",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/14932,https://github.com/elastic/elasticsearch/pull/15853))\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:766)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)\n\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)\n\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)\n\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)\n\tat java.lang.Thread.run(Thread.java:745)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/14932,https://github.com/elastic/elasticsearch/pull/15853))",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateAndDeleteIndexConcurrently(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743801353,
  "executionTime": 17
 }
]

[
 "TEST_STARTED",
 "ID#testUnknownSettingFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnknownSettingFails(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743801371,
  "executionTime": 134
 }
]

[
 "TEST_STARTED",
 "ID#testCreateIndexWithMetadataBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateIndexWithMetadataBlocks(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743801505,
  "executionTime": 756
 }
]

[
 "TEST_STARTED",
 "ID#testRestartIndexCreationAfterFullClusterRestart(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestartIndexCreationAfterFullClusterRestart(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743802261,
  "executionTime": 477
 }
]

[
 "TEST_STARTED",
 "ID#testInvalidShardCountSettings(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:23,207][WARN ][org.elasticsearch.transport] [node_t1] Transport response handler not found of id [6]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testInvalidShardCountSettings(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743802739,
  "executionTime": 483
 }
]

[
 "TEST_STARTED",
 "ID#testMappingConflictRootCause(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:23,635][WARN ][org.elasticsearch.transport] [node_t1] Transport response handler not found of id [5]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMappingConflictRootCause(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743803222,
  "executionTime": 416
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleAddMapping(org.elasticsearch.action.admin.indices.create.CreateIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleAddMapping(org.elasticsearch.action.admin.indices.create.CreateIndexIT)",
  "startTimestamp": 1453743803638,
  "executionTime": 174
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.admin.indices.create.CreateIndexIT",
  "startTimestamp": 1453743800106,
  "executionTime": 3817
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
   "displayName": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
   "children": [
    {
     "id": "ID#testNoBuckets(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testNoBuckets(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testNoBuckets",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    },
    {
     "id": "ID#testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testDocCountTopLevel",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    },
    {
     "id": "ID#testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testDocCountAsSubAgg",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    },
    {
     "id": "ID#testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testMetricAsSubAggWithInsertZeros",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    },
    {
     "id": "ID#testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testMetricAsSubAgg",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    },
    {
     "id": "ID#testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testMetricTopLevel",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    },
    {
     "id": "ID#testNested(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "displayName": "testNested(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
     "methodName": "testNested",
     "className": "org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743803949
 }
]

[
 "TEST_STARTED",
 "ID#testNoBuckets(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoBuckets(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743804532,
  "executionTime": 614
 }
]

[
 "TEST_STARTED",
 "ID#testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743805146,
  "executionTime": 64
 }
]

[
 "TEST_STARTED",
 "ID#testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743805210,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743805236,
  "executionTime": 29
 }
]

[
 "TEST_STARTED",
 "ID#testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743805265,
  "executionTime": 27
 }
]

[
 "TEST_STARTED",
 "ID#testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743805292,
  "executionTime": 22
 }
]

[
 "TEST_STARTED",
 "ID#testNested(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNested(org.elasticsearch.search.aggregations.pipeline.AvgBucketIT)",
  "startTimestamp": 1453743805314,
  "executionTime": 24
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.pipeline.AvgBucketIT",
  "startTimestamp": 1453743803949,
  "executionTime": 1686
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.settings.UpdateSettingsIT",
   "displayName": "org.elasticsearch.indices.settings.UpdateSettingsIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
   "children": [
    {
     "id": "ID#testUpdateThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testUpdateThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testUpdateThrottleSettings",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    },
    {
     "id": "ID#testOpenCloseUpdateSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testOpenCloseUpdateSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testOpenCloseUpdateSettings",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    },
    {
     "id": "ID#testEngineGCDeletesSetting(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testEngineGCDeletesSetting(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testEngineGCDeletesSetting",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    },
    {
     "id": "ID#testUpdateAutoThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testUpdateAutoThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testUpdateAutoThrottleSettings",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    },
    {
     "id": "ID#testResetDefault(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testResetDefault(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testResetDefault",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    },
    {
     "id": "ID#testUpdateMergeMaxThreadCount(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testUpdateMergeMaxThreadCount(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testUpdateMergeMaxThreadCount",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    },
    {
     "id": "ID#testUpdateSettingsWithBlocks(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "displayName": "testUpdateSettingsWithBlocks(org.elasticsearch.indices.settings.UpdateSettingsIT)",
     "methodName": "testUpdateSettingsWithBlocks",
     "className": "org.elasticsearch.indices.settings.UpdateSettingsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743805644
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743805661,
  "executionTime": 16117
 }
]

[
 "TEST_STARTED",
 "ID#testOpenCloseUpdateSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testOpenCloseUpdateSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743821778,
  "executionTime": 255
 }
]

[
 "TEST_STARTED",
 "ID#testEngineGCDeletesSetting(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEngineGCDeletesSetting(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743822033,
  "executionTime": 1053
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateAutoThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,145][TRACE][org.elasticsearch.tasks  ] [node_s1] register 1128 [transport] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@57814550]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,145][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [444][indices:admin/create] sent to [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,154][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [444][indices:admin/create] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,174][TRACE][org.elasticsearch.tasks  ] [node_s0] register 621 [local] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@79a9134f]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,183][TRACE][org.elasticsearch.tasks  ] [node_s0] register 622 [transport] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@79a9134f]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,183][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [create-index [test], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,183][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,184][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,184][DEBUG][org.elasticsearch.indices] [node_s0] creating Index [test], shards [1]/[0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,184][DEBUG][org.elasticsearch.test.store] [node_s0] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,185][TRACE][org.elasticsearch.index.mapper] [node_s0] [test] using dynamic[true], default mapping source[{\"_default_\":{}}], default percolator mapping source[{%0A\"_default_\":{%0A\"properties\" : {%0A\"query\" : {%0A\"type\" : \"percolator\"%0A}%0A}%0A}%0A}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,185][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling translog_sync every 1.6s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,185][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling refresh every 1s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,186][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test] creating index, cause [api], templates [random_index_template], shards [1]/[0], mappings [_default_]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,186][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,186][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start balancing cluster%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage without relocations: [49oX2Kh4RMy8NHe26o23nw][node_s1][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage with relocations: [0 bytes] [49oX2Kh4RMy8NHe26o23nw][node_s1][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] node [49oX2Kh4RMy8NHe26o23nw] has 86.93446209900966%25 used disk%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage without relocations: [zu2uzwecT2umvZeKk4a3dw][node_s0][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/0] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage with relocations: [0 bytes] [zu2uzwecT2umvZeKk4a3dw][node_s0][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/0] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] node [zu2uzwecT2umvZeKk4a3dw] has 86.93446209900966%25 used disk%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage without relocations: [5DQBOLFkRdygBe8iZ0jM0g][node_s2][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/2] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage with relocations: [0 bytes] [5DQBOLFkRdygBe8iZ0jM0g][node_s2][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/2] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,187][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] node [5DQBOLFkRdygBe8iZ0jM0g] has 86.9344662156577%25 used disk%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,188][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[null], [P], v[0], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]] to [49oX2Kh4RMy8NHe26o23nw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,188][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,188][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,188][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]] to node [49oX2Kh4RMy8NHe26o23nw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,188][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing ... (reason [cleaning up after validating index on master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing index service (reason [cleaning up after validating index on master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][DEBUG][org.elasticsearch.index.cache.query.index] [node_s0] [test] full cache clear, reason [close]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][DEBUG][org.elasticsearch.indices] [node_s0] [test] closed... (reason [cleaning up after validating index on master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,189][TRACE][org.elasticsearch.cluster.service] expecting 4 acknowledgements for cluster_state update (version: 49)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,193][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [create-index [test], cause [api]]%0Aversion: 49%0Astate uuid: Mive9HYfSpC0-YBB2gFi8A%0Afrom_diff: false%0Ameta data version: 45%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], local, master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 27):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,193][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [49]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,193][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [49] with size 1152 to [node_s1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,193][TRACE][org.elasticsearch.cluster.service] [node_s1] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,194][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [49] with size 1152 to [node_s2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,194][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][TRACE][org.elasticsearch.cluster.service] [node_s2] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][TRACE][org.elasticsearch.cluster.service] [node_s1] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 49%0Astate uuid: Mive9HYfSpC0-YBB2gFi8A%0Afrom_diff: false%0Ameta data version: 45%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local], local%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[mode=>local, data=>false, client=>true]%0Arouting_table (version 27):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][TRACE][org.elasticsearch.cluster.service] [node_s2] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 49%0Astate uuid: Mive9HYfSpC0-YBB2gFi8A%0Afrom_diff: false%0Ameta data version: 45%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local], local%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 27):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 49%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [49] with size 1152 to [node_s3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][DEBUG][org.elasticsearch.indices.cluster] [node_s1] [test] creating index%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,196][TRACE][org.elasticsearch.cluster.service] [node_s3] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,196][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,195][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 49%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,196][TRACE][org.elasticsearch.cluster.service] [node_s3] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 49%0Astate uuid: Mive9HYfSpC0-YBB2gFi8A%0Afrom_diff: false%0Ameta data version: 45%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local], local%0Arouting_table (version 27):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,196][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,196][DEBUG][org.elasticsearch.cluster.service] [node_s3] set local cluster state to version 49%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,197][DEBUG][org.elasticsearch.index  ] [node_s2] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,197][DEBUG][org.elasticsearch.indices] [node_s1] creating Index [test], shards [1]/[0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,197][TRACE][org.elasticsearch.gateway] [node_s2] [test] writing state, reason [freshly created]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,197][DEBUG][org.elasticsearch.test.store] [node_s1] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][DEBUG][org.elasticsearch.index  ] [node_s3] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]], cluster_state update (version: 49)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 49, uuid: Mive9HYfSpC0-YBB2gFi8A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][TRACE][org.elasticsearch.index.mapper] [node_s1] [test] using dynamic[true], default mapping source[{\"_default_\":{}}], default percolator mapping source[{%0A\"_default_\":{%0A\"properties\" : {%0A\"query\" : {%0A\"type\" : \"percolator\"%0A}%0A}%0A}%0A}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][TRACE][org.elasticsearch.index  ] [node_s1] [test] scheduling translog_sync every 1.6s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][TRACE][org.elasticsearch.index  ] [node_s1] [test] scheduling refresh every 1s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,198][DEBUG][org.elasticsearch.indices.cluster] [node_s1] [test] adding mapping [_default_], source [{\"_default_\":{\"_timestamp\":{\"enabled\":false},\"dynamic_templates\":[{\"template-strings\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager_global_ordinals\"}},\"match_mapping_type\":\"string\"}},{\"template-longs\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"long\"}},{\"template-doubles\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"double\"}},{\"template-geo_points\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"geo_point\"}},{\"template-booleans\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager\"}},\"match_mapping_type\":\"boolean\"}}]}}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,199][DEBUG][org.elasticsearch.indices.cluster] [node_s1] [test][0] creating shard%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,199][TRACE][org.elasticsearch.env    ] [node_s1] acquiring node shardlock on [[test][0]], timeout [5000]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,199][TRACE][org.elasticsearch.env    ] [node_s1] successfully acquired shardlock for [[test][0]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,200][DEBUG][org.elasticsearch.index  ] [node_s1] [test] [test][0] creating using a new path [ShardPath{path=/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1/indices/test/0, indexUUID='lRF-vrjyS-uOFCrMi_dU_g', shard=[test][0]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,200][DEBUG][org.elasticsearch.index  ] [node_s1] [test] creating shard_id [test][0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,200][DEBUG][org.elasticsearch.test.store] [node_s1] [test][0] Using MockDirWrapper with seed [318E67882A63CC93] throttle: [NEVER] crashIndex: [true]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,201][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,203][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]], cluster_state update (version: 49)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,203][DEBUG][org.elasticsearch.index.store] [node_s1] [test][0] store stats are refreshed with refresh_interval [10s]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,203][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 8ms done applying updated cluster_state (version: 49, uuid: Mive9HYfSpC0-YBB2gFi8A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,203][DEBUG][org.elasticsearch.index.shard] [node_s1] [test][0] state: [CREATED]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,204][DEBUG][org.elasticsearch.index.shard] [node_s1] [test][0] state: [CREATED]->[RECOVERING], reason [from store]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,204][DEBUG][org.elasticsearch.index.shard] [node_s1] [test][0] starting recovery from store ...%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,204][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,205][TRACE][org.elasticsearch.gateway] [node_s1] [test] writing state, reason [freshly created]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,218][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]], cluster_state update (version: 49)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,219][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 23ms done applying updated cluster_state (version: 49, uuid: Mive9HYfSpC0-YBB2gFi8A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,219][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 49%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,219][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,219][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,219][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [freshly created]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]], cluster_state update (version: 49)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 49)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: took 40ms done applying updated cluster_state (version: 49, uuid: Mive9HYfSpC0-YBB2gFi8A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 622%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 621%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [444][indices:admin/create] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [444][indices:admin/create] received response from [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.tasks  ] [node_s1] unregister task for id: 1128%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.tasks  ] [node_s3] register 284 [transport] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@637ba79a]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,224][TRACE][org.elasticsearch.test.transport.tracer] [node_s3] [136][indices:admin/settings/update] sent to [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [136][indices:admin/settings/update] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.tasks  ] [node_s0] register 623 [local] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@1599e4d2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.tasks  ] [node_s0] register 624 [transport] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@1599e4d2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [update-settings]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]] to node [49oX2Kh4RMy8NHe26o23nw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,225][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,226][TRACE][org.elasticsearch.cluster.service] expecting 4 acknowledgements for cluster_state update (version: 50)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,226][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [update-settings]%0Aversion: 50%0Astate uuid: hv0hT7EXRMaJquRalDsuag%0Afrom_diff: false%0Ameta data version: 46%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], local, master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 28):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,226][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [50]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,226][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [50] with size 807 to [node_s1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,226][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [50] with size 807 to [node_s2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,227][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [50] with size 807 to [node_s3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,227][TRACE][org.elasticsearch.cluster.service] [node_s1] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,227][TRACE][org.elasticsearch.cluster.service] [node_s3] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,229][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,229][TRACE][org.elasticsearch.cluster.service] [node_s3] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 50%0Astate uuid: hv0hT7EXRMaJquRalDsuag%0Afrom_diff: false%0Ameta data version: 46%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local], local%0Arouting_table (version 28):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,229][DEBUG][org.elasticsearch.cluster.service] [node_s3] set local cluster state to version 50%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,230][DEBUG][org.elasticsearch.index  ] [node_s3] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,230][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]], cluster_state update (version: 50)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,230][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 50, uuid: hv0hT7EXRMaJquRalDsuag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,227][TRACE][org.elasticsearch.cluster.service] [node_s2] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,231][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,229][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,231][TRACE][org.elasticsearch.cluster.service] [node_s2] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 50%0Astate uuid: hv0hT7EXRMaJquRalDsuag%0Afrom_diff: false%0Ameta data version: 46%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local], local%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 28):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,231][TRACE][org.elasticsearch.cluster.service] [node_s1] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 50%0Astate uuid: hv0hT7EXRMaJquRalDsuag%0Afrom_diff: false%0Ameta data version: 46%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local], local%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[mode=>local, data=>false, client=>true]%0Arouting_table (version 28):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=p7CM9wVaTEKokyBEL6K5LA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.186Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,231][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 50%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,231][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 50%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,232][DEBUG][org.elasticsearch.index  ] [node_s2] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,232][TRACE][org.elasticsearch.gateway] [node_s2] [test] writing state, reason [version changed from [1] to [2]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,232][TRACE][org.elasticsearch.indices.cluster] [node_s1] ignoring recovery instruction for an existing shard [test][0] (shard state: [RECOVERING])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,233][INFO ][org.elasticsearch.common.settings] [node_s1] updating [index.merge.scheduler.auto_throttle] from [true] to [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,233][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,233][TRACE][org.elasticsearch.gateway] [node_s1] [test] writing state, reason [version changed from [1] to [2]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,236][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]], cluster_state update (version: 50)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,236][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 50, uuid: hv0hT7EXRMaJquRalDsuag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,237][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]], cluster_state update (version: 50)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,237][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 6ms done applying updated cluster_state (version: 50, uuid: hv0hT7EXRMaJquRalDsuag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,237][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 50%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,237][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,238][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,238][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [version changed from [1] to [2]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,241][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]], cluster_state update (version: 50)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,241][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 50)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: took 16ms done applying updated cluster_state (version: 50, uuid: hv0hT7EXRMaJquRalDsuag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 624%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 623%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [136][indices:admin/settings/update] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.test.transport.tracer] [node_s3] [136][indices:admin/settings/update] received response from [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.tasks  ] [node_s3] unregister task for id: 284%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.tasks  ] [node_s1] register 1129 [transport] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@40d3d9a5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [445][indices:monitor/settings/get] sent to [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [445][indices:monitor/settings/get] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.tasks  ] [node_s0] register 625 [local] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@d92ca5f]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,242][TRACE][org.elasticsearch.tasks  ] [node_s0] register 626 [transport] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@d92ca5f]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,252][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 626%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,252][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 625%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,252][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [445][indices:monitor/settings/get] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,252][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [445][indices:monitor/settings/get] received response from [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,252][TRACE][org.elasticsearch.tasks  ] [node_s1] unregister task for id: 1129%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateAutoThrottleSettings(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743823086,
  "executionTime": 226
 }
]

[
 "TEST_STARTED",
 "ID#testResetDefault(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResetDefault(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743823312,
  "executionTime": 455
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateMergeMaxThreadCount(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,816][TRACE][org.elasticsearch.test   ] Using transport client for node [node_s3] sniff: [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,816][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s3] [129][indices:admin/create] sent to [{node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,816][TRACE][org.elasticsearch.test.transport.tracer] [node_s3] [129][indices:admin/create] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,824][TRACE][org.elasticsearch.tasks  ] [node_s3] register 299 [local] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@49e7a18a]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,824][TRACE][org.elasticsearch.tasks  ] [node_s3] register 300 [transport] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@49e7a18a]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,824][TRACE][org.elasticsearch.test.transport.tracer] [node_s3] [145][indices:admin/create] sent to [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,825][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [145][indices:admin/create] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,825][TRACE][org.elasticsearch.tasks  ] [node_s0] register 705 [local] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@6b99a0f7]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,825][TRACE][org.elasticsearch.tasks  ] [node_s0] register 706 [transport] [indices:admin/create] [org.elasticsearch.action.admin.indices.create.CreateIndexRequest@6b99a0f7]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,825][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [create-index [test], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,825][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,826][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,826][DEBUG][org.elasticsearch.indices] [node_s0] creating Index [test], shards [1]/[0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,826][DEBUG][org.elasticsearch.test.store] [node_s0] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,826][TRACE][org.elasticsearch.index.mapper] [node_s0] [test] using dynamic[true], default mapping source[{\"_default_\":{}}], default percolator mapping source[{%0A\"_default_\":{%0A\"properties\" : {%0A\"query\" : {%0A\"type\" : \"percolator\"%0A}%0A}%0A}%0A}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,826][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling translog_sync every 2.4s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,826][TRACE][org.elasticsearch.index  ] [node_s0] [test] scheduling refresh every 1s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,827][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test] creating index, cause [api], templates [random_index_template], shards [1]/[0], mappings [_default_]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start balancing cluster%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage without relocations: [49oX2Kh4RMy8NHe26o23nw][node_s1][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage with relocations: [0 bytes] [49oX2Kh4RMy8NHe26o23nw][node_s1][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] node [49oX2Kh4RMy8NHe26o23nw] has 86.93446209900966%25 used disk%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage without relocations: [zu2uzwecT2umvZeKk4a3dw][node_s0][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/0] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage with relocations: [0 bytes] [zu2uzwecT2umvZeKk4a3dw][node_s0][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/0] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] node [zu2uzwecT2umvZeKk4a3dw] has 86.93446209900966%25 used disk%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage without relocations: [5DQBOLFkRdygBe8iZ0jM0g][node_s2][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/2] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] usage with relocations: [0 bytes] [5DQBOLFkRdygBe8iZ0jM0g][node_s2][/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/2] free: 48.4gb[13%25]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.decider] [node_s0] node [5DQBOLFkRdygBe8iZ0jM0g] has 86.9344662156577%25 used disk%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[null], [P], v[0], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]] to [49oX2Kh4RMy8NHe26o23nw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]] to node [49oX2Kh4RMy8NHe26o23nw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,828][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing ... (reason [cleaning up after validating index on master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.indices] [node_s0] [test] closing index service (reason [cleaning up after validating index on master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.index.cache.query.index] [node_s0] [test] full cache clear, reason [close]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.index.cache.bitset] [node_s0] [test] clearing all bitsets because [close]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.indices] [node_s0] [test] closed... (reason [cleaning up after validating index on master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][TRACE][org.elasticsearch.cluster.service] expecting 4 acknowledgements for cluster_state update (version: 63)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [create-index [test], cause [api]]%0Aversion: 63%0Astate uuid: 2O0U5_GSTXe0_reRKcJzcA%0Afrom_diff: false%0Ameta data version: 59%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], local, master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 37):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [63]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,829][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [63] with size 1098 to [node_s1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [63] with size 1098 to [node_s2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [63] with size 1098 to [node_s3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][TRACE][org.elasticsearch.cluster.service] [node_s2] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][TRACE][org.elasticsearch.cluster.service] [node_s1] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][TRACE][org.elasticsearch.cluster.service] [node_s3] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][TRACE][org.elasticsearch.cluster.service] [node_s3] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 63%0Astate uuid: 2O0U5_GSTXe0_reRKcJzcA%0Afrom_diff: false%0Ameta data version: 59%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local], local%0Arouting_table (version 37):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,831][DEBUG][org.elasticsearch.cluster.service] [node_s3] set local cluster state to version 63%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,831][DEBUG][org.elasticsearch.index  ] [node_s3] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,831][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]], cluster_state update (version: 63)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,831][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 63, uuid: 2O0U5_GSTXe0_reRKcJzcA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,831][TRACE][org.elasticsearch.cluster.service] [node_s1] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 63%0Astate uuid: 2O0U5_GSTXe0_reRKcJzcA%0Afrom_diff: false%0Ameta data version: 59%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local], local%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[mode=>local, data=>false, client=>true]%0Arouting_table (version 37):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,832][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 63%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,832][DEBUG][org.elasticsearch.indices.cluster] [node_s1] [test] creating index%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,832][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,832][DEBUG][org.elasticsearch.indices] [node_s1] creating Index [test], shards [1]/[0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,832][DEBUG][org.elasticsearch.test.store] [node_s1] [test] using index.store.throttle.type [NONE], with index.store.throttle.max_bytes_per_sec [null]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,830][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,833][TRACE][org.elasticsearch.index.mapper] [node_s1] [test] using dynamic[true], default mapping source[{\"_default_\":{}}], default percolator mapping source[{%0A\"_default_\":{%0A\"properties\" : {%0A\"query\" : {%0A\"type\" : \"percolator\"%0A}%0A}%0A}%0A}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,833][TRACE][org.elasticsearch.index  ] [node_s1] [test] scheduling translog_sync every 2.4s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,833][TRACE][org.elasticsearch.index  ] [node_s1] [test] scheduling refresh every 1s%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,833][DEBUG][org.elasticsearch.indices.cluster] [node_s1] [test] adding mapping [_default_], source [{\"_default_\":{\"dynamic_templates\":[{\"template-strings\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager_global_ordinals\"}},\"match_mapping_type\":\"string\"}},{\"template-longs\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager\"}},\"match_mapping_type\":\"long\"}},{\"template-doubles\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"double\"}},{\"template-geo_points\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"geo_point\"}},{\"template-booleans\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"boolean\"}}]}}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,833][TRACE][org.elasticsearch.cluster.service] [node_s2] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 63%0Astate uuid: 2O0U5_GSTXe0_reRKcJzcA%0Afrom_diff: false%0Ameta data version: 59%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local], local%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 37):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,834][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 63%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,834][DEBUG][org.elasticsearch.indices.cluster] [node_s1] [test][0] creating shard%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,834][TRACE][org.elasticsearch.env    ] [node_s1] acquiring node shardlock on [[test][0]], timeout [5000]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,834][TRACE][org.elasticsearch.env    ] [node_s1] successfully acquired shardlock for [[test][0]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,834][DEBUG][org.elasticsearch.index  ] [node_s2] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,834][TRACE][org.elasticsearch.gateway] [node_s2] [test] writing state, reason [freshly created]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,835][DEBUG][org.elasticsearch.index  ] [node_s1] [test] [test][0] creating using a new path [ShardPath{path=/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1/indices/test/0, indexUUID='p7Yew7blT5i8JPk90HMLeg', shard=[test][0]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,835][DEBUG][org.elasticsearch.index  ] [node_s1] [test] creating shard_id [test][0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,835][DEBUG][org.elasticsearch.test.store] [node_s1] [test][0] Using MockDirWrapper with seed [8B2496C7C40EC234] throttle: [NEVER] crashIndex: [true]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,835][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,836][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]], cluster_state update (version: 63)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,836][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 3ms done applying updated cluster_state (version: 63, uuid: 2O0U5_GSTXe0_reRKcJzcA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,839][DEBUG][org.elasticsearch.index.store] [node_s1] [test][0] store stats are refreshed with refresh_interval [10s]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,839][DEBUG][org.elasticsearch.index.shard] [node_s1] [test][0] state: [CREATED]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,839][DEBUG][org.elasticsearch.index.shard] [node_s1] [test][0] state: [CREATED]->[RECOVERING], reason [from store]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,839][DEBUG][org.elasticsearch.index.shard] [node_s1] [test][0] starting recovery from store ...%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,840][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,840][TRACE][org.elasticsearch.gateway] [node_s1] [test] writing state, reason [freshly created]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,842][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]], cluster_state update (version: 63)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,842][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 10ms done applying updated cluster_state (version: 63, uuid: 2O0U5_GSTXe0_reRKcJzcA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,842][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 63%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,842][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,842][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,842][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [freshly created]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,844][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]], cluster_state update (version: 63)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,844][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 63)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,844][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test], cause [api]]: took 19ms done applying updated cluster_state (version: 63, uuid: 2O0U5_GSTXe0_reRKcJzcA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,844][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 706%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 705%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [145][indices:admin/create] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.test.transport.tracer] [node_s3] [145][indices:admin/create] received response from [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.tasks  ] [node_s3] unregister task for id: 300%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.tasks  ] [node_s3] unregister task for id: 299%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.test.transport.tracer] [node_s3] [129][indices:admin/create] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,845][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s3] [129][indices:admin/create] received response from [{node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.test   ] Using transport client for node [node_s1] sniff: [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s1] [110][indices:admin/settings/update] sent to [{node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [110][indices:admin/settings/update] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.tasks  ] [node_s1] register 1148 [local] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@4f83b7e7]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.tasks  ] [node_s1] register 1149 [transport] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@4f83b7e7]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [465][indices:admin/settings/update] sent to [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [465][indices:admin/settings/update] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.tasks  ] [node_s0] register 707 [local] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@33c18120]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.tasks  ] [node_s0] register 708 [transport] [indices:admin/settings/update] [org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest@33c18120]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.cluster.service] [node_s0] will process [update-settings]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,846][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start assigning unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start distributing Shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Assigned shard [[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]] to node [49oX2Kh4RMy8NHe26o23nw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] Start allocating unassigned shards%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.cluster.service] expecting 4 acknowledgements for cluster_state update (version: 64)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.cluster.service] [node_s0] cluster state updated, source [update-settings]%0Aversion: 64%0Astate uuid: K6WoSMA1QuuRnNkwo_YWSA%0Afrom_diff: false%0Ameta data version: 60%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], local, master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 38):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [64]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [64] with size 769 to [node_s1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,847][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [64] with size 769 to [node_s2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.discovery.local] [node_s0] sending diff cluster state version [64] with size 769 to [node_s3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.cluster.service] [node_s2] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.cluster.service] [node_s3] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.cluster.service] [node_s1] will process [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.cluster.service] [node_s3] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 64%0Astate uuid: K6WoSMA1QuuRnNkwo_YWSA%0Afrom_diff: false%0Ameta data version: 60%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local], local%0Arouting_table (version 38):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][DEBUG][org.elasticsearch.cluster.service] [node_s3] set local cluster state to version 64%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.cluster.service] [node_s1] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 64%0Astate uuid: K6WoSMA1QuuRnNkwo_YWSA%0Afrom_diff: false%0Ameta data version: 60%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local], local%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[mode=>local, data=>false, client=>true]%0Arouting_table (version 38):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,849][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IFD: init: current segments file is \"segments\"; deletionPolicy=org.apache.lucene.index.SnapshotDeletionPolicy@6748f117%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,849][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 64%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,850][TRACE][org.elasticsearch.indices.cluster] [node_s1] ignoring recovery instruction for an existing shard [test][0] (shard state: [RECOVERING])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,848][TRACE][org.elasticsearch.cluster.service] [node_s2] cluster state updated, source [local-disco-receive(from master)]%0Aversion: 64%0Astate uuid: K6WoSMA1QuuRnNkwo_YWSA%0Afrom_diff: false%0Ameta data version: 60%0Anodes: %0A   {node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]%0A   {node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local], local%0A   {node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local], master%0A   {node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]%0Arouting_table (version 38):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A%0Arouting_nodes:%0A-----node_id[49oX2Kh4RMy8NHe26o23nw][V]%0A--------[test][0], node[49oX2Kh4RMy8NHe26o23nw], [P], v[1], s[INITIALIZING], a[id=eXwKjGoARzCHx4muUtRNhA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:43:43.827Z]]%0A-----node_id[zu2uzwecT2umvZeKk4a3dw][V]%0A-----node_id[5DQBOLFkRdygBe8iZ0jM0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,849][DEBUG][org.elasticsearch.index  ] [node_s3] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,850][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s3}{JFKpq7nBTyO0KwPWy_9BNQ}{local}{local[116]}[client=>true, data=>false, mode=>local]], cluster_state update (version: 64)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,850][DEBUG][org.elasticsearch.cluster.service] [node_s3] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 64, uuid: K6WoSMA1QuuRnNkwo_YWSA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,849][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IFD: now checkpoint \"\" [0 segments ; isCommit = false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,850][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IFD: 1 msec to checkpoint%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,850][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: init: create=true%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,850][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 64%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,851][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: %0Adir=store(ElasticsearchMockDirectoryWrapper(default(mmapfs(/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1/indices/test/0/index),niofs(/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.indices.settings.UpdateSettingsIT_DEE1149085A36D88-001/tempDir-001/data/SUITE-CHILD_VM=[1]-CLUSTER_SEED=[1692818353014540811]-HASH=[142CBC49FB0C89C8]-cluster/nodes/1/indices/test/0/index))))%0Aindex=%0Aversion=5.5.0%0Aanalyzer=org.elasticsearch.index.mapper.MapperService$MapperAnalyzerWrapper%0AramBufferSizeMB=256.0%0AmaxBufferedDocs=-1%0AmaxBufferedDeleteTerms=-1%0AmergedSegmentWarmer=org.elasticsearch.index.engine.InternalEngine$1@37088cf9%0AdelPolicy=org.apache.lucene.index.SnapshotDeletionPolicy%0Acommit=null%0AopenMode=CREATE%0Asimilarity=org.elasticsearch.index.similarity.SimilarityService$PerFieldSimilarity%0AmergeScheduler=EngineMergeScheduler: maxThreadCount=10000, maxMergeCount=10000, ioThrottle=true%0Adefault WRITE_LOCK_TIMEOUT=0%0AwriteLockTimeout=5000%0Acodec=Asserting(Lucene54)%0AinfoStream=org.elasticsearch.common.lucene.LoggerInfoStream%0AmergePolicy=ElasticsearchMergePolicy([TieredMergePolicy: maxMergeAtOnce=2, maxMergeAtOnceExplicit=30, maxMergedSegmentMB=5120.0, floorSegmentMB=2.0, forceMergeDeletesPctAllowed=10.0, segmentsPerTier=2.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.1)%0AindexerThreadPool=org.apache.lucene.index.DocumentsWriterPerThreadPool@5af09d2b%0AreaderPooling=false%0AperThreadHardLimitMB=1945%0AuseCompoundFile=true%0AcommitOnClose=false%0Awriter=org.apache.lucene.index.IndexWriter@1aba4f60%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,851][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: MMapDirectory.UNMAP_SUPPORTED=true%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,851][INFO ][org.elasticsearch.common.settings] [node_s1] updating [index.merge.scheduler.max_thread_count] from [10000] to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,851][DEBUG][org.elasticsearch.index  ] [node_s2] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,852][TRACE][org.elasticsearch.gateway] [node_s2] [test] writing state, reason [version changed from [1] to [2]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,852][DEBUG][org.elasticsearch.index  ] [node_s1] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,852][TRACE][org.elasticsearch.gateway] [node_s1] [test] writing state, reason [version changed from [1] to [2]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,852][DEBUG][org.elasticsearch.index.translog] [node_s1] [test][0] wipe translog location - creating new translog%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]], cluster_state update (version: 64)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 64, uuid: K6WoSMA1QuuRnNkwo_YWSA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s2}{5DQBOLFkRdygBe8iZ0jM0g}{local}{local[115]}[mode=>local]], cluster_state update (version: 64)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 64, uuid: K6WoSMA1QuuRnNkwo_YWSA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 64%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][TRACE][org.elasticsearch.cluster.routing] [node_s0] no need to schedule reroute - no delayed unassigned shards, minDelaySetting [0], scheduled [9223372036854775807]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,854][DEBUG][org.elasticsearch.index  ] [node_s0] [test] using [tiered] merge mergePolicy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[2], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[2.0], reclaim_deletes_weight[2.0]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.gateway] [node_s0] [test] writing state, reason [version changed from [1] to [2]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][DEBUG][org.elasticsearch.index.engine] [node_s1] [test][0] no translog ID present in the current generation - creating one%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine] [node_s1] [test][0] committing writer with translog id [1]  and sync id [null] %0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: commit: start%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: commit: enter lock%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: commit: now prepare%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: prepareCommit: flush%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW:   index before flush %0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] DW: startFullFlush%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: apply all deletes during flush%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,855][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: now apply all deletes for all segments maxDoc=0%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,856][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] BD: prune sis=segments:  minGen=9223372036854775807 packetCount=0%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,856][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] DW: elasticsearch[node_s1][generic][T#4] finishFullFlush success=true%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,856][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: startCommit(): start%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,856][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: startCommit index= changeCount=3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]], cluster_state update (version: 64)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 64)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update-settings]: took 10ms done applying updated cluster_state (version: 64, uuid: K6WoSMA1QuuRnNkwo_YWSA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 708%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 707%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [465][indices:admin/settings/update] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [465][indices:admin/settings/update] received response from [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.tasks  ] [node_s1] unregister task for id: 1149%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.tasks  ] [node_s1] unregister task for id: 1148%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.test.transport.tracer] [node_s1] [110][indices:admin/settings/update] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s1] [110][indices:admin/settings/update] received response from [{node_s1}{49oX2Kh4RMy8NHe26o23nw}{local}{local[114]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.test   ] Using transport client for node [node_s0] sniff: [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s0] [103][indices:monitor/settings/get] sent to [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]] (timeout: [null])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [103][indices:monitor/settings/get] received request%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.tasks  ] [node_s0] register 709 [local] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@2f4603eb]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,857][TRACE][org.elasticsearch.tasks  ] [node_s0] register 710 [transport] [indices:monitor/settings/get] [org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest@2f4603eb]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,859][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: startCommit: wrote pending segments file \"pending_segments_1\"%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,859][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: done all syncs: []%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,859][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: commit: pendingCommit != null%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,861][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 710%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,861][TRACE][org.elasticsearch.tasks  ] [node_s0] unregister task for id: 709%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,861][TRACE][org.elasticsearch.test.transport.tracer] [node_s0] [103][indices:monitor/settings/get] sent response%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,861][TRACE][org.elasticsearch.transport.tracer] [transport_client_node_s0] [103][indices:monitor/settings/get] received response from [{node_s0}{zu2uzwecT2umvZeKk4a3dw}{local}{local[113]}[mode=>local]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,861][TRACE][org.elasticsearch.index.engine.lucene.iw] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IW: commit: done writing segments file \"segments_1\"%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:43,861][TRACE][org.elasticsearch.index.engine.lucene.iw.ifd] [node_s1] [test][0] elasticsearch[node_s1][generic][T#4] IFD: now checkpoint \"\" [0 segments ; isCommit = true]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateMergeMaxThreadCount(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743823767,
  "executionTime": 126
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateSettingsWithBlocks(org.elasticsearch.indices.settings.UpdateSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateSettingsWithBlocks(org.elasticsearch.indices.settings.UpdateSettingsIT)",
  "startTimestamp": 1453743823893,
  "executionTime": 498
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.settings.UpdateSettingsIT",
  "startTimestamp": 1453743805644,
  "executionTime": 18799
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.NoMasterNodeIT",
   "displayName": "org.elasticsearch.cluster.NoMasterNodeIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.NoMasterNodeIT",
   "children": [
    {
     "id": "ID#testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)",
     "displayName": "testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)",
     "methodName": "testNoMasterActions",
     "className": "org.elasticsearch.cluster.NoMasterNodeIT",
     "children": []
    },
    {
     "id": "ID#testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)",
     "displayName": "testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)",
     "methodName": "testNoMasterActionsWriteMasterBlock",
     "className": "org.elasticsearch.cluster.NoMasterNodeIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743824454
 }
]

[
 "TEST_STARTED",
 "ID#testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:45,509][WARN ][org.elasticsearch.discovery] [node_t0] waited for 500ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:45,966][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t1}{xKsn5E-XR-SkYli7OCeiqQ}{127.0.0.1}{127.0.0.1:9561}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:47,349][WARN ][org.elasticsearch.indices.cluster] [node_t1] [[test][1]] marking and sending shard failed due to [master [{node_t1}{xKsn5E-XR-SkYli7OCeiqQ}{127.0.0.1}{127.0.0.1:9561}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:47,352][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][1] received shard failed for [test][1], node[xKsn5E-XR-SkYli7OCeiqQ], [P], v[4], s[STARTED], a[id=25yJsHQkQqSHTyZ3KtnyEg], indexUUID [kc-wjqGCQ5ewUfJ34zUcwQ], message [master [{node_t1}{xKsn5E-XR-SkYli7OCeiqQ}{127.0.0.1}{127.0.0.1:9561}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:47,355][WARN ][org.elasticsearch.indices.cluster] [node_t1] [[test][0]] marking and sending shard failed due to [master [{node_t1}{xKsn5E-XR-SkYli7OCeiqQ}{127.0.0.1}{127.0.0.1:9561}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:47,355][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][0] received shard failed for [test][0], node[xKsn5E-XR-SkYli7OCeiqQ], [P], v[5], s[STARTED], a[id=cd_AuVRwSr2Z7gpwhUCT-A], indexUUID [kc-wjqGCQ5ewUfJ34zUcwQ], message [master [{node_t1}{xKsn5E-XR-SkYli7OCeiqQ}{127.0.0.1}{127.0.0.1:9561}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:47,562][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{c6VRx754QeKgjbLOZrHqAg}{127.0.0.1}{127.0.0.1:9560}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)",
  "startTimestamp": 1453743824472,
  "executionTime": 3104
 }
]

[
 "TEST_STARTED",
 "ID#testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,132][WARN ][org.elasticsearch.discovery] [node_t0] waited for 500ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,700][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t1}{nruRKZBvS0eEr6GzkmjPlQ}{127.0.0.1}{127.0.0.1:9581}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,702][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{node_t0}{mzfBUdbhSoynAOHpyOH48Q}{127.0.0.1}{127.0.0.1:9580}[mode=>network]]%0ARemoteTransportException[[node_t0][127.0.0.1:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,703][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9580}]%0ARemoteTransportException[[node_t0][127.0.0.1:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,705][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9580}]%0ARemoteTransportException[[node_t0][[::1]:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,803][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9580}]%0ARemoteTransportException[[node_t0][127.0.0.1:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,804][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9580}]%0ARemoteTransportException[[node_t0][[::1]:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,873][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] failed send ping to {#zen_unicast_7#}{::1}{[::1]:9581}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,892][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] failed send ping to {#zen_unicast_7#}{::1}{[::1]:9581}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,892][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] failed send ping to {#zen_unicast_7#}{::1}{[::1]:9581}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,873][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] failed send ping to {#zen_unicast_7#}{::1}{[::1]:9581}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,873][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] failed send ping to {#zen_unicast_7#}{::1}{[::1]:9581}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,908][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9580}]%0ARemoteTransportException[[node_t0][127.0.0.1:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,909][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9580}]%0ARemoteTransportException[[node_t0][[::1]:9580][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,978][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] failed send ping to {#zen_unicast_8#}{::1}{[::1]:9582}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,978][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] failed send ping to {#zen_unicast_8#}{::1}{[::1]:9582}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:48,978][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] failed send ping to {#zen_unicast_8#}{::1}{[::1]:9582}%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:910)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:43:49,806][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{87GDz6HxQyKtx8KGlGwgUQ}{127.0.0.1}{127.0.0.1:9580}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)",
  "startTimestamp": 1453743827576,
  "executionTime": 2238
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.NoMasterNodeIT",
  "startTimestamp": 1453743824454,
  "executionTime": 5377
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
   "displayName": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
   "methodName": null,
   "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
   "children": [
    {
     "id": "ID#testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testDeleteSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testCreateSnapshotWithIndexBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testCreateSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testRestoreSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testGetSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testSnapshotStatusWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743829840
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1453743829856,
  "executionTime": 1046
 }
]

[
 "TEST_STARTED",
 "ID#testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1453743830902,
  "executionTime": 2857
 }
]

[
 "TEST_STARTED",
 "ID#testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1453743833759,
  "executionTime": 1246
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1453743835005,
  "executionTime": 1256
 }
]

[
 "TEST_STARTED",
 "ID#testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1453743836261,
  "executionTime": 1566
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1453743837827,
  "executionTime": 1263
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
  "startTimestamp": 1453743829840,
  "executionTime": 9697
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
   "children": [
    {
     "id": "ID#testStringValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldDocCountAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldWithRouting",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldTermSortAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldTermSortDesc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldWithRouting",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldTermSortDesc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldSubAggAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldSubAggAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldSingleShard",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldDocCountAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldSubAggAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldTermSortAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldSingleShard",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldSubAggDesc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldDocCountAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldWithRouting",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldTermSortDesc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testStringValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testStringValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testStringValueFieldSubAggDesc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldSingleShard",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testLongValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testLongValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testLongValueFieldSubAggDesc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    },
    {
     "id": "ID#testDoubleValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "displayName": "testDoubleValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
     "methodName": "testDoubleValueFieldTermSortAsc",
     "className": "org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743839550
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743840736,
  "executionTime": 104
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743840840,
  "executionTime": 55
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743840895,
  "executionTime": 79
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743840974,
  "executionTime": 29
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841003,
  "executionTime": 45
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841048,
  "executionTime": 27
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841075,
  "executionTime": 94
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841169,
  "executionTime": 38
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841207,
  "executionTime": 43
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841250,
  "executionTime": 29
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldSubAggAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841279,
  "executionTime": 33
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841313,
  "executionTime": 29
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841342,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841368,
  "executionTime": 37
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841405,
  "executionTime": 33
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841438,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldDocCountAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841464,
  "executionTime": 37
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldWithRouting(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841501,
  "executionTime": 25
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldTermSortDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841526,
  "executionTime": 32
 }
]

[
 "TEST_STARTED",
 "ID#testStringValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStringValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841558,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueField(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841584,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldSingleShard(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841610,
  "executionTime": 33
 }
]

[
 "TEST_STARTED",
 "ID#testLongValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLongValueFieldSubAggDesc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841643,
  "executionTime": 30
 }
]

[
 "TEST_STARTED",
 "ID#testDoubleValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDoubleValueFieldTermSortAsc(org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT)",
  "startTimestamp": 1453743841673,
  "executionTime": 28
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.TermsDocCountErrorIT",
  "startTimestamp": 1453743839550,
  "executionTime": 2513
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.routing.AliasResolveRoutingIT",
   "displayName": "org.elasticsearch.routing.AliasResolveRoutingIT",
   "methodName": null,
   "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
   "children": [
    {
     "id": "ID#testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "displayName": "testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "methodName": "testResolveSearchRouting",
     "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
     "children": []
    },
    {
     "id": "ID#testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "displayName": "testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "methodName": "testResolveIndexRouting",
     "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
     "children": []
    },
    {
     "id": "ID#testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "displayName": "testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "methodName": "testSearchClosedWildcardIndex",
     "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743842071
 }
]

[
 "TEST_STARTED",
 "ID#testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
  "startTimestamp": 1453743842084,
  "executionTime": 671
 }
]

[
 "TEST_STARTED",
 "ID#testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
  "startTimestamp": 1453743842755,
  "executionTime": 887
 }
]

[
 "TEST_STARTED",
 "ID#testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)",
  "startTimestamp": 1453743843643,
  "executionTime": 746
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:44:04,405][WARN ][org.elasticsearch.transport] [node_s1] Transport response handler not found of id [177]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.routing.AliasResolveRoutingIT",
  "startTimestamp": 1453743842071,
  "executionTime": 2369
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.RejectionActionIT",
   "displayName": "org.elasticsearch.action.RejectionActionIT",
   "methodName": null,
   "className": "org.elasticsearch.action.RejectionActionIT",
   "children": [
    {
     "id": "ID#testSimulatedSearchRejectionLoad(org.elasticsearch.action.RejectionActionIT)",
     "displayName": "testSimulatedSearchRejectionLoad(org.elasticsearch.action.RejectionActionIT)",
     "methodName": "testSimulatedSearchRejectionLoad",
     "className": "org.elasticsearch.action.RejectionActionIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743844448
 }
]

[
 "TEST_STARTED",
 "ID#testSimulatedSearchRejectionLoad(org.elasticsearch.action.RejectionActionIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimulatedSearchRejectionLoad(org.elasticsearch.action.RejectionActionIT)",
  "startTimestamp": 1453743844461,
  "executionTime": 2975
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.RejectionActionIT",
  "startTimestamp": 1453743844448,
  "executionTime": 3040
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.allocation.ClusterRerouteIT",
   "displayName": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
   "children": [
    {
     "id": "ID#testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithCommands_enableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testDelayWithALargeAmountOfShards",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testClusterRerouteWithBlocks",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithAllocateLocalGateway_disableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteExplain",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithAllocateLocalGateway_enableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithCommands_disableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743847496
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743847511,
  "executionTime": 625
 }
]

[
 "TEST_STARTED",
 "ID#testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743848136,
  "executionTime": 47194
 }
]

[
 "TEST_STARTED",
 "ID#testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743895330,
  "executionTime": 678
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743896009,
  "executionTime": 382
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743896392,
  "executionTime": 263
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743896655,
  "executionTime": 741
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1453743897396,
  "executionTime": 479
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.allocation.ClusterRerouteIT",
  "startTimestamp": 1453743847496,
  "executionTime": 51007
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.suggest.stats.SuggestStatsIT",
   "displayName": "org.elasticsearch.index.suggest.stats.SuggestStatsIT",
   "methodName": null,
   "className": "org.elasticsearch.index.suggest.stats.SuggestStatsIT",
   "children": [
    {
     "id": "ID#testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)",
     "displayName": "testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)",
     "methodName": "testSimpleStats",
     "className": "org.elasticsearch.index.suggest.stats.SuggestStatsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743898518
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)",
  "startTimestamp": 1453743898534,
  "executionTime": 3747
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.suggest.stats.SuggestStatsIT",
  "startTimestamp": 1453743898518,
  "executionTime": 3779
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.http.netty.HttpPublishPortIT",
   "displayName": "org.elasticsearch.http.netty.HttpPublishPortIT",
   "methodName": null,
   "className": "org.elasticsearch.http.netty.HttpPublishPortIT",
   "children": [
    {
     "id": "ID#testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)",
     "displayName": "testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)",
     "methodName": "testHttpPublishPort",
     "className": "org.elasticsearch.http.netty.HttpPublishPortIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743902304
 }
]

[
 "TEST_STARTED",
 "ID#testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)",
  "startTimestamp": 1453743902321,
  "executionTime": 177
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.http.netty.HttpPublishPortIT",
  "startTimestamp": 1453743902304,
  "executionTime": 213
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
   "displayName": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
   "children": [
    {
     "id": "ID#testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "displayName": "testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "methodName": "testGetMappingsWithBlocks",
     "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
     "children": []
    },
    {
     "id": "ID#testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "displayName": "testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "methodName": "testGetMappingsWhereThereAreNone",
     "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "displayName": "testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "methodName": "testSimpleGetMappings",
     "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743902525
 }
]

[
 "TEST_STARTED",
 "ID#testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
  "startTimestamp": 1453743902539,
  "executionTime": 173
 }
]

[
 "TEST_STARTED",
 "ID#testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
  "startTimestamp": 1453743902712,
  "executionTime": 203
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
  "startTimestamp": 1453743902916,
  "executionTime": 314
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
  "startTimestamp": 1453743902525,
  "executionTime": 714
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.admin.indices.get.GetIndexIT",
   "displayName": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
   "methodName": null,
   "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
   "children": [
    {
     "id": "ID#testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleAlias",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleMixedFeatures",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testGetIndexWithBlocks",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleUnknownIndex",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testEmpty",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimple",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleSettings",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testEmptyMixedFeatures",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleMapping",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743903248
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743903686,
  "executionTime": 21
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743903707,
  "executionTime": 20
 }
]

[
 "TEST_STARTED",
 "ID#testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743903727,
  "executionTime": 251
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743903979,
  "executionTime": 22
 }
]

[
 "TEST_STARTED",
 "ID#testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743904001,
  "executionTime": 16
 }
]

[
 "TEST_STARTED",
 "ID#testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743904017,
  "executionTime": 15
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743904032,
  "executionTime": 15
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743904047,
  "executionTime": 15
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1453743904062,
  "executionTime": 13
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:04,190][WARN ][org.elasticsearch.transport] [node_s1] Transport response handler not found of id [35]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.admin.indices.get.GetIndexIT",
  "startTimestamp": 1453743903248,
  "executionTime": 958
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.geo.GeoFilterIT",
   "displayName": "org.elasticsearch.search.geo.GeoFilterIT",
   "methodName": null,
   "className": "org.elasticsearch.search.geo.GeoFilterIT",
   "children": [
    {
     "id": "ID#testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testNeighbors",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testGeohashCellFilter",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testShapeBuilders",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testShapeRelations",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testBulk(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testBulk(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testBulk",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743904237
 }
]

[
 "TEST_STARTED",
 "ID#testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1453743904336,
  "executionTime": 240
 }
]

[
 "TEST_STARTED",
 "ID#testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1453743904576,
  "executionTime": 413
 }
]

[
 "TEST_STARTED",
 "ID#testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1453743904989,
  "executionTime": 440
 }
]

[
 "TEST_STARTED",
 "ID#testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1453743905429,
  "executionTime": 956
 }
]

[
 "TEST_STARTED",
 "ID#testBulk(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulk(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1453743906386,
  "executionTime": 3719
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:10,119][WARN ][org.elasticsearch.transport] [node_s1] Transport response handler not found of id [224]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.geo.GeoFilterIT",
  "startTimestamp": 1453743904237,
  "executionTime": 5907
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.msearch.SimpleMultiSearchIT",
   "displayName": "org.elasticsearch.search.msearch.SimpleMultiSearchIT",
   "methodName": null,
   "className": "org.elasticsearch.search.msearch.SimpleMultiSearchIT",
   "children": [
    {
     "id": "ID#testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)",
     "displayName": "testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)",
     "methodName": "testSimpleMultiSearch",
     "className": "org.elasticsearch.search.msearch.SimpleMultiSearchIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743910176
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)",
  "startTimestamp": 1453743910190,
  "executionTime": 1038
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.msearch.SimpleMultiSearchIT",
  "startTimestamp": 1453743910176,
  "executionTime": 1059
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
   "displayName": "org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
   "methodName": null,
   "className": "org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
   "children": [
    {
     "id": "ID#testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)",
     "displayName": "testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)",
     "methodName": "testRegexpFilter",
     "className": "org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743911242
 }
]

[
 "TEST_STARTED",
 "ID#testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)",
  "startTimestamp": 1453743911255,
  "executionTime": 674
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
  "startTimestamp": 1453743911242,
  "executionTime": 697
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
   "children": [
    {
     "id": "ID#testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "displayName": "testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "methodName": "testSingleValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
     "children": []
    },
    {
     "id": "ID#testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "displayName": "testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "methodName": "testMultiValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
     "children": []
    },
    {
     "id": "ID#testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "displayName": "testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "methodName": "testUnmapped",
     "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743911945
 }
]

[
 "TEST_STARTED",
 "ID#testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
  "startTimestamp": 1453743913028,
  "executionTime": 23
 }
]

[
 "TEST_STARTED",
 "ID#testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
  "startTimestamp": 1453743913051,
  "executionTime": 43
 }
]

[
 "TEST_STARTED",
 "ID#testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
  "startTimestamp": 1453743913094,
  "executionTime": 30
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
  "startTimestamp": 1453743911945,
  "executionTime": 1743
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
   "displayName": "org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
   "methodName": null,
   "className": "org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
   "children": [
    {
     "id": "ID#testIndexCausesIndexCreation(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "displayName": "testIndexCausesIndexCreation(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "methodName": "testIndexCausesIndexCreation",
     "className": "org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
     "children": []
    },
    {
     "id": "ID#testOneReplica(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "displayName": "testOneReplica(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "methodName": "testOneReplica",
     "className": "org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
     "children": []
    },
    {
     "id": "ID#testNoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "displayName": "testNoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "methodName": "testNoReplicas",
     "className": "org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
     "children": []
    },
    {
     "id": "ID#testTwoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "displayName": "testTwoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
     "methodName": "testTwoReplicas",
     "className": "org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743913710
 }
]

[
 "TEST_STARTED",
 "ID#testIndexCausesIndexCreation(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexCausesIndexCreation(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
  "startTimestamp": 1453743913724,
  "executionTime": 3351
 }
]

[
 "TEST_STARTED",
 "ID#testOneReplica(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testOneReplica(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
  "startTimestamp": 1453743917075,
  "executionTime": 7240
 }
]

[
 "TEST_STARTED",
 "ID#testNoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
  "startTimestamp": 1453743924315,
  "executionTime": 4098
 }
]

[
 "TEST_STARTED",
 "ID#testTwoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTwoReplicas(org.elasticsearch.search.basic.SearchWhileCreatingIndexIT)",
  "startTimestamp": 1453743928414,
  "executionTime": 4658
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.basic.SearchWhileCreatingIndexIT",
  "startTimestamp": 1453743913710,
  "executionTime": 19413
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.source.SourceFetchingIT",
   "displayName": "org.elasticsearch.search.source.SourceFetchingIT",
   "methodName": null,
   "className": "org.elasticsearch.search.source.SourceFetchingIT",
   "children": [
    {
     "id": "ID#testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "displayName": "testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "methodName": "testSourceFiltering",
     "className": "org.elasticsearch.search.source.SourceFetchingIT",
     "children": []
    },
    {
     "id": "ID#testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)",
     "displayName": "testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)",
     "methodName": "testSourceDefaultBehavior",
     "className": "org.elasticsearch.search.source.SourceFetchingIT",
     "children": []
    },
    {
     "id": "ID#testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "displayName": "testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "methodName": "testSourceWithWildcardFiltering",
     "className": "org.elasticsearch.search.source.SourceFetchingIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743933129
 }
]

[
 "TEST_STARTED",
 "ID#testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
  "startTimestamp": 1453743933143,
  "executionTime": 467
 }
]

[
 "TEST_STARTED",
 "ID#testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)",
  "startTimestamp": 1453743933610,
  "executionTime": 119
 }
]

[
 "TEST_STARTED",
 "ID#testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
  "startTimestamp": 1453743933729,
  "executionTime": 186
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.source.SourceFetchingIT",
  "startTimestamp": 1453743933129,
  "executionTime": 797
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.basic.TransportSearchFailuresIT",
   "displayName": "org.elasticsearch.search.basic.TransportSearchFailuresIT",
   "methodName": null,
   "className": "org.elasticsearch.search.basic.TransportSearchFailuresIT",
   "children": [
    {
     "id": "ID#testFailedSearchWithWrongQuery(org.elasticsearch.search.basic.TransportSearchFailuresIT)",
     "displayName": "testFailedSearchWithWrongQuery(org.elasticsearch.search.basic.TransportSearchFailuresIT)",
     "methodName": "testFailedSearchWithWrongQuery",
     "className": "org.elasticsearch.search.basic.TransportSearchFailuresIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743933934
 }
]

[
 "TEST_STARTED",
 "ID#testFailedSearchWithWrongQuery(org.elasticsearch.search.basic.TransportSearchFailuresIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFailedSearchWithWrongQuery(org.elasticsearch.search.basic.TransportSearchFailuresIT)",
  "startTimestamp": 1453743933945,
  "executionTime": 1287
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.basic.TransportSearchFailuresIT",
  "startTimestamp": 1453743933934,
  "executionTime": 1312
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.tribe.TribeIT",
   "displayName": "org.elasticsearch.tribe.TribeIT",
   "methodName": null,
   "className": "org.elasticsearch.tribe.TribeIT",
   "children": [
    {
     "id": "ID#testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testIndexWriteBlocks",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testGlobalReadWriteBlocks",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testCloseAndOpenIndex",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testOnConflictPrefer",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testOnConflictDrop(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testOnConflictDrop(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testOnConflictDrop",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testTribeOnOneCluster",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743935255
 }
]

[
 "TEST_STARTED",
 "ID#testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:36,116][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1453743935373,
  "executionTime": 1384
 }
]

[
 "TEST_STARTED",
 "ID#testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:36,990][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1453743936757,
  "executionTime": 516
 }
]

[
 "TEST_STARTED",
 "ID#testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:37,563][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1453743937273,
  "executionTime": 1075
 }
]

[
 "TEST_STARTED",
 "ID#testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:38,804][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1453743938348,
  "executionTime": 961
 }
]

[
 "TEST_STARTED",
 "ID#testOnConflictDrop(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:39,823][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testOnConflictDrop(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1453743939309,
  "executionTime": 1151
 }
]

[
 "TEST_STARTED",
 "ID#testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:40,624][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1453743940460,
  "executionTime": 1027
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.tribe.TribeIT",
  "startTimestamp": 1453743935255,
  "executionTime": 6268
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.SearchTimeoutIT",
   "displayName": "org.elasticsearch.search.SearchTimeoutIT",
   "methodName": null,
   "className": "org.elasticsearch.search.SearchTimeoutIT",
   "children": [
    {
     "id": "ID#testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)",
     "displayName": "testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)",
     "methodName": "testSimpleTimeout",
     "className": "org.elasticsearch.search.SearchTimeoutIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743941530
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)",
  "startTimestamp": 1453743941548,
  "executionTime": 679
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.SearchTimeoutIT",
  "startTimestamp": 1453743941530,
  "executionTime": 703
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.settings.ClusterSettingsIT",
   "displayName": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
   "children": [
    {
     "id": "ID#testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testMissingUnits",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testDeleteIsAppliedFirst",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testClusterSettingsUpdateResponse",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testClusterUpdateSettingsWithBlocks",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testClusterNonExistingSettingsUpdate",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testUpdateDiscoveryPublishTimeout",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testCanUpdateTracerSettings",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testResetClusterSetting",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743942241
 }
]

[
 "TEST_STARTED",
 "ID#testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743942256,
  "executionTime": 650
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743942906,
  "executionTime": 142
 }
]

[
 "TEST_STARTED",
 "ID#testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743943048,
  "executionTime": 85
 }
]

[
 "TEST_STARTED",
 "ID#testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743943134,
  "executionTime": 466
 }
]

[
 "TEST_STARTED",
 "ID#testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:45:44,049][WARN ][org.elasticsearch.transport] [node_t1] Transport response handler not found of id [4]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743943600,
  "executionTime": 461
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743944061,
  "executionTime": 241
 }
]

[
 "TEST_STARTED",
 "ID#testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743944302,
  "executionTime": 158
 }
]

[
 "TEST_STARTED",
 "ID#testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1453743944460,
  "executionTime": 263
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.settings.ClusterSettingsIT",
  "startTimestamp": 1453743942241,
  "executionTime": 2582
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
   "displayName": "org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
   "methodName": null,
   "className": "org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
   "children": [
    {
     "id": "ID#testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)",
     "displayName": "testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)",
     "methodName": "testThatRelativePathsDontAffectPlugins",
     "className": "org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743944829
 }
]

[
 "TEST_STARTED",
 "ID#testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)",
  "startTimestamp": 1453743944843,
  "executionTime": 16097
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
  "startTimestamp": 1453743944829,
  "executionTime": 16120
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
   "displayName": "org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
   "children": [
    {
     "id": "ID#testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)",
     "displayName": "testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)",
     "methodName": "testBreakerWithRandomExceptions",
     "className": "org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743960957
 }
]

[
 "TEST_STARTED",
 "ID#testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)",
  "startTimestamp": 1453743960972,
  "executionTime": 788
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
  "startTimestamp": 1453743960957,
  "executionTime": 846
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
   "displayName": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
   "methodName": null,
   "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
   "children": [
    {
     "id": "ID#testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotName",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteOrphanSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRestoreWithDifferentMappingsAndSettings",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotRelocatingPrimary",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotMoreThanOnce",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testReadonlyRepository",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeletionOfFailingToRecoverIndexShouldStopRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testMoveShardWhileSnapshotting",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshotWithMissingIndexAndShardMetadata",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDataFileFailureDuringSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRestoreAliases",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRenameOnRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRestoreTemplates",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshotWithCorruptedSnapshotFile",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testBatchingShardUpdateTask",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteRepositoryWhileSnapshotting",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testFreshIndexUUID",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testListCorruptedSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRecreateBlocksOnRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testEmptySnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testThrottling",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotStatus",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testIncludeGlobalState",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshotWithMissingMetadata",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testChangeSettingsOnRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDataFileFailureDuringRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testUnallocatedShards",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotFileFailureDuringSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testUrlRepository",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotSingleClosedIndex",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotClosedIndex",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSingleGetAfterRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testBasicWorkFlow",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteIndexDuringSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453743961825
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743961845,
  "executionTime": 206
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743962052,
  "executionTime": 385
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743962437,
  "executionTime": 388
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743962825,
  "executionTime": 3937
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743966763,
  "executionTime": 1226
 }
]

[
 "TEST_STARTED",
 "ID#testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:08,824][WARN ][org.elasticsearch.snapshots] [node_s0] failed to create snapshot [readonly-repo:test-snap-2]%0ARepositoryException[[readonly-repo] cannot create snapshot in a readonly repository]%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:267)%0A%09at org.elasticsearch.snapshots.SnapshotsService.beginSnapshot(SnapshotsService.java:309)%0A%09at org.elasticsearch.snapshots.SnapshotsService.access$600(SnapshotsService.java:95)%0A%09at org.elasticsearch.snapshots.SnapshotsService$1$1.run(SnapshotsService.java:231)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743967989,
  "executionTime": 955
 }
]

[
 "TEST_STARTED",
 "ID#testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743968944,
  "executionTime": 613
 }
]

[
 "TEST_STARTED",
 "ID#testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743969557,
  "executionTime": 1110
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743970667,
  "executionTime": 874
 }
]

[
 "TEST_STARTED",
 "ID#testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:12,217][WARN ][org.elasticsearch.snapshots] [node_s2] [[test-idx][5]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][5]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:12,220][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][3]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][3]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:12,225][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][4]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][4]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:12,238][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][0]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][0]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:12,238][WARN ][org.elasticsearch.snapshots] [node_s2] [[test-idx][2]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][2]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743971541,
  "executionTime": 940
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743972481,
  "executionTime": 2489
 }
]

[
 "TEST_STARTED",
 "ID#testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:23,523][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo][test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] indices [test-idx-2] and [test-idx-1] are renamed into the same index [same-name]]%0A%09at org.elasticsearch.snapshots.RestoreService.renamedIndices(RestoreService.java:694)%0A%09at org.elasticsearch.snapshots.RestoreService.restoreSnapshot(RestoreService.java:209)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:82)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:41)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:23,525][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo][test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] indices [test-idx-2] and [test-idx-1] are renamed into the same index [test-idx-1]]%0A%09at org.elasticsearch.snapshots.RestoreService.renamedIndices(RestoreService.java:694)%0A%09at org.elasticsearch.snapshots.RestoreService.restoreSnapshot(RestoreService.java:209)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:82)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:41)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:23,537][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0A[__WRONG__] InvalidIndexNameException[Invalid index name [__WRONG__], must not start with '_']%0A%09at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:152)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:253)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:23,539][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0A[alias-3] InvalidIndexNameException[Invalid index name [alias-3], already exists as alias]%0A%09at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:170)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:253)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:23,542][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] cannot rename index [test-idx-1] into [alias-1] because of conflict with an alias with the same name]%0A%09at org.elasticsearch.snapshots.RestoreService$1.checkAliasNameConflicts(RestoreService.java:336)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:314)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:23,553][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] cannot rename index [test-idx-1] into [alias-2] because of conflict with an alias with the same name]%0A%09at org.elasticsearch.snapshots.RestoreService$1.checkAliasNameConflicts(RestoreService.java:336)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:314)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743974971,
  "executionTime": 9168
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743984139,
  "executionTime": 124
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,584][WARN ][org.elasticsearch.repositories.fs] [node_s0] cannot read snapshot file [test-repo:test-snap-1]%0Ajava.lang.IllegalStateException: class org.apache.lucene.store.BufferedChecksumIndexInput cannot seek backwards (pos=-10 getFilePointer()=0)%0A%09at org.apache.lucene.store.ChecksumIndexInput.seek(ChecksumIndexInput.java:50)%0A%09at org.apache.lucene.codecs.CodecUtil.checksumEntireFile(CodecUtil.java:448)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:106)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshot(BlobStoreRepository.java:438)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.deleteSnapshot(BlobStoreRepository.java:298)%0A%09at org.elasticsearch.snapshots.SnapshotsService$8.run(SnapshotsService.java:1009)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743984263,
  "executionTime": 447
 }
]

[
 "TEST_STARTED",
 "ID#testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,751][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,751][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,752][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index-template [random_index_template], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,752][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [410], source [create-index-template [random_index_template], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,752][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [410]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,753][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,753][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [410], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,753][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,753][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [410], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,753][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 410%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,753][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 410%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,757][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 3ms done applying updated cluster_state (version: 410, uuid: euX0_BreT5Wk8O9Y9LskTQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,757][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 410, uuid: euX0_BreT5Wk8O9Y9LskTQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,758][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 410%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,761][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index-template [random_index_template], cause [api]]: took 8ms done applying updated cluster_state (version: 410, uuid: euX0_BreT5Wk8O9Y9LskTQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,762][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put_repository [test-repo]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [411], source [put_repository [test-repo]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [411]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [411], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 411%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,763][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [411], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,764][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 411%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,769][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 411, uuid: Yu1iWVLzQ0mzuMzdgfcI9g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,771][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 7ms done applying updated cluster_state (version: 411, uuid: Yu1iWVLzQ0mzuMzdgfcI9g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,771][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 411%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,784][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put_repository [test-repo]]: took 21ms done applying updated cluster_state (version: 411, uuid: Yu1iWVLzQ0mzuMzdgfcI9g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,787][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test-idx], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,790][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] creating index, cause [api], templates [random_index_template], shards [3]/[0], mappings [_default_]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [412], source [create-index [test-idx], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [412]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [412], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [412], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 412%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,792][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 412%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,830][DEBUG][org.elasticsearch.cluster.action.shard] [node_s2] 2 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], s[INITIALIZING], a[id=gZ5VP0V1T4mospdUIyym3A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,831][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 38ms done applying updated cluster_state (version: 412, uuid: hLD46IUxQ6i11B74uYNLrw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,831][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 412%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,831][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard started for [[test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], s[INITIALIZING], a[id=gZ5VP0V1T4mospdUIyym3A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,831][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 38ms done applying updated cluster_state (version: 412, uuid: hLD46IUxQ6i11B74uYNLrw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,830][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], s[INITIALIZING], a[id=G2JsRzrSQOiyUY67RBqWAA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,831][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], s[INITIALIZING], a[id=G2JsRzrSQOiyUY67RBqWAA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,847][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test-idx], cause [api]]: took 58ms done applying updated cluster_state (version: 412, uuid: hLD46IUxQ6i11B74uYNLrw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,847][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], s[INITIALIZING], a[id=gZ5VP0V1T4mospdUIyym3A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], s[INITIALIZING], a[id=G2JsRzrSQOiyUY67RBqWAA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,848][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [413], source [shard-started ([test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], s[INITIALIZING], a[id=gZ5VP0V1T4mospdUIyym3A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], s[INITIALIZING], a[id=G2JsRzrSQOiyUY67RBqWAA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,848][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [413]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,848][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,855][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [413], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,855][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 413%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,856][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,856][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [413], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,856][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 413%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,863][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,863][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 11ms done applying updated cluster_state (version: 413, uuid: YTWrRN1rSBewySmHVu0bkA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 12ms done applying updated cluster_state (version: 413, uuid: YTWrRN1rSBewySmHVu0bkA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 413%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,868][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,873][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], s[INITIALIZING], a[id=gZ5VP0V1T4mospdUIyym3A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], s[INITIALIZING], a[id=G2JsRzrSQOiyUY67RBqWAA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store]]: took 25ms done applying updated cluster_state (version: 413, uuid: YTWrRN1rSBewySmHVu0bkA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,873][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,874][INFO ][org.elasticsearch.cluster.routing.allocation] [node_s0] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test-idx][1], [test-idx][1]] ...]).%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,874][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [414], source [shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,874][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [414]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,878][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 10ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [414], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 414%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 10ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [414], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,879][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 414%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,883][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 3ms done applying updated cluster_state (version: 414, uuid: LgH9yEZHTD2ZA62sdRloKA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,883][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,883][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 414, uuid: LgH9yEZHTD2ZA62sdRloKA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,883][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,883][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 414%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,889][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 6ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,889][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 5ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,892][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], s[INITIALIZING], a[id=8MST72i0SQ-0-0hOPghI6A], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:46:24.790Z]]), reason [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 18ms done applying updated cluster_state (version: 414, uuid: LgH9yEZHTD2ZA62sdRloKA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,892][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,892][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,892][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,894][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,894][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,894][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,892][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,904][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 11ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,905][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 10ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,905][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 10ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,905][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,920][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 15ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,920][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,920][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,921][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [type1],put-mapping [type1]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,923][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] create_mapping [type1] with source [{\"type1\":{\"_timestamp\":{\"enabled\":true},\"dynamic_templates\":[{\"template-strings\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager_global_ordinals\"}},\"match_mapping_type\":\"string\"}},{\"template-longs\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"long\"}},{\"template-doubles\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager\"}},\"match_mapping_type\":\"double\"}},{\"template-geo_points\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager\"}},\"match_mapping_type\":\"geo_point\"}},{\"template-booleans\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"boolean\"}}],\"properties\":{\"field1\":{\"type\":\"string\",\"fielddata\":{\"loading\":\"eager_global_ordinals\"}}}}}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,924][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [415], source [put-mapping [type1],put-mapping [type1]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,924][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [415]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,925][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,925][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [415], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,925][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 415%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,925][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,925][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [415], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,925][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 415%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,931][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 415, uuid: RB5dYhjpTnigzXBeqyKXww)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,931][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 415%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,931][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 415, uuid: RB5dYhjpTnigzXBeqyKXww)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,935][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [type1],put-mapping [type1]]: took 13ms done applying updated cluster_state (version: 415, uuid: RB5dYhjpTnigzXBeqyKXww)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,935][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:24,977][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]: took 21ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create_snapshot [test-snap]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [416], source [create_snapshot [test-snap]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [416]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [416], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 416%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [416], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,106][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 416%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,107][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 416, uuid: DyTFtYiRQsaGmpjxfLqsBg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,108][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 416, uuid: DyTFtYiRQsaGmpjxfLqsBg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,108][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 416%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,109][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create_snapshot [test-snap]]: took 2ms done applying updated cluster_state (version: 416, uuid: DyTFtYiRQsaGmpjxfLqsBg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,121][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update_snapshot [test-snap]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,121][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [417], source [update_snapshot [test-snap]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,121][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [417]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,121][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,121][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [417], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,121][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 417%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,122][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 417, uuid: TwP-C6hTRa2YubUlHrdNpA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,122][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,122][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [417], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,122][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 417%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,122][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 417, uuid: TwP-C6hTRa2YubUlHrdNpA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,122][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 417%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,123][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update_snapshot [test-snap]]: took 2ms done applying updated cluster_state (version: 417, uuid: TwP-C6hTRa2YubUlHrdNpA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,123][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,191][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 68ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,200][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,200][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [418], source [update snapshot state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,200][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [418]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,200][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,200][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [418], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,200][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,201][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 418%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,201][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [418], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,201][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 418%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,201][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 418, uuid: 9_0i7P8oRz2kywOGrnB7HA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,202][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 418, uuid: 9_0i7P8oRz2kywOGrnB7HA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,202][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 418%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 2ms done applying updated cluster_state (version: 418, uuid: 9_0i7P8oRz2kywOGrnB7HA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove snapshot metadata]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [419], source [remove snapshot metadata]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [419]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [419], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 419%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [419], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,203][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 419%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,204][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 419, uuid: 7VmgnTDyQ_SXlm8pouyQWw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,204][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 419, uuid: 7VmgnTDyQ_SXlm8pouyQWw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,204][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 419%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,205][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove snapshot metadata]: took 1ms done applying updated cluster_state (version: 419, uuid: 7VmgnTDyQ_SXlm8pouyQWw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,205][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [close-indices [test-idx]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,205][INFO ][org.elasticsearch.cluster.metadata] [node_s0] closing indices [[test-idx]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [420], source [close-indices [test-idx]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [420]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [420], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 420%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,206][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [420], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,207][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 420%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,213][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 7ms done applying updated cluster_state (version: 420, uuid: c8Bo9JbTRAebXFPp4M1GDQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,213][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 7ms done applying updated cluster_state (version: 420, uuid: c8Bo9JbTRAebXFPp4M1GDQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,213][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 420%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,220][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [close-indices [test-idx]]: took 14ms done applying updated cluster_state (version: 420, uuid: c8Bo9JbTRAebXFPp4M1GDQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,227][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [restore_snapshot[test-snap]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,230][DEBUG][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] skipping rebalance due to in-flight shard/store fetches%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,230][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [421], source [restore_snapshot[test-snap]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [421]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [421], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 421%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [421], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,231][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 421%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,235][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 421, uuid: UKpA8Fz-QUaskYlhiC0OJQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,236][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 421, uuid: UKpA8Fz-QUaskYlhiC0OJQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,236][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 421%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,240][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [restore_snapshot[test-snap]]: took 12ms done applying updated cluster_state (version: 421, uuid: UKpA8Fz-QUaskYlhiC0OJQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,240][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_reroute(async_shard_fetch)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [422], source [cluster_reroute(async_shard_fetch)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [422]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [422], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [422], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 422%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,241][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 422%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,246][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 422, uuid: eYOpEjzYR2W5zCFhhXMe3A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,247][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 422, uuid: eYOpEjzYR2W5zCFhhXMe3A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,247][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 422%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,253][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_reroute(async_shard_fetch)]: took 13ms done applying updated cluster_state (version: 422, uuid: eYOpEjzYR2W5zCFhhXMe3A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,253][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,274][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=IqMUC5sFSB6XSkocWUQdww], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,274][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=IqMUC5sFSB6XSkocWUQdww], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,284][DEBUG][org.elasticsearch.cluster.action.shard] [node_s2] 2 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WjRjwz6JR6GTJ_ZyCYIFow], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,294][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard started for [[test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WjRjwz6JR6GTJ_ZyCYIFow], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,305][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [vajyhAtuQhq9T1i-x5fpRQ] for shard [[test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pAPASr2AT8KkerrOok9NUQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,315][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pAPASr2AT8KkerrOok9NUQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]], indexUUID [Nty49kVNQaC2mqyZ20Xh_w], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,325][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 71ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,326][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=IqMUC5sFSB6XSkocWUQdww], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WjRjwz6JR6GTJ_ZyCYIFow], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pAPASr2AT8KkerrOok9NUQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,326][INFO ][org.elasticsearch.cluster.routing.allocation] [node_s0] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test-idx][0], [test-idx][2], [test-idx][1]] ...]).%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,326][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [423], source [shard-started ([test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=IqMUC5sFSB6XSkocWUQdww], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WjRjwz6JR6GTJ_ZyCYIFow], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pAPASr2AT8KkerrOok9NUQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,326][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [423]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,327][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,327][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [423], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,327][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 423%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,327][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,327][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [423], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,327][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 423%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,335][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 7ms done applying updated cluster_state (version: 423, uuid: EbF7_y9tReuXNy4NFsKDNQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,335][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,336][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 8ms done applying updated cluster_state (version: 423, uuid: EbF7_y9tReuXNy4NFsKDNQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,336][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,337][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 423%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,347][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][0], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=IqMUC5sFSB6XSkocWUQdww], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WjRjwz6JR6GTJ_ZyCYIFow], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pAPASr2AT8KkerrOok9NUQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-01-25T17:46:25.227Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: took 20ms done applying updated cluster_state (version: 423, uuid: EbF7_y9tReuXNy4NFsKDNQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,347][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,347][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [424], source [update snapshot state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,347][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [424]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,347][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 12ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,352][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,353][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 16ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,353][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,363][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 10ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 11ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [424], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [424], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 424%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,364][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 424%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,365][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 424, uuid: 9i3VFefWT7eFhdoWwJsQBA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,365][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 424, uuid: 9i3VFefWT7eFhdoWwJsQBA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,365][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 424%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 18ms done applying updated cluster_state (version: 424, uuid: 9i3VFefWT7eFhdoWwJsQBA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,366][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,373][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete-index [test-idx]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,373][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] deleting index%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,373][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [425], source [delete-index [test-idx]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,373][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [425]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,374][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,374][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [425], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,374][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 425%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,374][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,374][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [425], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,374][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 425%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,386][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 12ms done applying updated cluster_state (version: 425, uuid: OXspQDwORgiCqTFFX75PQg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,389][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 15ms done applying updated cluster_state (version: 425, uuid: OXspQDwORgiCqTFFX75PQg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,389][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 425%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,406][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete-index [test-idx]]: took 32ms done applying updated cluster_state (version: 425, uuid: OXspQDwORgiCqTFFX75PQg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,407][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove-index-template [random_index_template]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,407][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [426], source [remove-index-template [random_index_template]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,407][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [426]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,407][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,407][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [426], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,407][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 426%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,408][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,408][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [426], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,408][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 426%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,411][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 426, uuid: FmsGV3M5RXir-C3rgJZqKQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,412][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 4ms done applying updated cluster_state (version: 426, uuid: FmsGV3M5RXir-C3rgJZqKQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,412][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 426%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,416][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove-index-template [random_index_template]]: took 9ms done applying updated cluster_state (version: 426, uuid: FmsGV3M5RXir-C3rgJZqKQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [427], source [delete_repository [*]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [427]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [427], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 427%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [427], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,417][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 427%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,421][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 3ms done applying updated cluster_state (version: 427, uuid: qa5aBSJJSXSa-nQD_ndx0g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,421][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 3ms done applying updated cluster_state (version: 427, uuid: qa5aBSJJSXSa-nQD_ndx0g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,421][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 427%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,425][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: took 8ms done applying updated cluster_state (version: 427, uuid: qa5aBSJJSXSa-nQD_ndx0g)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743984710,
  "executionTime": 715
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:25,834][WARN ][org.elasticsearch.repositories] [node_s0] failed to create repository [test-repo]%0Ajava.lang.IllegalStateException: trying to modify or unregister repository that is currently used %0A%09at org.elasticsearch.repositories.RepositoriesService.ensureRepositoryNotInUse(RepositoriesService.java:421)%0A%09at org.elasticsearch.repositories.RepositoriesService.access$000(RepositoriesService.java:60)%0A%09at org.elasticsearch.repositories.RepositoriesService$1.execute(RepositoriesService.java:113)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743985425,
  "executionTime": 982
 }
]

[
 "TEST_STARTED",
 "ID#testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743986407,
  "executionTime": 3027
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743989434,
  "executionTime": 2787
 }
]

[
 "TEST_STARTED",
 "ID#testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:46:33,876][WARN ][org.elasticsearch.snapshots] [node_s0] failed to get snapshot [test-repo:test-snap-2]%0Ajava.lang.IllegalStateException: class org.apache.lucene.store.BufferedChecksumIndexInput cannot seek backwards (pos=-9 getFilePointer()=0)%0A%09at org.apache.lucene.store.ChecksumIndexInput.seek(ChecksumIndexInput.java:50)%0A%09at org.apache.lucene.codecs.CodecUtil.checksumEntireFile(CodecUtil.java:448)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:106)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshot(BlobStoreRepository.java:438)%0A%09at org.elasticsearch.snapshots.SnapshotsService.snapshots(SnapshotsService.java:153)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.masterOperation(TransportGetSnapshotsAction.java:80)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.masterOperation(TransportGetSnapshotsAction.java:49)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743992221,
  "executionTime": 2084
 }
]

[
 "TEST_STARTED",
 "ID#testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743994305,
  "executionTime": 1285
 }
]

[
 "TEST_STARTED",
 "ID#testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743995591,
  "executionTime": 215
 }
]

[
 "TEST_STARTED",
 "ID#testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453743995806,
  "executionTime": 76653
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744072459,
  "executionTime": 595
 }
]

[
 "TEST_STARTED",
 "ID#testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744073054,
  "executionTime": 1591
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:55,172][WARN ][org.elasticsearch.repositories.fs] [node_s0] cannot read metadata for snapshot [test-repo:test-snap-1]%0ASnapshotMissingException[[test-repo:test-snap-1] is missing]; nested: NoSuchFileException[/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT_DEE1149085A36D88-001/tempDir-001/repos/mEJTnptxFj/meta-test-snap-1.dat];%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshotMetaData(BlobStoreRepository.java:470)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.deleteSnapshot(BlobStoreRepository.java:308)%0A%09at org.elasticsearch.snapshots.SnapshotsService$8.run(SnapshotsService.java:1009)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.nio.file.NoSuchFileException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT_DEE1149085A36D88-001/tempDir-001/repos/mEJTnptxFj/meta-test-snap-1.dat%0A%09at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)%0A%09at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)%0A%09at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)%0A%09at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)%0A%09at java.nio.file.Files.newByteChannel(Files.java:361)%0A%09at java.nio.file.Files.newByteChannel(Files.java:407)%0A%09at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.HandleTrackingFS.newInputStream(HandleTrackingFS.java:93)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.HandleTrackingFS.newInputStream(HandleTrackingFS.java:93)%0A%09at java.nio.file.Files.newInputStream(Files.java:152)%0A%09at org.elasticsearch.common.blobstore.fs.FsBlobContainer.readBlob(FsBlobContainer.java:93)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:100)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshotMetaData(BlobStoreRepository.java:468)%0A%09... 5 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744074645,
  "executionTime": 681
 }
]

[
 "TEST_STARTED",
 "ID#testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:56,334][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] cannot modify setting [index.number_of_shards] on restore]%0A%09at org.elasticsearch.snapshots.RestoreService$1.updateIndexSettings(RestoreService.java:416)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:241)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:56,353][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0Ajava.lang.IllegalArgumentException: must specify non-negative number of shards for index [test-idx]%0A%09at org.elasticsearch.cluster.metadata.IndexMetaData$Builder.build(IndexMetaData.java:753)%0A%09at org.elasticsearch.snapshots.RestoreService$1.updateIndexSettings(RestoreService.java:422)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:241)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744075326,
  "executionTime": 2210
 }
]

[
 "TEST_STARTED",
 "ID#testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,159][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,161][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,162][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,161][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_AE9icE5Sa2t9iIT23a5EQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,164][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=O-nCWB_dS46oqN_eLkV4eQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,165][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][6]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][6]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,167][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=8wQ5frjlQnG25dQK2dhAqA], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,170][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard failed for [test-idx][6], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=KyvVxgpUSr2ESZ_YsC2YuQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][6]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,185][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][1]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,194][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=CW-Z9j_XSSqTOP9aibuTBw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,195][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=8wQ5frjlQnG25dQK2dhAqA], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,195][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard failed for [test-idx][6], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=KyvVxgpUSr2ESZ_YsC2YuQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,196][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_AE9icE5Sa2t9iIT23a5EQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,197][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,197][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=O-nCWB_dS46oqN_eLkV4eQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,199][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=-T7Bp9YfThe54RiWEzxwdw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,209][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=-T7Bp9YfThe54RiWEzxwdw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,212][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=CW-Z9j_XSSqTOP9aibuTBw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,218][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard failed for [test-idx][6], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=KyvVxgpUSr2ESZ_YsC2YuQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,218][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=8wQ5frjlQnG25dQK2dhAqA], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,228][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_AE9icE5Sa2t9iIT23a5EQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,228][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=O-nCWB_dS46oqN_eLkV4eQ], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,247][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=CW-Z9j_XSSqTOP9aibuTBw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,249][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=-T7Bp9YfThe54RiWEzxwdw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-01-25T17:47:58.125Z], details[restore_source[test-repo/test-snap]]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,293][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,314][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=0YwqN6BORyiNNhdn9bMvuA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,322][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,328][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][6]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][6]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,329][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=W1boqgRZSR23sXqOREl2cg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,332][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard failed for [test-idx][6], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ukwj3jkjRd-H46sFr0V_NA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][6]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,333][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][1]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,337][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[gGeZEQlUTneubqjOlz0qmA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=j6wKvyt8RImilizf1CRycw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,348][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,348][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=VqgzSkQCS-iZXF_xeTaE-g], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,349][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,359][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ew8y3dwTSnKjjys71-8i-w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,363][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=VqgzSkQCS-iZXF_xeTaE-g], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,370][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ew8y3dwTSnKjjys71-8i-w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.258Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,381][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,404][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,415][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=CjIpipg-S8aQ4-MLwpNCZA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.346Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,417][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=bM0YARqPRmqiAmwnnNUVZw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.346Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,422][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][1]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,431][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=nhizWLXxQHmo32-XZbyyMQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.346Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,432][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][6]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][6]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,441][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard failed for [test-idx][6], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=4W8cwXo9Rgy0F-uIMqt8TQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.346Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][6]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][6]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,452][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,473][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=nhizWLXxQHmo32-XZbyyMQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.346Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,474][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,475][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=NG5fnD3sSVe3iN7bo3YZ9w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.371Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,479][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=a4KT0TZ6SPeG0AtWl51DlA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.370Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,474][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard failed for [test-idx][6], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=4W8cwXo9Rgy0F-uIMqt8TQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.346Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,504][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,515][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,517][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=JNau-143R3aShR1ipZ0Ihg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.418Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,518][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7crRA0uOTuWoc70juaKkGg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.418Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,524][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7crRA0uOTuWoc70juaKkGg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.418Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,537][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][1]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,546][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,546][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=JNau-143R3aShR1ipZ0Ihg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.418Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,558][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[gGeZEQlUTneubqjOlz0qmA], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=riGZOU2lSce5mjX34rHVEQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.491Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,558][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=I23SFsriTzWMrhPR2so2LA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.491Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,588][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,589][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=sDXd2YYaSqyFFDbQ-zIh8w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.491Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,596][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=sDXd2YYaSqyFFDbQ-zIh8w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.491Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,615][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,628][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=SgOHCQTyTAqPhCN9o6rRbA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,632][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,634][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,635][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2FyOxdGaToWdZui_GDNf8w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,636][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][1]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,636][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=nMoKZmGpTMGnC9BQt7-NGA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,638][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=sR9xjZ0CSzSsqTeRhlOeRQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,642][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=SgOHCQTyTAqPhCN9o6rRbA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,649][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=sR9xjZ0CSzSsqTeRhlOeRQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,650][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[gGeZEQlUTneubqjOlz0qmA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2FyOxdGaToWdZui_GDNf8w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,654][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,657][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=nMoKZmGpTMGnC9BQt7-NGA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.570Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,657][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tZ_753IJSKqoIS0uKmlmuQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.604Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,691][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][1]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,691][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,695][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=VwXZVFl8SdmPZC_CjO4YPQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,699][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,700][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2ZiHvml7SFq1HYuHh5VDuw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,702][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[gGeZEQlUTneubqjOlz0qmA], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=sgHKy3TRRzCnDQwDqYTmGw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][1]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][1]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,713][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard failed for [test-idx][1], node[gGeZEQlUTneubqjOlz0qmA], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=sgHKy3TRRzCnDQwDqYTmGw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,714][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2ZiHvml7SFq1HYuHh5VDuw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,714][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,717][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7n7cI2dpTZShoLMMws6tOw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,722][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,722][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=zGHrI32YR-aBDJDmF2TkUg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.661Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,723][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7n7cI2dpTZShoLMMws6tOw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.660Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,726][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=zGHrI32YR-aBDJDmF2TkUg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.661Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,735][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,745][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Ht5yas9ITnCO6L_fglYmhA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.697Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,745][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Ht5yas9ITnCO6L_fglYmhA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.697Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,767][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,770][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7aVXEqAhQcSXBnA1YU6HiQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.717Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,777][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,779][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=SlPpwbWgRaGeFw2I-RSdHg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.746Z], details[master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,790][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7aVXEqAhQcSXBnA1YU6HiQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.717Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,805][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,808][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=SlPpwbWgRaGeFw2I-RSdHg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.746Z], details[master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,808][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=i5KuPTx2Q7uCnPlwMWrE5Q], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.727Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,919][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7aVXEqAhQcSXBnA1YU6HiQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.717Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,937][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=i5KuPTx2Q7uCnPlwMWrE5Q], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.727Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,976][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,987][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=5b-UyneOTKmzDpjizHAriw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.961Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,990][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:58,993][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=kpK58AbMSm-azhTZuhkirg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.961Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,002][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,003][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=KK0RrL1pTiKIbaq1AvsENQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.961Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,004][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=5b-UyneOTKmzDpjizHAriw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.961Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,010][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=KK0RrL1pTiKIbaq1AvsENQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.961Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,029][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,039][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=C2NtDfTLTD-9a9_5yJ1heg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.999Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,044][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,046][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,046][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=8u5bUthTQWm2zzjIT7WLkA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.011Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,049][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=PPq-LfvaTHOfRs5NO9h61A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.999Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,059][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=8u5bUthTQWm2zzjIT7WLkA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.011Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,059][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[gGeZEQlUTneubqjOlz0qmA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=PPq-LfvaTHOfRs5NO9h61A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:58.999Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[792], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,091][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,096][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[21], restoring[test-repo:test-snap], s[INITIALIZING], a[id=EXwVYytUSIO54Lq1dzZXBQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.043Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,182][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[21], restoring[test-repo:test-snap], s[INITIALIZING], a[id=EXwVYytUSIO54Lq1dzZXBQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.043Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,190][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,191][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Ie2SMY6OTG6JiIKQF4HpdA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.057Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,200][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Ie2SMY6OTG6JiIKQF4HpdA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.057Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,203][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[21], restoring[test-repo:test-snap], s[INITIALIZING], a[id=EXwVYytUSIO54Lq1dzZXBQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.043Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,237][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,238][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,239][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[23], restoring[test-repo:test-snap], s[INITIALIZING], a[id=O_MPSt5GRY2nQRqyqrZqrQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.204Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,244][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[21], restoring[test-repo:test-snap], s[INITIALIZING], a[id=bj6BsnjrT76b_GAbNIZTYA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.204Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,247][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[23], restoring[test-repo:test-snap], s[INITIALIZING], a[id=O_MPSt5GRY2nQRqyqrZqrQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.204Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,258][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,259][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[23], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ysJuMIdMR_yuUR7Y6sAvzQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.248Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,277][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,279][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[23], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ysJuMIdMR_yuUR7Y6sAvzQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.248Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,290][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=awrGpTPLRnCdEZa_HGTUPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.248Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,300][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=awrGpTPLRnCdEZa_HGTUPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.248Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,300][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=awrGpTPLRnCdEZa_HGTUPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.248Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,301][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,307][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=jagEnoIzQjSVTKW9EjRhuQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.280Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,307][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=jagEnoIzQjSVTKW9EjRhuQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.280Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,318][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,319][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[27], restoring[test-repo:test-snap], s[INITIALIZING], a[id=yrV3pxNTRB2LGWTnlxgt-A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.301Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,323][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,328][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[27], restoring[test-repo:test-snap], s[INITIALIZING], a[id=114YJ0hvTB2rszUpfRgcqA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.308Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,329][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[27], restoring[test-repo:test-snap], s[INITIALIZING], a[id=yrV3pxNTRB2LGWTnlxgt-A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.301Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,343][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,348][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,349][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[29], restoring[test-repo:test-snap], s[INITIALIZING], a[id=TnayroivRtuh4JbVqVjlsA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.330Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,352][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[29], restoring[test-repo:test-snap], s[INITIALIZING], a[id=FvXL9xYhQjO1naN-hFG9pg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.330Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,362][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[29], restoring[test-repo:test-snap], s[INITIALIZING], a[id=FvXL9xYhQjO1naN-hFG9pg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.330Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,386][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[gGeZEQlUTneubqjOlz0qmA], [P], v[29], restoring[test-repo:test-snap], s[INITIALIZING], a[id=FvXL9xYhQjO1naN-hFG9pg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.330Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,388][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,396][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[31], restoring[test-repo:test-snap], s[INITIALIZING], a[id=CEjsEIXoQS6PXJsob1ofcA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.350Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,452][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,455][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[-Ynu0l2TQSC1HgOLarL4nw], [P], v[33], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ZBI2YEeQSx6r0miksiLKsg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,480][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][4]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,481][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[31], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7691RQxFRFeBvmU-PJwsEA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][4]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][4]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,524][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard failed for [test-idx][4], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[31], restoring[test-repo:test-snap], s[INITIALIZING], a[id=7691RQxFRFeBvmU-PJwsEA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,537][WARN ][org.elasticsearch.indices.cluster] [node_s2] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,548][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[35], restoring[test-repo:test-snap], s[INITIALIZING], a[id=aekplVejQRKA3Y2jFHlg-A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.474Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,548][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[gGeZEQlUTneubqjOlz0qmA], [P], v[35], restoring[test-repo:test-snap], s[INITIALIZING], a[id=aekplVejQRKA3Y2jFHlg-A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.474Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [master {node_s0}{vajyhAtuQhq9T1i-x5fpRQ}{local}{local[336]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,569][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][5]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:47:59,569][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard failed for [test-idx][5], node[vajyhAtuQhq9T1i-x5fpRQ], [P], v[37], restoring[test-repo:test-snap], s[INITIALIZING], a[id=DPOvxqVXRV-f-H0QEMzLtg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-01-25T17:47:59.554Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], indexUUID [sOynlu6HQJudUhXS6jSmBw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][5]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$723/891321478.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$724/740527924.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][5]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744077536,
  "executionTime": 2301
 }
]

[
 "TEST_STARTED",
 "ID#testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744079837,
  "executionTime": 127
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:00,410][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][0]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][0]] IndexShardSnapshotFailedException[failed to list blobs]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:525)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:293)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.listBlobs(MockRepository.java:339)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:523)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:00,417][WARN ][org.elasticsearch.snapshots] [node_s2] [[test-idx][2]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][2]] IndexShardSnapshotFailedException[Failed to write file list]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$Context.finalize(BlobStoreIndexShardRepository.java:399)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:628)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:293)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:357)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.writeBlob(ChecksumBlobStoreFormat.java:182)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.writeAtomic(ChecksumBlobStoreFormat.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$Context.finalize(BlobStoreIndexShardRepository.java:397)%0A%09... 9 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:00,435][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to finalize snapshot%0ARepositoryException[[test-repo] failed to update snapshot in repository]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.finalizeSnapshot(BlobStoreRepository.java:384)%0A%09at org.elasticsearch.snapshots.SnapshotsService$5.run(SnapshotsService.java:802)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:293)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:357)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.writeSnapshotList(BlobStoreRepository.java:577)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.finalizeSnapshot(BlobStoreRepository.java:381)%0A%09... 4 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744079965,
  "executionTime": 578
 }
]

[
 "TEST_STARTED",
 "ID#testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744080544,
  "executionTime": 1600
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744082145,
  "executionTime": 281
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744082426,
  "executionTime": 888
 }
]

[
 "TEST_STARTED",
 "ID#testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744083314,
  "executionTime": 581
 }
]

[
 "TEST_STARTED",
 "ID#testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744083895,
  "executionTime": 4211
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1453744088106,
  "executionTime": 2190
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
  "startTimestamp": 1453743961825,
  "executionTime": 130802
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
   "displayName": "org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
   "methodName": null,
   "className": "org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
   "children": [
    {
     "id": "ID#testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)",
     "displayName": "testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)",
     "methodName": "testFieldValueFactor",
     "className": "org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744092633
 }
]

[
 "TEST_STARTED",
 "ID#testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)",
  "startTimestamp": 1453744092647,
  "executionTime": 376
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
  "startTimestamp": 1453744092633,
  "executionTime": 400
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.update.UpdateNoopIT",
   "displayName": "org.elasticsearch.update.UpdateNoopIT",
   "methodName": null,
   "className": "org.elasticsearch.update.UpdateNoopIT",
   "children": [
    {
     "id": "ID#testMapAndField(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testMapAndField(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testMapAndField",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testMap(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testMap(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testMap",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testArrayField(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testArrayField(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testArrayField",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testTotallyEmpty",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testSingleField(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testSingleField(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testSingleField",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testTwoFields(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testTwoFields(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testTwoFields",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744093040
 }
]

[
 "TEST_STARTED",
 "ID#testMapAndField(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMapAndField(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1453744093055,
  "executionTime": 298
 }
]

[
 "TEST_STARTED",
 "ID#testMap(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMap(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1453744093353,
  "executionTime": 272
 }
]

[
 "TEST_STARTED",
 "ID#testArrayField(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArrayField(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1453744093625,
  "executionTime": 352
 }
]

[
 "TEST_STARTED",
 "ID#testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1453744093977,
  "executionTime": 414
 }
]

[
 "TEST_STARTED",
 "ID#testSingleField(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSingleField(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1453744094391,
  "executionTime": 529
 }
]

[
 "TEST_STARTED",
 "ID#testTwoFields(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTwoFields(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1453744094920,
  "executionTime": 517
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.update.UpdateNoopIT",
  "startTimestamp": 1453744093040,
  "executionTime": 2417
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.template.IndexTemplateFilteringIT",
   "displayName": "org.elasticsearch.indices.template.IndexTemplateFilteringIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.template.IndexTemplateFilteringIT",
   "children": [
    {
     "id": "ID#testTemplateFiltering(org.elasticsearch.indices.template.IndexTemplateFilteringIT)",
     "displayName": "testTemplateFiltering(org.elasticsearch.indices.template.IndexTemplateFilteringIT)",
     "methodName": "testTemplateFiltering",
     "className": "org.elasticsearch.indices.template.IndexTemplateFilteringIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744095465
 }
]

[
 "TEST_STARTED",
 "ID#testTemplateFiltering(org.elasticsearch.indices.template.IndexTemplateFilteringIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTemplateFiltering(org.elasticsearch.indices.template.IndexTemplateFilteringIT)",
  "startTimestamp": 1453744095479,
  "executionTime": 224
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.template.IndexTemplateFilteringIT",
  "startTimestamp": 1453744095465,
  "executionTime": 245
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.FilterIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.FilterIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
   "children": [
    {
     "id": "ID#testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testEmptyFilterDeclarations",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testEmptyAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testAsSubAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testWithContextBasedSubAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testSimple",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testWithSubAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744095723
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1453744096672,
  "executionTime": 33
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1453744096705,
  "executionTime": 70
 }
]

[
 "TEST_STARTED",
 "ID#testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1453744096776,
  "executionTime": 38
 }
]

[
 "TEST_STARTED",
 "ID#testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1453744096814,
  "executionTime": 64
 }
]

[
 "TEST_STARTED",
 "ID#testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1453744096878,
  "executionTime": 36
 }
]

[
 "TEST_STARTED",
 "ID#testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1453744096915,
  "executionTime": 56
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.FilterIT",
  "startTimestamp": 1453744095723,
  "executionTime": 1517
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
   "displayName": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
   "methodName": null,
   "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
   "children": [
    {
     "id": "ID#testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testIncompatibleFieldTypes",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testFieldStatsIndexLevel",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testIncompatibleFilter",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testRandom",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testFieldStatsFiltering",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744097248
 }
]

[
 "TEST_STARTED",
 "ID#testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1453744097262,
  "executionTime": 316
 }
]

[
 "TEST_STARTED",
 "ID#testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1453744097578,
  "executionTime": 1495
 }
]

[
 "TEST_STARTED",
 "ID#testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1453744099073,
  "executionTime": 644
 }
]

[
 "TEST_STARTED",
 "ID#testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1453744099718,
  "executionTime": 472
 }
]

[
 "TEST_STARTED",
 "ID#testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1453744100190,
  "executionTime": 1521
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
  "startTimestamp": 1453744097248,
  "executionTime": 4478
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT",
   "displayName": "org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT",
   "methodName": null,
   "className": "org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT",
   "children": [
    {
     "id": "ID#testIndicesStatsWithBlocks(org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT)",
     "displayName": "testIndicesStatsWithBlocks(org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT)",
     "methodName": "testIndicesStatsWithBlocks",
     "className": "org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744101732
 }
]

[
 "TEST_STARTED",
 "ID#testIndicesStatsWithBlocks(org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndicesStatsWithBlocks(org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT)",
  "startTimestamp": 1453744101746,
  "executionTime": 365
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.admin.indices.stats.IndicesStatsBlocksIT",
  "startTimestamp": 1453744101732,
  "executionTime": 384
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.transport.ActionNamesIT",
   "displayName": "org.elasticsearch.transport.ActionNamesIT",
   "methodName": null,
   "className": "org.elasticsearch.transport.ActionNamesIT",
   "children": [
    {
     "id": "ID#testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)",
     "displayName": "testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)",
     "methodName": "testActionNamesCategories",
     "className": "org.elasticsearch.transport.ActionNamesIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744102122
 }
]

[
 "TEST_STARTED",
 "ID#testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)",
  "startTimestamp": 1453744102136,
  "executionTime": 253
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.transport.ActionNamesIT",
  "startTimestamp": 1453744102122,
  "executionTime": 316
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.gateway.RecoverAfterNodesIT",
   "displayName": "org.elasticsearch.gateway.RecoverAfterNodesIT",
   "methodName": null,
   "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
   "children": [
    {
     "id": "ID#testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "displayName": "testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "methodName": "testRecoverAfterMasterNodes",
     "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
     "children": []
    },
    {
     "id": "ID#testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "displayName": "testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "methodName": "testRecoverAfterDataNodes",
     "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
     "children": []
    },
    {
     "id": "ID#testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "displayName": "testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "methodName": "testRecoverAfterNodes",
     "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744102445
 }
]

[
 "TEST_STARTED",
 "ID#testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
  "startTimestamp": 1453744102478,
  "executionTime": 385
 }
]

[
 "TEST_STARTED",
 "ID#testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
  "startTimestamp": 1453744102863,
  "executionTime": 584
 }
]

[
 "TEST_STARTED",
 "ID#testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
  "startTimestamp": 1453744103447,
  "executionTime": 10370
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.gateway.RecoverAfterNodesIT",
  "startTimestamp": 1453744102445,
  "executionTime": 11397
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.IndicesLifecycleListenerIT",
   "displayName": "org.elasticsearch.indices.IndicesLifecycleListenerIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.IndicesLifecycleListenerIT",
   "children": [
    {
     "id": "ID#testIndexShardFailedOnRelocation(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
     "displayName": "testIndexShardFailedOnRelocation(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
     "methodName": "testIndexShardFailedOnRelocation",
     "className": "org.elasticsearch.indices.IndicesLifecycleListenerIT",
     "children": []
    },
    {
     "id": "ID#testBeforeIndexAddedToCluster(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
     "displayName": "testBeforeIndexAddedToCluster(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
     "methodName": "testBeforeIndexAddedToCluster",
     "className": "org.elasticsearch.indices.IndicesLifecycleListenerIT",
     "children": []
    },
    {
     "id": "ID#testIndexStateShardChanged(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
     "displayName": "testIndexStateShardChanged(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
     "methodName": "testIndexStateShardChanged",
     "className": "org.elasticsearch.indices.IndicesLifecycleListenerIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744113851
 }
]

[
 "TEST_STARTED",
 "ID#testIndexShardFailedOnRelocation(org.elasticsearch.indices.IndicesLifecycleListenerIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:34,006][WARN ][org.elasticsearch.index  ] [node_t1] [index1] failed to invoke before index created callback%0Ajava.lang.RuntimeException: FAIL%0A%09at org.elasticsearch.indices.IndicesLifecycleListenerIT$2.beforeIndexCreated(IndicesLifecycleListenerIT.java:130)%0A%09at org.elasticsearch.test.MockIndexEventListener$TestEventListener.beforeIndexCreated(MockIndexEventListener.java:126)%0A%09at org.elasticsearch.index.CompositeIndexEventListener.beforeIndexCreated(CompositeIndexEventListener.java:144)%0A%09at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:303)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewIndices(IndicesClusterStateService.java:325)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:195)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:596)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:34,006][WARN ][org.elasticsearch.indices.cluster] [node_t1] [[index1][0]] marking and sending shard failed due to [failed to create index]%0Ajava.lang.RuntimeException: FAIL%0A%09at org.elasticsearch.indices.IndicesLifecycleListenerIT$2.beforeIndexCreated(IndicesLifecycleListenerIT.java:130)%0A%09at org.elasticsearch.test.MockIndexEventListener$TestEventListener.beforeIndexCreated(MockIndexEventListener.java:126)%0A%09at org.elasticsearch.index.CompositeIndexEventListener.beforeIndexCreated(CompositeIndexEventListener.java:144)%0A%09at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:303)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewIndices(IndicesClusterStateService.java:325)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:195)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:596)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:34,007][WARN ][org.elasticsearch.cluster.action.shard] [node_t0] [index1][0] received shard failed for [index1][0], node[HvYaTC2fTMGB4K7OuCmCOQ], relocating [vJ5pRuE5T3-mAC1T3nQx-g], [P], v[3], s[INITIALIZING], a[id=rK0lqWUPRpSVrwh-P8J1Yg, rId=SyeT1r_USG2Pd3-ozR3CwA], expected_shard_size[130], indexUUID [i2X4XlR9RF-vZXXMsHARxg], message [failed to create index], failure [NotSerializableExceptionWrapper[FAIL]]%0ANotSerializableExceptionWrapper[FAIL]%0A%09at org.elasticsearch.indices.IndicesLifecycleListenerIT$2.beforeIndexCreated(IndicesLifecycleListenerIT.java:130)%0A%09at org.elasticsearch.test.MockIndexEventListener$TestEventListener.beforeIndexCreated(MockIndexEventListener.java:126)%0A%09at org.elasticsearch.index.CompositeIndexEventListener.beforeIndexCreated(CompositeIndexEventListener.java:144)%0A%09at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:303)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewIndices(IndicesClusterStateService.java:325)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:195)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:596)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexShardFailedOnRelocation(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
  "startTimestamp": 1453744113869,
  "executionTime": 170
 }
]

[
 "TEST_STARTED",
 "ID#testBeforeIndexAddedToCluster(org.elasticsearch.indices.IndicesLifecycleListenerIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:34,327][WARN ][org.elasticsearch.index  ] [node_t0] [failed] failed to invoke before index added to cluster callback%0AElasticsearchException[failing on purpose]%0A%09at org.elasticsearch.indices.IndicesLifecycleListenerIT$1.beforeIndexAddedToCluster(IndicesLifecycleListenerIT.java:88)%0A%09at org.elasticsearch.test.MockIndexEventListener$TestEventListener.beforeIndexAddedToCluster(MockIndexEventListener.java:171)%0A%09at org.elasticsearch.index.CompositeIndexEventListener.beforeIndexAddedToCluster(CompositeIndexEventListener.java:254)%0A%09at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$1.execute(MetaDataCreateIndexService.java:386)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBeforeIndexAddedToCluster(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
  "startTimestamp": 1453744114039,
  "executionTime": 319
 }
]

[
 "TEST_STARTED",
 "ID#testIndexStateShardChanged(org.elasticsearch.indices.IndicesLifecycleListenerIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:34,399][WARN ][org.elasticsearch.index  ] [node_t0] [failed] failed to invoke before index created callback%0AElasticsearchException[failing on purpose]%0A%09at org.elasticsearch.indices.IndicesLifecycleListenerIT$IndexShardStateChangeListener.beforeIndexCreated(IndicesLifecycleListenerIT.java:257)%0A%09at org.elasticsearch.test.MockIndexEventListener$TestEventListener.beforeIndexCreated(MockIndexEventListener.java:126)%0A%09at org.elasticsearch.index.CompositeIndexEventListener.beforeIndexCreated(CompositeIndexEventListener.java:144)%0A%09at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:303)%0A%09at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$1.execute(MetaDataCreateIndexService.java:312)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexStateShardChanged(org.elasticsearch.indices.IndicesLifecycleListenerIT)",
  "startTimestamp": 1453744114359,
  "executionTime": 429
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.IndicesLifecycleListenerIT",
  "startTimestamp": 1453744113851,
  "executionTime": 962
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
   "displayName": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
   "methodName": null,
   "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
   "children": [
    {
     "id": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "displayName": "testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "methodName": "testGetMappings",
     "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
     "children": []
    },
    {
     "id": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "displayName": "testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "methodName": "testGetAliases",
     "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
     "children": []
    },
    {
     "id": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "displayName": "testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "methodName": "testGetSettings",
     "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744114824
 }
]

[
 "TEST_STARTED",
 "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1453744114832,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "message": "'backwards' test group is disabled (@Backwards())",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:668)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$200(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:591)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1453744114831,
  "executionTime": 1
 }
]

[
 "TEST_STARTED",
 "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1453744114832,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "message": "'backwards' test group is disabled (@Backwards())",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:668)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$200(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:591)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1453744114832,
  "executionTime": 0
 }
]

[
 "TEST_STARTED",
 "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1453744114832,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "message": "'backwards' test group is disabled (@Backwards())",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:668)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$200(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:591)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1453744114832,
  "executionTime": 0
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
  "startTimestamp": 1453744114824,
  "executionTime": 8
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
   "displayName": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
   "methodName": null,
   "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
   "children": [
    {
     "id": "ID#testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIsolateMasterAndVerifyClusterStateConsensus",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testSendingShardFailure",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testClusterFormingWithASlowNode",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIndicesDeleted",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testAckedIndexing",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testMasterNodeGCs",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testStaleMasterNotHijackingMajority",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testNodesFDAfterMasterReelection",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testUnicastSinglePingResponseContainsMaster",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testNodeNotReachableFromMaster",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testRejoinDocumentExistsInAllShardCopies",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testClusterJoinDespiteOfPublishingIssues",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIsolatedUnicastNodes",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testSearchWithRelocationAndSlowClusterStateProcessing",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testVerifyApiBlocksDuringPartition",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testFailWithMinimumMasterNodesConfigured",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744114861
 }
]

[
 "TEST_STARTED",
 "ID#testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,971][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [9]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,971][WARN ][org.elasticsearch.gateway] [node_t0] [test][1]: failed to list shard for shard_store on node [lyQxBp2hT_CGL_9wEQWL-A]%0AFailedNodeException[Failed node [lyQxBp2hT_CGL_9wEQWL-A]]; nested: SendRequestTransportException[[node_t2][127.0.0.1:30202][internal:cluster/nodes/indices/shard/store[n]]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:208)%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$700(TransportNodesAction.java:109)%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$2.handleException(TransportNodesAction.java:181)%0A%09at org.elasticsearch.transport.TransportService$3.run(TransportService.java:319)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: SendRequestTransportException[[node_t2][127.0.0.1:30202][internal:cluster/nodes/indices/shard/store[n]]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:168)%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$100(TransportNodesAction.java:109)%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:83)%0A%09at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:53)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:101)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.list(TransportNodesListShardStoreMetaData.java:91)%0A%09at org.elasticsearch.gateway.AsyncShardFetch.asyncFetch(AsyncShardFetch.java:274)%0A%09at org.elasticsearch.gateway.AsyncShardFetch.fetchData(AsyncShardFetch.java:124)%0A%09at org.elasticsearch.gateway.GatewayAllocator$InternalReplicaShardAllocator.fetchData(GatewayAllocator.java:182)%0A%09at org.elasticsearch.gateway.ReplicaShardAllocator.allocateUnassigned(ReplicaShardAllocator.java:142)%0A%09at org.elasticsearch.gateway.GatewayAllocator.allocateUnassigned(GatewayAllocator.java:122)%0A%09at org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocators.allocateUnassigned(ShardsAllocators.java:72)%0A%09at org.elasticsearch.cluster.routing.allocation.AllocationService.reroute(AllocationService.java:309)%0A%09at org.elasticsearch.cluster.routing.allocation.AllocationService.reroute(AllocationService.java:273)%0A%09at org.elasticsearch.cluster.routing.allocation.AllocationService.reroute(AllocationService.java:259)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$6.execute(ZenDiscovery.java:582)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09... 3 more%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 25 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,972][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-node_failed({node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,972][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network],{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,972][WARN ][org.elasticsearch.discovery.zen] [node_t0] failed to publish to min_master_nodes, current nodes: {{node_t0}{41jBQMAfShm68Eb7OXvDew}{127.0.0.1}{127.0.0.1:30200}[mode=>network],{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network],{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,972][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30201}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,973][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,973][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:38,973][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30202}]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:39,004][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = transport disconnected), current nodes: {{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network],{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:40,474][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30201}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:40,474][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:40,474][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:40,474][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30202}]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,976][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30201}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,977][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30201}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,978][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,979][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,978][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30202}]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,977][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{nzF29BZBRcqo-1BngKcHsg}{127.0.0.1}{127.0.0.1:30201}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30201][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30201] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,977][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:41,976][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30202}]%0ASendRequestTransportException[[node_t2][127.0.0.1:30202][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30202] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:45,082][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{lyQxBp2hT_CGL_9wEQWL-A}{127.0.0.1}{127.0.0.1:30202}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744114871,
  "executionTime": 10216
 }
]

[
 "TEST_STARTED",
 "ID#testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:50,207][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network],{node_t1}{DXqqTKlqS_SSZvZI1-Ddzg}{127.0.0.1}{127.0.0.1:30204}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:50,264][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network],{node_t1}{DXqqTKlqS_SSZvZI1-Ddzg}{127.0.0.1}{127.0.0.1:30204}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:51,209][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t1}{DXqqTKlqS_SSZvZI1-Ddzg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:51,210][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-node_failed({node_t1}{DXqqTKlqS_SSZvZI1-Ddzg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:52,212][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:52,213][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-node_failed({node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:52,213][WARN ][org.elasticsearch.discovery.zen] [node_t0] failed to publish to min_master_nodes, current nodes: {{node_t0}{2SGjecntQw2vfdISJKB2KA}{127.0.0.1}{127.0.0.1:30203}[mode=>network],{node_t1}{DXqqTKlqS_SSZvZI1-Ddzg}{127.0.0.1}{127.0.0.1:30204}[mode=>network],{node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:52,214][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-failed-to-publish]%0Aorg.elasticsearch.cluster.NotMasterException: no longer master. source: [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:53,295][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][0] received shard failed for [test][0], node[DXqqTKlqS_SSZvZI1-Ddzg], [P], v[4], s[STARTED], a[id=mDNF2Z58RGyeUtKyAeI2XA], indexUUID [mVR_nDuQQnOBSLj9yGWMWg], message [simulated], failure [CorruptIndexException[simulated (resource=null)]]%0Aorg.apache.lucene.index.CorruptIndexException: simulated (resource=null)%0A%09at org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT.testSendingShardFailure(DiscoveryWithServiceDisruptionsIT.java:917)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,347][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30204}]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,347][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network]]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,347][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30205}]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,347][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{DXqqTKlqS_SSZvZI1-Ddzg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,349][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{dLpvfvZkRi-sBOOI3rXD4w}{127.0.0.1}{127.0.0.1:30205}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744125087,
  "executionTime": 10267
 }
]

[
 "TEST_STARTED",
 "ID#testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,392][WARN ][org.elasticsearch.discovery] [node_t0] waited for 1ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,420][WARN ][org.elasticsearch.discovery] [node_t1] waited for 1ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:48:55,448][WARN ][org.elasticsearch.discovery] [node_t2] waited for 1ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:03,137][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{6frbPGgtS_iE4HZNtZ1VFQ}{127.0.0.1}{127.0.0.1:30208}[mode=>network],{node_t1}{uarMq52KRviHb5X91Iszxg}{127.0.0.1}{127.0.0.1:30207}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:03,137][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t2}{6frbPGgtS_iE4HZNtZ1VFQ}{127.0.0.1}{127.0.0.1:30208}[mode=>network],{node_t1}{uarMq52KRviHb5X91Iszxg}{127.0.0.1}{127.0.0.1:30207}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744135354,
  "executionTime": 7792
 }
]

[
 "TEST_STARTED",
 "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744143146,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "message": "'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/11665))",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/11665))\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:766)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)\n\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)\n\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)\n\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)\n\tat java.lang.Thread.run(Thread.java:745)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/11665))",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744143146,
  "executionTime": 1
 }
]

[
 "TEST_STARTED",
 "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744143147,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "message": "'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=needs some more work to stabilize))",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=needs some more work to stabilize))\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:766)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)\n\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)\n\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)\n\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)\n\tat java.lang.Thread.run(Thread.java:745)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=needs some more work to stabilize))",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744143147,
  "executionTime": 0
 }
]

[
 "TEST_STARTED",
 "ID#testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:08,246][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{CyY8Boj9S5Oy-hq6OZ-QQQ}{127.0.0.1}{127.0.0.1:30209}[mode=>network],{node_t1}{vbqY1t0mRZCXbUeS9hBkGg}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:08,246][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{CyY8Boj9S5Oy-hq6OZ-QQQ}{127.0.0.1}{127.0.0.1:30209}[mode=>network],{node_t1}{vbqY1t0mRZCXbUeS9hBkGg}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:11,998][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30211}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30211][internal:discovery/zen/unicast] request_id [20] timed out after [3751ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:12,000][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30211}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30211][internal:discovery/zen/unicast] request_id [21] timed out after [3753ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:12,757][WARN ][org.elasticsearch.discovery.zen.publish] [node_t2] timed out waiting for all nodes to process published state [2] (timeout [1s], pending nodes: [{node_t1}{vbqY1t0mRZCXbUeS9hBkGg}{127.0.0.1}{127.0.0.1:30210}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:14,759][WARN ][org.elasticsearch.discovery.zen] [node_t0] discovered [{node_t2}{5t_mwavKRJSdxfwPY-YhPg}{127.0.0.1}{127.0.0.1:30211}[mode=>network]] which is also master but with an older cluster_state, telling [{node_t2}{5t_mwavKRJSdxfwPY-YhPg}{127.0.0.1}{127.0.0.1:30211}[mode=>network]] to rejoin the cluster ([node fd ping])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:14,762][WARN ][org.elasticsearch.discovery.zen] [node_t2] received a request to rejoin the cluster from [CyY8Boj9S5Oy-hq6OZ-QQQ], current nodes: {{node_t0}{CyY8Boj9S5Oy-hq6OZ-QQQ}{127.0.0.1}{127.0.0.1:30209}[mode=>network],{node_t2}{5t_mwavKRJSdxfwPY-YhPg}{127.0.0.1}{127.0.0.1:30211}[mode=>network],{node_t1}{vbqY1t0mRZCXbUeS9hBkGg}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:17,777][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{5t_mwavKRJSdxfwPY-YhPg}{127.0.0.1}{127.0.0.1:30211}[mode=>network],{node_t1}{vbqY1t0mRZCXbUeS9hBkGg}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:17,778][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t2}{5t_mwavKRJSdxfwPY-YhPg}{127.0.0.1}{127.0.0.1:30211}[mode=>network],{node_t1}{vbqY1t0mRZCXbUeS9hBkGg}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744143147,
  "executionTime": 14642
 }
]

[
 "TEST_STARTED",
 "ID#testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:22,895][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{pb1sKuaJQmuTY2mJ60Jhlg}{127.0.0.1}{127.0.0.1:30212}[mode=>network],{node_t2}{vqXth1wqSI6c83fVgcdm4Q}{127.0.0.1}{127.0.0.1:30214}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:22,948][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{pb1sKuaJQmuTY2mJ60Jhlg}{127.0.0.1}{127.0.0.1:30212}[mode=>network],{node_t2}{vqXth1wqSI6c83fVgcdm4Q}{127.0.0.1}{127.0.0.1:30214}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:26,649][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30213}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30213][internal:discovery/zen/unicast] request_id [21] timed out after [3752ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:26,699][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30213}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30213][internal:discovery/zen/unicast] request_id [24] timed out after [3750ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:28,116][WARN ][org.elasticsearch.discovery.zen.publish] [node_t0] received a cluster state from a different master than the current one, rejecting (received {node_t1}{-HxRs4YIQomjAHyA1V8VZg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], current {node_t0}{pb1sKuaJQmuTY2mJ60Jhlg}{127.0.0.1}{127.0.0.1:30212}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:28,117][WARN ][org.elasticsearch.discovery.zen.publish] [node_t2] received a cluster state from a different master than the current one, rejecting (received {node_t1}{-HxRs4YIQomjAHyA1V8VZg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], current {node_t0}{pb1sKuaJQmuTY2mJ60Jhlg}{127.0.0.1}{127.0.0.1:30212}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:28,118][WARN ][org.elasticsearch.cluster.service] [node_t1] failing [sneaky-update]: failed to commit cluster state version [4]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:28,119][WARN ][org.elasticsearch.discovery] failure [sneaky-update]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:28,119][WARN ][org.elasticsearch.discovery.zen] [node_t1] failed to publish to min_master_nodes, current nodes: {{node_t1}{-HxRs4YIQomjAHyA1V8VZg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],{node_t0}{pb1sKuaJQmuTY2mJ60Jhlg}{127.0.0.1}{127.0.0.1:30212}[mode=>network],{node_t2}{vqXth1wqSI6c83fVgcdm4Q}{127.0.0.1}{127.0.0.1:30214}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:31,164][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t1}{-HxRs4YIQomjAHyA1V8VZg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],{node_t2}{vqXth1wqSI6c83fVgcdm4Q}{127.0.0.1}{127.0.0.1:30214}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:31,164][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t1}{-HxRs4YIQomjAHyA1V8VZg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],{node_t2}{vqXth1wqSI6c83fVgcdm4Q}{127.0.0.1}{127.0.0.1:30214}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744157790,
  "executionTime": 13384
 }
]

[
 "TEST_STARTED",
 "ID#testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:34,426][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t0}{uubdRYSjRyu_Znt3qsJtng}{127.0.0.1}{127.0.0.1:30215}[mode=>network],{node_t1}{rD1QBWVaTCmWnTJNOr73uA}{127.0.0.1}{127.0.0.1:30216}[mode=>network],{node_t3}{szCmkZrMQiGNJnrWNNNEMg}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:34,426][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = shut_down), current nodes: {{node_t0}{uubdRYSjRyu_Znt3qsJtng}{127.0.0.1}{127.0.0.1:30215}[mode=>network],{node_t1}{rD1QBWVaTCmWnTJNOr73uA}{127.0.0.1}{127.0.0.1:30216}[mode=>network],{node_t3}{szCmkZrMQiGNJnrWNNNEMg}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:34,426][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = shut_down), current nodes: {{node_t0}{uubdRYSjRyu_Znt3qsJtng}{127.0.0.1}{127.0.0.1:30215}[mode=>network],{node_t1}{rD1QBWVaTCmWnTJNOr73uA}{127.0.0.1}{127.0.0.1:30216}[mode=>network],{node_t3}{szCmkZrMQiGNJnrWNNNEMg}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:38,431][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = transport disconnected), current nodes: {{node_t0}{uubdRYSjRyu_Znt3qsJtng}{127.0.0.1}{127.0.0.1:30215}[mode=>network],{node_t3}{szCmkZrMQiGNJnrWNNNEMg}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:38,431][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30215}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30215][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30215] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30215] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:38,433][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] failed to send ping to [{node_t1}{rD1QBWVaTCmWnTJNOr73uA}{127.0.0.1}{127.0.0.1:30216}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30216][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30216] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30216] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:38,433][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] failed to send ping to [{node_t0}{uubdRYSjRyu_Znt3qsJtng}{127.0.0.1}{127.0.0.1:30215}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30215][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30215] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30215] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:41,470][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = shut_down), current nodes: {{node_t3}{szCmkZrMQiGNJnrWNNNEMg}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744171174,
  "executionTime": 10301
 }
]

[
 "TEST_STARTED",
 "ID#testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:45,786][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t3}{Tw6gK909SlC0AJdc1utv-Q}{127.0.0.1}{127.0.0.1:30222}[mode=>network],{node_t0}{zKUqM_MDRmaQXA_Bxl1HOQ}{127.0.0.1}{127.0.0.1:30219}[mode=>network],{node_t1}{de977UG8RLOW_TuPL5-dkg}{127.0.0.1}{127.0.0.1:30220}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:48,821][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t3}{Tw6gK909SlC0AJdc1utv-Q}{127.0.0.1}{127.0.0.1:30222}[mode=>network],{node_t2}{45fuqZ1vTde8MD7_WS0kig}{127.0.0.1}{127.0.0.1:30221}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:48,825][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = transport disconnected), current nodes: {{node_t3}{Tw6gK909SlC0AJdc1utv-Q}{127.0.0.1}{127.0.0.1:30222}[mode=>network],{node_t1}{de977UG8RLOW_TuPL5-dkg}{127.0.0.1}{127.0.0.1:30220}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:48,828][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] failed send ping to {node_t1}{de977UG8RLOW_TuPL5-dkg}{127.0.0.1}{127.0.0.1:30220}[mode=>network]%0Ajava.lang.IllegalStateException: can't add nodes to a stopped transport%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:900)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:895)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNode(MockTransportService.java:408)%0A%09at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:235)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:398)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744181476,
  "executionTime": 7353
 }
]

[
 "TEST_STARTED",
 "ID#testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:55,106][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{S8VNlh8oTUGr04B4T_c45Q}{127.0.0.1}{127.0.0.1:30224}[master=>false, mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,377][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{S8VNlh8oTUGr04B4T_c45Q}{127.0.0.1}{127.0.0.1:30224}[master=>false, mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744188829,
  "executionTime": 9552
 }
]

[
 "TEST_STARTED",
 "ID#testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,446][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t0] using minimum_master_nodes [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,457][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] using initial hosts [127.0.0.1:30225, 127.0.0.1:30226, 127.0.0.1:30227], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,458][DEBUG][org.elasticsearch.discovery.zen] [node_t0] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,458][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,458][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1005], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1006], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,490][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,491][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] failed to connect to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0AConnectTransportException[[][127.0.0.1:30226] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30226];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30226%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,491][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] failed to connect to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0AConnectTransportException[[][127.0.0.1:30227] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30227];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30227%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,525][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t1] using minimum_master_nodes [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,525][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] using initial hosts [127.0.0.1:30225, 127.0.0.1:30226, 127.0.0.1:30227], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,525][DEBUG][org.elasticsearch.discovery.zen] [node_t1] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,525][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,526][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,557][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,557][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,557][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,557][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1008], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1009], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,558][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] failed to connect to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0AConnectTransportException[[][127.0.0.1:30227] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30227];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30227%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,559][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1010], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,598][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t2] using minimum_master_nodes [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,598][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] using initial hosts [127.0.0.1:30225, 127.0.0.1:30226, 127.0.0.1:30227], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,598][DEBUG][org.elasticsearch.discovery.zen] [node_t2] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,598][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,598][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,629][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,629][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,629][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,629][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1012], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1013], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,630][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,631][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1014], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:58,631][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1015], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1017], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network] with temp node {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network] with temp node {#zen_unicast_5_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_5_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,995][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1018], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,996][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_5_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,997][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1019], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,997][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_5_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1020], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,997][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1021], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:49:59,997][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1022], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,060][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,060][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,060][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1024], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network] with temp node {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1026], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1025], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,061][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network] with temp node {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1027], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,062][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1028], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,063][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1029], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,130][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,130][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,130][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,130][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1031], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,130][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1034], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1032], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1033], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network] with temp node {#zen_unicast_4_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network] with temp node {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_4_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,131][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,132][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,132][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,132][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_4_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,132][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,132][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_4_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1035], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:00,133][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1036], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,496][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,496][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1038], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,496][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network] with temp node {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network] with temp node {#zen_unicast_7_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_7_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1041], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1039], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,497][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1040], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,498][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,498][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,498][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,498][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_7_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,498][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1042], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,498][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_7_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1043], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1042], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1043], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1042], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1043], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_5_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,499][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_7_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,501][TRACE][org.elasticsearch.discovery.zen] [node_t0] joining master {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,562][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,562][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,562][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1045], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network] with temp node {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1046], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1047], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network] with temp node {#zen_unicast_7_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_7_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,563][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1048], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,564][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,564][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,564][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,564][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_7_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,564][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1049], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,565][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_7_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1050], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,565][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_7_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,565][TRACE][org.elasticsearch.discovery.zen] [node_t1] full ping responses:%0A%09--> ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1050], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1049], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,565][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,565][DEBUG][org.elasticsearch.discovery.zen] [node_t1] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1050], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1049], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,565][TRACE][org.elasticsearch.discovery.zen] [node_t1] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,566][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,566][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_4__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,566][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_6__FjxnJWMRBKXTv-XMjpxdQ#}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,567][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,567][TRACE][org.elasticsearch.discovery.zen] [node_t1] joining master {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,634][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,634][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,634][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,634][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1052], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,634][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,634][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1053], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,635][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,635][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,636][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1055], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,636][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1056], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,637][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}: [ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1004], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1054], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,637][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1007], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1011], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1016], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1023], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1030], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1037], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1044], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1051], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1057], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][TRACE][org.elasticsearch.discovery.zen] [node_t2] full ping responses:%0A%09--> ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1055], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1057], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][DEBUG][org.elasticsearch.discovery.zen] [node_t2] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1055], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1057], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][DEBUG][org.elasticsearch.discovery.zen] [node_t2] elected as master, waiting for incoming joins ([1] needed)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_5_yAiYq0VEQCGhSOgEORxIKA#}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_4_w0Sdmye_TjqcGlWeXVGeug#}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,639][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received full cluster state version [1] with size [325]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,639][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received full cluster state version [1] with size [325]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,639][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network] acked cluster state version [1]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,639][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,639][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [wkF-EK0sQoKa1P9uwolE8w], version [1]) to [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,639][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [wkF-EK0sQoKa1P9uwolE8w], version [1]) to [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,640][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] restarting fault detection against master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,640][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] restarting fault detection against master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,640][DEBUG][org.elasticsearch.discovery.zen] [node_t0] got first state from fresh master [_FjxnJWMRBKXTv-XMjpxdQ]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,640][DEBUG][org.elasticsearch.discovery.zen] [node_t1] got first state from fresh master [_FjxnJWMRBKXTv-XMjpxdQ]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,640][TRACE][org.elasticsearch.discovery.zen] [node_t0] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,640][TRACE][org.elasticsearch.discovery.zen] [node_t1] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,643][TRACE][org.elasticsearch.discovery.zen] [node_t2] stopping join accumulation ([election closed])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,643][TRACE][org.elasticsearch.discovery.zen] [node_t2] cluster joins counter set to [1] (elected as master)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,643][TRACE][org.elasticsearch.action.admin.indices.stats] [node_t2] Error during transport action execution.%0AClusterBlockException[blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];]%0A%09at org.elasticsearch.cluster.block.ClusterBlocks.globalBlockedException(ClusterBlocks.java:157)%0A%09at org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction.checkGlobalBlock(TransportIndicesStatsAction.java:70)%0A%09at org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction.checkGlobalBlock(TransportIndicesStatsAction.java:47)%0A%09at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction$AsyncAction.<init>(TransportBroadcastByNodeAction.java:230)%0A%09at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction.doExecute(TransportBroadcastByNodeAction.java:210)%0A%09at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction.doExecute(TransportBroadcastByNodeAction.java:77)%0A%09at org.elasticsearch.action.support.TransportAction.doExecute(TransportAction.java:113)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:101)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.updateIndicesStats(InternalClusterInfoService.java:269)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:320)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:276)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.lambda$onMaster$155(InternalClusterInfoService.java:135)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService$$Lambda$717/776708085.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,644][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,644][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,645][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t2] Serving cluster state request using version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,645][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [2] with uuid [lyEdRUZhQvyzg8lDkivAsg], diff size [175]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,645][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received diff cluster state version [2] with uuid [lyEdRUZhQvyzg8lDkivAsg], diff size [175]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,645][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network] acked cluster state version [2]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,645][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,655][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [lyEdRUZhQvyzg8lDkivAsg], version [2]) to [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,656][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [lyEdRUZhQvyzg8lDkivAsg], version [2]) to [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,680][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,680][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: sampled state rejected by predicate (version [2], status [APPLIED]). adding listener to ClusterService%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:01,680][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: postAdded - predicate rejected state (version [2], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,639][TRACE][org.elasticsearch.discovery.zen.fd] [node_t2] [node  ] [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,640][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received diff cluster state version [3] with uuid [eOPqZi2uQq-oisa193cJxQ], diff size [285]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,640][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network] acked cluster state version [3]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,640][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,640][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [eOPqZi2uQq-oisa193cJxQ], version [3]) to [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,643][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,643][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: accepting cluster state change (version [3], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,643][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,643][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,654][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,666][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,678][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,689][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,707][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,740][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,805][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:02,933][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,190][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,643][TRACE][org.elasticsearch.discovery.zen.fd] [node_t2] checking ping from [w0Sdmye_TjqcGlWeXVGeug] under a cluster state thread%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,646][TRACE][org.elasticsearch.discovery.zen.fd] [node_t1] [master] failed to ping [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], retry [1] out of [1]%0ARemoteTransportException[[node_t2][127.0.0.1:30227][internal:discovery/zen/fd/master_ping]]; nested: IllegalStateException;%0ACaused by: java.lang.IllegalStateException%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,646][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] failed to ping [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], tried [1] times, each with maximum [1s] timeout%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,646][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] stopping fault detection against master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [master failure, failed to ping, tried [1] times, each with  maximum [1s] timeout]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,646][INFO ][org.elasticsearch.discovery.zen] [node_t1] master_left [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [failed to ping, tried [1] times, each with  maximum [1s] timeout]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network],{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1059], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1060], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,647][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] connected to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,650][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1062], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,650][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1061], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,651][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1063], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,706][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,707][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,707][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: sampled state rejected by predicate (version [3], status [APPLIED]). adding listener to ClusterService%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:03,707][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: postAdded - predicate rejected state (version [3], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1065], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1067], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1066], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,148][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,149][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1068], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:05,149][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1069], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1071], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,649][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1073], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,650][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,650][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1072], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,651][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1074], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,651][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1075], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,653][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] disconnecting from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,653][TRACE][org.elasticsearch.discovery.zen] [node_t1] full ping responses:%0A%09--> ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1075], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1074], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,653][DEBUG][org.elasticsearch.discovery.zen] [node_t1] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]], id[1075], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A%09--> ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1074], master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,653][TRACE][org.elasticsearch.discovery.zen] [node_t1] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,654][TRACE][org.elasticsearch.discovery.zen] [node_t1] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,657][TRACE][org.elasticsearch.discovery.zen] [node_t1] joining master {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,659][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received full cluster state version [4] with size [289]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,659][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received diff cluster state version [4] with uuid [3WNk5q0ZRZ6LxqctQiAJ0A], diff size [310]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,660][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network] acked cluster state version [4]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,660][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,660][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [3WNk5q0ZRZ6LxqctQiAJ0A], version [4]) to [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,661][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [3WNk5q0ZRZ6LxqctQiAJ0A], version [4]) to [{node_t0}{yAiYq0VEQCGhSOgEORxIKA}{127.0.0.1}{127.0.0.1:30225}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,661][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] restarting fault detection against master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,661][DEBUG][org.elasticsearch.discovery.zen] [node_t1] got first state from fresh master [_FjxnJWMRBKXTv-XMjpxdQ]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,661][TRACE][org.elasticsearch.discovery.zen] [node_t1] updated cluster join cluster to [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,663][TRACE][org.elasticsearch.action.admin.indices.stats] [node_t2] resolving shards for [indices:monitor/stats] based on cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,664][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,664][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: accepting cluster state change (version [4], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,664][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,664][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,671][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,672][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t2] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,673][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t0] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,673][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,673][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t2] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,675][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] stopping fault detection against master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [zen disco stop]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,675][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [5] with uuid [PCe8Av0ST-GKGheXQAvWRg], diff size [282]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,676][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network] acked cluster state version [5]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,676][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,676][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [PCe8Av0ST-GKGheXQAvWRg], version [5]) to [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,679][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] stopping fault detection against master [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], reason [zen disco stop]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1076], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1077], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]: [ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1058], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1064], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]], id[1070], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1076], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1076], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}, ping_response{node [{node_t2}{_FjxnJWMRBKXTv-XMjpxdQ}{127.0.0.1}{127.0.0.1:30227}[mode=>network]], id[1078], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2985823321707247797]-HASH=[142CBCA56B273568]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,680][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,681][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to connect to {node_t1}{w0Sdmye_TjqcGlWeXVGeug}{127.0.0.1}{127.0.0.1:30226}[mode=>network]%0ANodeDisconnectedException[[node_t1][127.0.0.1:30226][internal:discovery/zen/unicast] disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,681][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30226}%0AConnectTransportException[[][127.0.0.1:30226] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30226];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30226%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,682][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30225}%0AConnectTransportException[[][127.0.0.1:30225] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30225];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30225%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,684][TRACE][org.elasticsearch.discovery.zen.ping] [node_t2] pingAndWait interrupted%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,684][TRACE][org.elasticsearch.discovery.zen] [node_t2] No full ping responses%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,684][TRACE][org.elasticsearch.discovery.zen] [node_t2] thread is no longer in currentJoinThread. Stopping.%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744198381,
  "executionTime": 8305
 }
]

[
 "TEST_STARTED",
 "ID#testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,774][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,774][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,775][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,821][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,821][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,821][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,897][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,897][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:06,897][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,825][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(elected_as_master, [1] joins received)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,825][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(elected_as_master, [1] joins received)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,826][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(elected_as_master, [1] joins received)]%0Aversion: 1%0Astate uuid: _KDpMrBtRpucqNBaWDIAhA%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,826][INFO ][org.elasticsearch.cluster.service] [node_t1] new_master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], added {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-join(elected_as_master, [1] joins received)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,826][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: _KDpMrBtRpucqNBaWDIAhA%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][INFO ][org.elasticsearch.cluster.service] [node_t0] detected_master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], added {{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [1]])]: took 0s done applying updated cluster_state (version: 1, uuid: _KDpMrBtRpucqNBaWDIAhA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,827][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(elected_as_master, [1] joins received)]: took 2ms done applying updated cluster_state (version: 1, uuid: _KDpMrBtRpucqNBaWDIAhA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,828][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,829][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [local-gateway-elected-state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,829][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [local-gateway-elected-state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,829][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [local-gateway-elected-state]%0Aversion: 2%0Astate uuid: 1EWly2h_R-u7QwNZPApMrg%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,829][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,829][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,829][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,830][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: 1EWly2h_R-u7QwNZPApMrg%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,830][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,833][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [2]])]: took 3ms done applying updated cluster_state (version: 2, uuid: 1EWly2h_R-u7QwNZPApMrg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,833][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,835][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [local-gateway-elected-state]: took 6ms done applying updated cluster_state (version: 2, uuid: 1EWly2h_R-u7QwNZPApMrg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,907][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(join from node[{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,907][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,907][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(join from node[{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]])]%0Aversion: 3%0Astate uuid: 87m0iZCAQIGMqhUGYURVcQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,908][INFO ][org.elasticsearch.cluster.service] [node_t1] added {{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network],}, reason: zen-disco-join(join from node[{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,908][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,908][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,908][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,908][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,909][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,909][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: 87m0iZCAQIGMqhUGYURVcQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,909][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: 87m0iZCAQIGMqhUGYURVcQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,909][INFO ][org.elasticsearch.cluster.service] [node_t0] added {{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,909][INFO ][org.elasticsearch.cluster.service] [node_t2] detected_master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], added {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,911][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,911][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,912][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]: took 2ms done applying updated cluster_state (version: 3, uuid: 87m0iZCAQIGMqhUGYURVcQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [3]])]: took 5ms done applying updated cluster_state (version: 3, uuid: 87m0iZCAQIGMqhUGYURVcQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]])]: took 7ms done applying updated cluster_state (version: 3, uuid: 87m0iZCAQIGMqhUGYURVcQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,915][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,916][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [create-index [test], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,916][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [create-index [test], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,917][TRACE][org.elasticsearch.cluster.service] expecting 3 acknowledgements for cluster_state update (version: 4)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,917][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [create-index [test], cause [api]]%0Aversion: 4%0Astate uuid: AvkvkRqnTp6Er5coiKe0SQ%0Afrom_diff: false%0Ameta data version: 2%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 2):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,917][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,918][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,918][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,918][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: AvkvkRqnTp6Er5coiKe0SQ%0Afrom_diff: false%0Ameta data version: 2%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 2):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,918][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,919][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,919][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,919][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: AvkvkRqnTp6Er5coiKe0SQ%0Afrom_diff: false%0Ameta data version: 2%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 2):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,919][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,926][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]: took 7ms done applying updated cluster_state (version: 4, uuid: AvkvkRqnTp6Er5coiKe0SQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,926][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]], cluster_state update (version: 4)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,931][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [4]])]: took 12ms done applying updated cluster_state (version: 4, uuid: AvkvkRqnTp6Er5coiKe0SQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,931][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]], cluster_state update (version: 4)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,931][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,938][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network]], cluster_state update (version: 4)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,938][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 4)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,938][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [create-index [test], cause [api]]: took 22ms done applying updated cluster_state (version: 4, uuid: AvkvkRqnTp6Er5coiKe0SQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,938][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [shard-started ([test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery from store]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,938][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery from store]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,939][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [shard-started ([test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery from store]]%0Aversion: 5%0Astate uuid: qM3MeTERRbWlaAzoGKiQNw%0Afrom_diff: false%0Ameta data version: 3%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 3):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[2], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[2], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,939][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,939][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: qM3MeTERRbWlaAzoGKiQNw%0Afrom_diff: false%0Ameta data version: 3%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 3):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[2], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[2], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: qM3MeTERRbWlaAzoGKiQNw%0Afrom_diff: false%0Ameta data version: 3%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 3):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[2], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[2], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,940][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,947][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]: took 7ms done applying updated cluster_state (version: 5, uuid: qM3MeTERRbWlaAzoGKiQNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,950][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [5]])]: took 10ms done applying updated cluster_state (version: 5, uuid: qM3MeTERRbWlaAzoGKiQNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,950][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,960][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[1], s[INITIALIZING], a[id=b6T_XnHKTCKqZjy_hbUrYQ], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery from store]]: took 21ms done applying updated cluster_state (version: 5, uuid: qM3MeTERRbWlaAzoGKiQNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,960][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,960][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,960][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,965][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,966][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,966][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]%0Aversion: 6%0Astate uuid: _T8kd_ysQGSkEdlIitPPTA%0Afrom_diff: false%0Ameta data version: 4%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 4):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[3], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[3], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[3], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[3], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,966][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [6]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: _T8kd_ysQGSkEdlIitPPTA%0Afrom_diff: false%0Ameta data version: 4%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 4):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[3], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[3], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[3], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[3], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: _T8kd_ysQGSkEdlIitPPTA%0Afrom_diff: false%0Ameta data version: 4%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 4):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[3], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[3], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[3], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[3], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,967][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,975][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]: took 8ms done applying updated cluster_state (version: 6, uuid: _T8kd_ysQGSkEdlIitPPTA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,976][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [6]])]: took 9ms done applying updated cluster_state (version: 6, uuid: _T8kd_ysQGSkEdlIitPPTA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,976][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,980][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[2], s[INITIALIZING], a[id=jn2ObrtcSta8YN7om8CWMA], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]: took 14ms done applying updated cluster_state (version: 6, uuid: _T8kd_ysQGSkEdlIitPPTA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,980][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,981][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,981][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]],shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,981][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]],shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0Aversion: 7%0Astate uuid: -i3fVSdMT1SsjsmJmYDjeg%0Afrom_diff: false%0Ameta data version: 5%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,981][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [7]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]%0Aversion: 7%0Astate uuid: -i3fVSdMT1SsjsmJmYDjeg%0Afrom_diff: false%0Ameta data version: 5%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 7%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]%0Aversion: 7%0Astate uuid: -i3fVSdMT1SsjsmJmYDjeg%0Afrom_diff: false%0Ameta data version: 5%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,982][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 7%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,990][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]: took 7ms done applying updated cluster_state (version: 7, uuid: -i3fVSdMT1SsjsmJmYDjeg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,990][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [7]])]: took 8ms done applying updated cluster_state (version: 7, uuid: -i3fVSdMT1SsjsmJmYDjeg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,990][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 7%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,997][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[2], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]],shard-started ([test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[3], s[INITIALIZING], a[id=ndRKElugRpaLmNd6g8wUmg], unassigned_info[[reason=INDEX_CREATED], at[2016-01-25T17:50:09.916Z]]), reason [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 16ms done applying updated cluster_state (version: 7, uuid: -i3fVSdMT1SsjsmJmYDjeg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,998][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,998][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:09,998][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,827][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-node_failed({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_failed({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = transport disconnected), current nodes: {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0Aversion: 7%0Astate uuid: -i3fVSdMT1SsjsmJmYDjeg%0Afrom_diff: false%0Ameta data version: 5%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[4], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[4], s[STARTED], a[id=jn2ObrtcSta8YN7om8CWMA]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][X]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[4], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30229}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30229][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30229] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30229] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,829][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30230][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30230] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30230] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,829][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30229][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30229] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30229] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30230}]%0ASendRequestTransportException[[node_t2][127.0.0.1:30230][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30230] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30230] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][INFO ][org.elasticsearch.cluster.service] [node_t0] removed {{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,828][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-node_failed({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]), reason transport disconnected]%0Aversion: 8%0Astate uuid: 1B8qFFsiRRmIzfaHh0I1AA%0Afrom_diff: false%0Ameta data version: 6%0Anodes: %0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,832][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 7%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,832][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-node_failed({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]), reason transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,832][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [8]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,833][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: took 4ms done applying updated cluster_state (version: 7, uuid: -i3fVSdMT1SsjsmJmYDjeg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,833][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [8]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,833][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [8]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,833][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [8]])]%0Aversion: 8%0Astate uuid: 1B8qFFsiRRmIzfaHh0I1AA%0Afrom_diff: false%0Ameta data version: 6%0Anodes: %0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,833][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [8]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,833][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 8%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,841][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [8]])]: took 8ms done applying updated cluster_state (version: 8, uuid: 1B8qFFsiRRmIzfaHh0I1AA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,841][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 8%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,850][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_failed({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]), reason transport disconnected]: took 21ms done applying updated cluster_state (version: 8, uuid: 1B8qFFsiRRmIzfaHh0I1AA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,852][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [put-mapping [type]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,852][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [put-mapping [type]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,853][TRACE][org.elasticsearch.cluster.service] expecting 2 acknowledgements for cluster_state update (version: 9)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,853][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [put-mapping [type]]%0Aversion: 9%0Astate uuid: ECfMuXBtSmKJNdVoQWUSfw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,853][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [9]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,854][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [9]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,854][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [9]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,854][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [9]])]%0Aversion: 9%0Astate uuid: ECfMuXBtSmKJNdVoQWUSfw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,854][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 9%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,858][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [9]])]: took 4ms done applying updated cluster_state (version: 9, uuid: ECfMuXBtSmKJNdVoQWUSfw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,858][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]], cluster_state update (version: 9)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,858][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 9%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,862][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network]], cluster_state update (version: 9)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,862][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 9)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,862][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [put-mapping [type]]: took 10ms done applying updated cluster_state (version: 9, uuid: ECfMuXBtSmKJNdVoQWUSfw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,868][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,868][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:10,868][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,835][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(join from node[{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,835][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,835][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(join from node[{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]])]%0Aversion: 10%0Astate uuid: W7PuISv9S3efZyaJ9tkFOg%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,835][INFO ][org.elasticsearch.cluster.service] [node_t1] added {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-join(join from node[{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,835][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,836][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,836][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,836][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]%0Aversion: 10%0Astate uuid: W7PuISv9S3efZyaJ9tkFOg%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,836][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,836][INFO ][org.elasticsearch.cluster.service] [node_t2] added {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,836][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,837][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]%0Aversion: 10%0Astate uuid: W7PuISv9S3efZyaJ9tkFOg%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[5], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[5], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,837][INFO ][org.elasticsearch.cluster.service] [node_t0] detected_master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], added {{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,837][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 10%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,838][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 10%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,839][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]: took 2ms done applying updated cluster_state (version: 10, uuid: W7PuISv9S3efZyaJ9tkFOg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,842][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [10]])]: took 5ms done applying updated cluster_state (version: 10, uuid: W7PuISv9S3efZyaJ9tkFOg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,842][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 10%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]])]: took 7ms done applying updated cluster_state (version: 10, uuid: W7PuISv9S3efZyaJ9tkFOg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,843][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,846][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(async_shard_fetch)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,846][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(async_shard_fetch)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,846][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [cluster_reroute(async_shard_fetch)]%0Aversion: 11%0Astate uuid: bUkXkpRdRO-AgIUX_2PJVg%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 7):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[6], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[6], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[6], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[6], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,846][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [11]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]%0Aversion: 11%0Astate uuid: bUkXkpRdRO-AgIUX_2PJVg%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 7):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[6], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[6], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[6], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[6], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 11%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]%0Aversion: 11%0Astate uuid: bUkXkpRdRO-AgIUX_2PJVg%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 7):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[6], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[6], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[6], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[6], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,847][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 11%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,852][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]: took 4ms done applying updated cluster_state (version: 11, uuid: bUkXkpRdRO-AgIUX_2PJVg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,852][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [11]])]: took 5ms done applying updated cluster_state (version: 11, uuid: bUkXkpRdRO-AgIUX_2PJVg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,852][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 11%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,857][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(async_shard_fetch)]: took 10ms done applying updated cluster_state (version: 11, uuid: bUkXkpRdRO-AgIUX_2PJVg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,893][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,893][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,894][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]%0Aversion: 12%0Astate uuid: JUK1gRX2RQKWXCApLm6iQQ%0Afrom_diff: false%0Ameta data version: 8%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 8):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[7], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[7], s[STARTED], a[id=C8_Nhc84TRaFdBuQDUhqJQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[7], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[7], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[7], s[STARTED], a[id=C8_Nhc84TRaFdBuQDUhqJQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[7], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,894][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [12]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]%0Aversion: 12%0Astate uuid: JUK1gRX2RQKWXCApLm6iQQ%0Afrom_diff: false%0Ameta data version: 8%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 8):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[7], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[7], s[STARTED], a[id=C8_Nhc84TRaFdBuQDUhqJQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[7], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[7], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[7], s[STARTED], a[id=C8_Nhc84TRaFdBuQDUhqJQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[7], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]%0Aversion: 12%0Astate uuid: JUK1gRX2RQKWXCApLm6iQQ%0Afrom_diff: false%0Ameta data version: 8%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 8):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[7], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[7], s[STARTED], a[id=C8_Nhc84TRaFdBuQDUhqJQ]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[7], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A--------[test][0], node[yydJUeVLQCm3TMKQnh84zA], [P], v[7], s[STARTED], a[id=b6T_XnHKTCKqZjy_hbUrYQ]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A--------[test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[7], s[STARTED], a[id=C8_Nhc84TRaFdBuQDUhqJQ]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A--------[test][0], node[OumL7QmnRy-QBngP7WrqnQ], [R], v[7], s[STARTED], a[id=ndRKElugRpaLmNd6g8wUmg]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 12%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,895][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 12%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,901][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]: took 5ms done applying updated cluster_state (version: 12, uuid: JUK1gRX2RQKWXCApLm6iQQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,903][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [12]])]: took 7ms done applying updated cluster_state (version: 12, uuid: JUK1gRX2RQKWXCApLm6iQQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,903][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 12%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,910][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [shard-started ([test][0], node[qTeJECMuQTiKskTN-_UYoQ], [R], v[6], s[INITIALIZING], a[id=C8_Nhc84TRaFdBuQDUhqJQ], unassigned_info[[reason=NODE_LEFT], at[2016-01-25T17:50:10.828Z], details[node_left[qTeJECMuQTiKskTN-_UYoQ]]]), reason [after recovery (replica) from node [{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]]]]: took 16ms done applying updated cluster_state (version: 12, uuid: JUK1gRX2RQKWXCApLm6iQQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,916][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [delete-index [test]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,916][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete-index [test]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,916][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [delete-index [test]]%0Aversion: 13%0Astate uuid: -wXveliBQDu84TkmBaUnxA%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,916][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [13]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]%0Aversion: 13%0Astate uuid: -wXveliBQDu84TkmBaUnxA%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network]%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 13%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,917][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]%0Aversion: 13%0Astate uuid: -wXveliBQDu84TkmBaUnxA%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network], local%0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[qTeJECMuQTiKskTN-_UYoQ][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,918][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 13%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,935][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]: took 18ms done applying updated cluster_state (version: 13, uuid: -wXveliBQDu84TkmBaUnxA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,935][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [13]])]: took 18ms done applying updated cluster_state (version: 13, uuid: -wXveliBQDu84TkmBaUnxA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,935][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 13%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,943][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete-index [test]]: took 27ms done applying updated cluster_state (version: 13, uuid: -wXveliBQDu84TkmBaUnxA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,944][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [delete_repository [*]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,944][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,944][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete_repository [*]]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,944][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-node_left({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,945][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_left({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,945][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-node_left({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network])]%0Aversion: 14%0Astate uuid: kqlYvbo9Rue-pico-VkiBA%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], local, master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network]%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,945][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-node_left({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,945][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [14]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,946][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [14]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,946][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [14]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,947][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [14]])]%0Aversion: 14%0Astate uuid: kqlYvbo9Rue-pico-VkiBA%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network], master%0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A-----node_id[OumL7QmnRy-QBngP7WrqnQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,947][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [14]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,947][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 14%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,947][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network] committed version [14]])]: took 0s done applying updated cluster_state (version: 14, uuid: kqlYvbo9Rue-pico-VkiBA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,947][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 14%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,948][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_left({node_t0}{qTeJECMuQTiKskTN-_UYoQ}{127.0.0.1}{127.0.0.1:30228}[mode=>network])]: took 2ms done applying updated cluster_state (version: 14, uuid: kqlYvbo9Rue-pico-VkiBA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,949][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,949][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,949][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,949][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]%0Aversion: 14%0Astate uuid: kqlYvbo9Rue-pico-VkiBA%0Afrom_diff: false%0Ameta data version: 9%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t2}{yydJUeVLQCm3TMKQnh84zA}{127.0.0.1}{127.0.0.1:30230}[mode=>network], local%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[yydJUeVLQCm3TMKQnh84zA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,949][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,950][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 14%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:13,956][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t1}{OumL7QmnRy-QBngP7WrqnQ}{127.0.0.1}{127.0.0.1:30229}[mode=>network])]: took 6ms done applying updated cluster_state (version: 14, uuid: kqlYvbo9Rue-pico-VkiBA)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744206686,
  "executionTime": 7284
 }
]

[
 "TEST_STARTED",
 "ID#testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:18,129][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = transport disconnected), current nodes: {{node_t0}{YIsCjCsCTsKG4FBWps88og}{127.0.0.1}{127.0.0.1:30231}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744213970,
  "executionTime": 10186
 }
]

[
 "TEST_STARTED",
 "ID#testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,178][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t0] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,178][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] using initial hosts [127.0.0.1:30233], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,178][DEBUG][org.elasticsearch.discovery.zen] [node_t0] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,178][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,178][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1202], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,189][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1203], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,204][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t1] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,204][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] using initial hosts [127.0.0.1:30233], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,204][DEBUG][org.elasticsearch.discovery.zen] [node_t1] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,204][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,204][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,213][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,213][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1205], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,214][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,215][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1206], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,227][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t2] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,227][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] using initial hosts [127.0.0.1:30233], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,227][DEBUG][org.elasticsearch.discovery.zen] [node_t2] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,227][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,228][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1208], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,237][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,238][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1209], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,262][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t3] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,262][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] using initial hosts [127.0.0.1:30233], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,262][DEBUG][org.elasticsearch.discovery.zen] [node_t3] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,262][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,262][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,272][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1211], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,273][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,273][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:24,273][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1212], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,690][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,690][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1214], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,690][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,690][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1215], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,690][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] with temp node {#zen_unicast_2_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] with temp node {#zen_unicast_3_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_2_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] with temp node {#zen_unicast_4_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_3_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_4_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,693][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_3_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,691][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,693][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_2_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,693][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,693][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_4_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,693][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_3_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1216], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,693][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_2_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1217], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,694][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_4_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1218], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,719][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,719][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,720][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,720][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,720][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1220], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,720][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1221], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,721][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,721][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,721][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1222], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,740][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,740][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,740][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,740][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,740][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1224], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,741][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1225], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,741][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,741][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,741][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1226], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,774][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,774][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,774][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,774][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connecting (light) to {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,774][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1228], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,775][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connected to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,775][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1229], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,775][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:25,776][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1230], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,191][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,191][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1232], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1233], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] with temp node {#zen_unicast_5_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] with temp node {#zen_unicast_6_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_5_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_6_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,192][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] with temp node {#zen_unicast_7_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_7_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_6_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_5_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,193][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_7_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_6_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1234], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_5_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1235], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_7_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1236], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_6_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1234], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1235], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1236], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1234], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1235], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1236], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_7_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,194][DEBUG][org.elasticsearch.discovery.zen] [node_t0] elected as master, waiting for incoming joins ([2] needed)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,195][TRACE][org.elasticsearch.discovery.zen] [node_t0] not enough joins for election. Got [0], required [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,195][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_3_VNnQ6kJMRI-VQoe6OX0Rlg#}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,195][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_5_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,195][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_4_sCcm3X0AReC2623JV1nqUA#}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,195][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_2_QQmvjMD0T5irb3fyXN38uA#}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,221][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,222][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,222][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,222][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,222][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1239], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,222][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1238], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,223][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,223][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,224][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1240], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,224][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,224][TRACE][org.elasticsearch.discovery.zen] [node_t1] full ping responses:%0A%09--> ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1240], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,225][DEBUG][org.elasticsearch.discovery.zen] [node_t1] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1240], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,225][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,225][TRACE][org.elasticsearch.discovery.zen] [node_t1] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,225][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,226][TRACE][org.elasticsearch.discovery.zen] [node_t1] joining master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,227][TRACE][org.elasticsearch.discovery.zen] [node_t0] not enough joins for election. Got [1], required [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,241][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,241][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,241][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,241][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,241][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1242], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,241][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1243], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,242][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,242][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,242][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1244], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,243][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,243][TRACE][org.elasticsearch.discovery.zen] [node_t2] full ping responses:%0A%09--> ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1244], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,243][DEBUG][org.elasticsearch.discovery.zen] [node_t2] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1244], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,243][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,243][TRACE][org.elasticsearch.discovery.zen] [node_t2] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,243][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,244][TRACE][org.elasticsearch.discovery.zen] [node_t2] joining master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,246][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-join(elected_as_master, [2] joins received)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,246][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-join(elected_as_master, [2] joins received)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,246][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-join(elected_as_master, [2] joins received)]%0Aversion: 1%0Astate uuid: _pVDzVJmRqee4kS1FOJklQ%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,246][INFO ][org.elasticsearch.cluster.service] [node_t0] new_master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}, reason: zen-disco-join(elected_as_master, [2] joins received)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,246][DEBUG][org.elasticsearch.cluster.service] [node_t0] publishing cluster state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received full cluster state version [1] with size [324]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received full cluster state version [1] with size [324]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] acked cluster state version [1]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] acked cluster state version [1]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] committing version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [_pVDzVJmRqee4kS1FOJklQ], version [1]) to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [_pVDzVJmRqee4kS1FOJklQ], version [1]) to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,247][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] restarting fault detection against master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] restarting fault detection against master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][DEBUG][org.elasticsearch.discovery.zen] [node_t2] got first state from fresh master [LjOjksDXR2GbagAUMwfHoQ]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][DEBUG][org.elasticsearch.discovery.zen] [node_t1] got first state from fresh master [LjOjksDXR2GbagAUMwfHoQ]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][TRACE][org.elasticsearch.discovery.zen] [node_t2] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][TRACE][org.elasticsearch.discovery.zen] [node_t1] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: _pVDzVJmRqee4kS1FOJklQ%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: _pVDzVJmRqee4kS1FOJklQ%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][INFO ][org.elasticsearch.cluster.service] [node_t2] detected_master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,248][INFO ][org.elasticsearch.cluster.service] [node_t1] detected_master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: took 2ms done applying updated cluster_state (version: 1, uuid: _pVDzVJmRqee4kS1FOJklQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: took 2ms done applying updated cluster_state (version: 1, uuid: _pVDzVJmRqee4kS1FOJklQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([election closed])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.discovery.zen] [node_t0] cluster joins counter set to [1] (elected as master)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-join(elected_as_master, [2] joins received)]: took 4ms done applying updated cluster_state (version: 1, uuid: _pVDzVJmRqee4kS1FOJklQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,251][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [local-gateway-elected-state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,251][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [local-gateway-elected-state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,251][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [local-gateway-elected-state]%0Aversion: 2%0Astate uuid: qljvqDUjQP2KJ8hCI3_W9A%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,251][DEBUG][org.elasticsearch.cluster.service] [node_t0] publishing cluster state version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [2] with uuid [qljvqDUjQP2KJ8hCI3_W9A], diff size [176]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [2] with uuid [qljvqDUjQP2KJ8hCI3_W9A], diff size [176]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] acked cluster state version [2]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] acked cluster state version [2]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] committing version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [qljvqDUjQP2KJ8hCI3_W9A], version [2]) to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [qljvqDUjQP2KJ8hCI3_W9A], version [2]) to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: qljvqDUjQP2KJ8hCI3_W9A%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: qljvqDUjQP2KJ8hCI3_W9A%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,252][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,255][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: took 2ms done applying updated cluster_state (version: 2, uuid: qljvqDUjQP2KJ8hCI3_W9A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,255][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: took 2ms done applying updated cluster_state (version: 2, uuid: qljvqDUjQP2KJ8hCI3_W9A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,255][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,257][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [local-gateway-elected-state]: took 6ms done applying updated cluster_state (version: 2, uuid: qljvqDUjQP2KJ8hCI3_W9A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connecting (light) to {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1245], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1246], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,276][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1245], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1247], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,276][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connected to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,276][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1201], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1204], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1207], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1210], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1213], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1219], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1223], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1227], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1231], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1245], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1245], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1248], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][TRACE][org.elasticsearch.discovery.zen] [node_t3] full ping responses:%0A%09--> ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1248], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][DEBUG][org.elasticsearch.discovery.zen] [node_t3] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1248], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1237], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1241], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][TRACE][org.elasticsearch.discovery.zen] [node_t3] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] disconnecting from {#zen_unicast_3_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,277][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] disconnecting from {#zen_unicast_2_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,278][TRACE][org.elasticsearch.discovery.zen] [node_t3] joining master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,279][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-join(join from node[{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,279][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-join(join from node[{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,279][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-join(join from node[{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,279][INFO ][org.elasticsearch.cluster.service] [node_t0] added {{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],}, reason: zen-disco-join(join from node[{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,279][DEBUG][org.elasticsearch.cluster.service] [node_t0] publishing cluster state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [3] with uuid [CZOQ0MSgThKGGO8LHfSysw], diff size [333]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [3] with uuid [CZOQ0MSgThKGGO8LHfSysw], diff size [333]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] acked cluster state version [3]. processing ... (current pending [3], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] acked cluster state version [3]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] committing version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [CZOQ0MSgThKGGO8LHfSysw], version [3]) to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received full cluster state version [3] with size [314]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [CZOQ0MSgThKGGO8LHfSysw], version [3]) to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][INFO ][org.elasticsearch.cluster.service] [node_t2] added {{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] sending commit for cluster state (uuid: [CZOQ0MSgThKGGO8LHfSysw], version [3]) to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,280][INFO ][org.elasticsearch.cluster.service] [node_t1] added {{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] restarting fault detection against master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][DEBUG][org.elasticsearch.discovery.zen] [node_t3] got first state from fresh master [LjOjksDXR2GbagAUMwfHoQ]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][TRACE][org.elasticsearch.discovery.zen] [node_t3] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], local%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,281][INFO ][org.elasticsearch.cluster.service] [node_t3] detected_master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,283][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,283][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,283][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: took 2ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,283][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: took 3ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,284][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: took 5ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-join(join from node[{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]])]: took 6ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [finalize_join ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:27,286][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen.fd] [node_t2] [master] [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen.fd] [node_t1] [master] [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][INFO ][org.elasticsearch.discovery.zen] [node_t2] master_left [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][INFO ][org.elasticsearch.discovery.zen] [node_t1] master_left [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] stopping fault detection against master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [master failure, transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] stopping fault detection against master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [master failure, transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = transport disconnected), current nodes: {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]%0Aversion: 4%0Astate uuid: CcIlZGsCSLO9JUYd6Up5-w%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][INFO ][org.elasticsearch.cluster.service] [node_t0] removed {{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}, reason: zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30233][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 1ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,249][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1250], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1252], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][DEBUG][org.elasticsearch.cluster.service] [node_t0] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,250][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30233][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,253][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] failed to send cluster state to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/publish/send]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateToNode(PublishClusterStateAction.java:268)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateDiff(PublishClusterStateAction.java:254)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:185)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 18 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,253][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] failed to send cluster state to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0ASendRequestTransportException[[node_t1][127.0.0.1:30234][internal:discovery/zen/publish/send]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateToNode(PublishClusterStateAction.java:268)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateDiff(PublishClusterStateAction.java:254)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:185)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 18 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,252][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,251][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,254][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,254][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,254][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1253], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,254][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,253][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] failed to ack cluster state version [4]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,254][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] failed to ack cluster state version [4]. processing ... (current pending [1], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,254][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] failed to commit version [4]. no more pending master nodes, but failed to reach needed acks ([2] left)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,255][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 5ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,255][DEBUG][org.elasticsearch.discovery.zen] [node_t0] failed to publish cluster state version [4] (not enough nodes acknowledged, min master nodes [3])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,255][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1254], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,255][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1256], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,255][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1255], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,255][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [4]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [2] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,256][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [2] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,256][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,256][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,256][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]%0Aversion: 4%0Astate uuid: N91DkpzBQVeqHuXeOViD6Q%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,256][INFO ][org.elasticsearch.cluster.service] [node_t0] removed {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],}, reason: zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,256][DEBUG][org.elasticsearch.cluster.service] [node_t0] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,257][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,257][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] failed to send cluster state to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/publish/send]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateToNode(PublishClusterStateAction.java:268)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateDiff(PublishClusterStateAction.java:254)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:185)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 18 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,257][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] failed to send cluster state to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0ASendRequestTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/publish/send]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateToNode(PublishClusterStateAction.java:268)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateDiff(PublishClusterStateAction.java:254)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:185)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 18 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,257][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] failed to ack cluster state version [4]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] failed to ack cluster state version [4]. processing ... (current pending [1], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] failed to commit version [4]. no more pending master nodes, but failed to reach needed acks ([2] left)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][DEBUG][org.elasticsearch.discovery.zen] [node_t0] failed to publish cluster state version [4] (not enough nodes acknowledged, min master nodes [3])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [4]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [2] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [2] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,258][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,259][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]%0Aversion: 4%0Astate uuid: aWfxv9dpQg-rg2JCGEycIA%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,259][INFO ][org.elasticsearch.cluster.service] [node_t0] removed {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],}, reason: zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,259][DEBUG][org.elasticsearch.cluster.service] [node_t0] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,259][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,259][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] failed to send cluster state to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/publish/send]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateToNode(PublishClusterStateAction.java:268)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateDiff(PublishClusterStateAction.java:254)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:185)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 18 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,259][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] failed to send cluster state to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0ASendRequestTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/publish/send]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateToNode(PublishClusterStateAction.java:268)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendClusterStateDiff(PublishClusterStateAction.java:254)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:185)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 18 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,260][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] failed to ack cluster state version [4]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,260][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] failed to ack cluster state version [4]. processing ... (current pending [1], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,260][TRACE][org.elasticsearch.discovery.zen.publish] [node_t0] failed to commit version [4]. no more pending master nodes, but failed to reach needed acks ([2] left)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,260][DEBUG][org.elasticsearch.discovery.zen] [node_t0] failed to publish cluster state version [4] (not enough nodes acknowledged, min master nodes [3])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,260][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [4]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [2] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-node_failed({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [2] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy34.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-failed-to-publish]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][WARN ][org.elasticsearch.discovery.zen] [node_t0] failed to publish to min_master_nodes, current nodes: {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-failed-to-publish]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1258], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-failed-to-publish]: took 0s done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1259], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][DEBUG][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]: local node is no longer master%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,261][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30234][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,262][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-failed-to-publish]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][DEBUG][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-failed-to-publish]: local node is no longer master%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-failed-to-publish]%0Aorg.elasticsearch.cluster.NotMasterException: no longer master. source: [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][DEBUG][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-node_failed({node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]), reason transport disconnected]: local node is no longer master%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-failed-to-publish]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][DEBUG][org.elasticsearch.cluster.service] [node_t0] failing [zen-disco-failed-to-publish]: local node is no longer master%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,263][ERROR][org.elasticsearch.discovery.zen] [node_t0] unexpected failure during [zen-disco-failed-to-publish]%0Aorg.elasticsearch.cluster.NotMasterException: no longer master. source: [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,285][TRACE][org.elasticsearch.discovery.zen.fd] [node_t3] [master] [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,285][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] stopping fault detection against master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [master failure, transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,285][INFO ][org.elasticsearch.discovery.zen] [node_t3] master_left [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], reason [transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,285][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,285][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,285][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = transport disconnected), current nodes: {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0Aversion: 3%0Astate uuid: CZOQ0MSgThKGGO8LHfSysw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], local%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][INFO ][org.elasticsearch.cluster.service] [node_t3] removed {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30233][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,288][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1261], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,288][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-master_failed ({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 3ms done applying updated cluster_state (version: 3, uuid: CZOQ0MSgThKGGO8LHfSysw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,286][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] failed to send ping to [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30233][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,289][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1262], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,290][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:28,291][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1263], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1266], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,756][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1268], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1267], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1269], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1271], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,757][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1270], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,761][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,761][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1273], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1274], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30234][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,762][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,764][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,790][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,790][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1276], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1277], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:29,792][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1278], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,259][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,259][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,259][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,259][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1281], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1283], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1282], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1285], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,261][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,260][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1284], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,262][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,262][TRACE][org.elasticsearch.discovery.zen] [node_t2] full ping responses:%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1282], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1283], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,262][DEBUG][org.elasticsearch.discovery.zen] [node_t2] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1282], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1283], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,262][TRACE][org.elasticsearch.discovery.zen] [node_t2] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,262][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1286], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,262][TRACE][org.elasticsearch.discovery.zen] [node_t2] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [2] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][TRACE][org.elasticsearch.discovery.zen] [node_t2] joining master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][TRACE][org.elasticsearch.discovery.zen] [node_t1] full ping responses:%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1285], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1286], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][DEBUG][org.elasticsearch.discovery.zen] [node_t1] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1285], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1286], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][TRACE][org.elasticsearch.discovery.zen] [node_t1] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][DEBUG][org.elasticsearch.discovery.zen] [node_t1] elected as master, waiting for incoming joins ([2] needed)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][TRACE][org.elasticsearch.discovery.zen] [node_t1] not enough joins for election. Got [0], required [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,263][TRACE][org.elasticsearch.discovery.zen] [node_t1] not enough joins for election. Got [1], required [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1288], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1289], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30234][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,271][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,270][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,273][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,273][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses: {none}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false]) {none}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen] [node_t0] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen] [node_t0] not enough master nodes [[{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1291], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1292], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,274][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,275][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30234][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30234] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,275][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0ASendRequestTransportException[[node_t3][127.0.0.1:30236][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30236] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,275][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,277][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30235] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.connectToNodeLight(MockTransportService.java:157)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1295], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1294], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,294][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1296], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][TRACE][org.elasticsearch.discovery.zen] [node_t3] full ping responses:%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1294], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1296], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][DEBUG][org.elasticsearch.discovery.zen] [node_t3] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1294], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1296], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][TRACE][org.elasticsearch.discovery.zen] [node_t3] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][TRACE][org.elasticsearch.discovery.zen] [node_t3] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,295][TRACE][org.elasticsearch.discovery.zen] [node_t3] joining master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(elected_as_master, [2] joins received)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(elected_as_master, [2] joins received)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][DEBUG][org.elasticsearch.discovery.zen] [node_t1] received a join request for an existing node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][DEBUG][org.elasticsearch.discovery.zen] [node_t1] received a join request for an existing node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(elected_as_master, [2] joins received)]%0Aversion: 4%0Astate uuid: bkCYHy31TYqnnVhArbJmcw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local, master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][INFO ][org.elasticsearch.cluster.service] [node_t1] new_master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], reason: zen-disco-join(elected_as_master, [2] joins received)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received diff cluster state version [4] with uuid [bkCYHy31TYqnnVhArbJmcw], diff size [310]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [4] with uuid [bkCYHy31TYqnnVhArbJmcw], diff size [310]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] acked cluster state version [4]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] acked cluster state version [4]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [bkCYHy31TYqnnVhArbJmcw], version [4]) to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,296][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [bkCYHy31TYqnnVhArbJmcw], version [4]) to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] restarting fault detection against master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] restarting fault detection against master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.discovery.zen] [node_t3] got first state from fresh master [QQmvjMD0T5irb3fyXN38uA]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.discovery.zen] [node_t2] got first state from fresh master [QQmvjMD0T5irb3fyXN38uA]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.discovery.zen] [node_t2] updated cluster join cluster to [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.discovery.zen] [node_t3] updated cluster join cluster to [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: bkCYHy31TYqnnVhArbJmcw%0Afrom_diff: true%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: bkCYHy31TYqnnVhArbJmcw%0Afrom_diff: true%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], local%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][INFO ][org.elasticsearch.cluster.service] [node_t2] detected_master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][INFO ][org.elasticsearch.cluster.service] [node_t3] detected_master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]: took 0s done applying updated cluster_state (version: 4, uuid: bkCYHy31TYqnnVhArbJmcw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [4]])]: took 0s done applying updated cluster_state (version: 4, uuid: bkCYHy31TYqnnVhArbJmcw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.discovery.zen] [node_t1] stopping join accumulation ([election closed])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.discovery.zen] [node_t1] cluster joins counter set to [2] (elected as master)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(elected_as_master, [2] joins received)]: took 1ms done applying updated cluster_state (version: 4, uuid: bkCYHy31TYqnnVhArbJmcw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,297][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:31,298][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,778][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,778][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1298], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,779][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,779][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1257], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1299], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,779][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,779][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,779][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,779][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1301], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,780][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1300], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:32,780][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1251], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1249], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1302], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,279][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,280][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1304], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,280][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,280][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]: [ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1272], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1287], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1290], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1305], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,281][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,281][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,281][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,281][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1306], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,282][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1307], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,282][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [3] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1260], master [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1308], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,283][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1307], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1306], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1308], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,283][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1307], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1306], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A%09--> ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1308], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,283][TRACE][org.elasticsearch.discovery.zen] [node_t0] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,283][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,283][TRACE][org.elasticsearch.discovery.zen] [node_t0] joining master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,285][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(join from node[{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,285][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,285][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(join from node[{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]])]%0Aversion: 5%0Astate uuid: L-fVko5uTUqvxMjknl_ahQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local, master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][INFO ][org.elasticsearch.cluster.service] [node_t1] added {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-join(join from node[{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received full cluster state version [5] with size [312]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received diff cluster state version [5] with uuid [L-fVko5uTUqvxMjknl_ahQ], diff size [331]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [5] with uuid [L-fVko5uTUqvxMjknl_ahQ], diff size [331]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] acked cluster state version [5]. processing ... (current pending [3], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] acked cluster state version [5]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [L-fVko5uTUqvxMjknl_ahQ], version [5]) to [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [L-fVko5uTUqvxMjknl_ahQ], version [5]) to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [L-fVko5uTUqvxMjknl_ahQ], version [5]) to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,286][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: L-fVko5uTUqvxMjknl_ahQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], local%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] restarting fault detection against master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][INFO ][org.elasticsearch.cluster.service] [node_t3] added {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][DEBUG][org.elasticsearch.discovery.zen] [node_t0] got first state from fresh master [QQmvjMD0T5irb3fyXN38uA]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][TRACE][org.elasticsearch.discovery.zen] [node_t0] updated cluster join cluster to [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: L-fVko5uTUqvxMjknl_ahQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: L-fVko5uTUqvxMjknl_ahQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[LjOjksDXR2GbagAUMwfHoQ][V]%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,287][INFO ][org.elasticsearch.cluster.service] [node_t2] added {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,288][INFO ][org.elasticsearch.cluster.service] [node_t0] detected_master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,288][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,288][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]: took 1ms done applying updated cluster_state (version: 5, uuid: L-fVko5uTUqvxMjknl_ahQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,289][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,289][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,289][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]: took 2ms done applying updated cluster_state (version: 5, uuid: L-fVko5uTUqvxMjknl_ahQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,289][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [5]])]: took 2ms done applying updated cluster_state (version: 5, uuid: L-fVko5uTUqvxMjknl_ahQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,289][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]])]: took 4ms done applying updated cluster_state (version: 5, uuid: L-fVko5uTUqvxMjknl_ahQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,290][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,292][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [delete_repository [*]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,292][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,292][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete_repository [*]]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,292][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] stopping fault detection against master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [zen disco stop]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-node_left({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_left({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-node_left({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0Aversion: 6%0Astate uuid: LoZZVoMgTM6Ob1o6fn_0qw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], local, master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-node_left({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [6]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received diff cluster state version [6] with uuid [LoZZVoMgTM6Ob1o6fn_0qw], diff size [308]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,293][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [6] with uuid [LoZZVoMgTM6Ob1o6fn_0qw], diff size [308]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,294][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network] acked cluster state version [6]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,294][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network] acked cluster state version [6]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,294][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [6]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,294][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [LoZZVoMgTM6Ob1o6fn_0qw], version [6]) to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,294][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [LoZZVoMgTM6Ob1o6fn_0qw], version [6]) to [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: LoZZVoMgTM6Ob1o6fn_0qw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: LoZZVoMgTM6Ob1o6fn_0qw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network], master%0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], local%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[QQmvjMD0T5irb3fyXN38uA][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][INFO ][org.elasticsearch.cluster.service] [node_t3] removed {{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]: took 0s done applying updated cluster_state (version: 6, uuid: LoZZVoMgTM6Ob1o6fn_0qw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network] committed version [6]])]: took 0s done applying updated cluster_state (version: 6, uuid: LoZZVoMgTM6Ob1o6fn_0qw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,295][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,296][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_left({node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 2ms done applying updated cluster_state (version: 6, uuid: LoZZVoMgTM6Ob1o6fn_0qw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,296][INFO ][org.elasticsearch.discovery.zen] [node_t2] master_left [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [shut_down]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,296][INFO ][org.elasticsearch.discovery.zen] [node_t3] master_left [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [shut_down]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,296][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = shut_down), current nodes: {{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] stopping fault detection against master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [master left (reason = shut_down)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] stopping fault detection against master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], reason [master left (reason = shut_down)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_4_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] replacing {node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network] with temp node {#zen_unicast_4_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0Aversion: 6%0Astate uuid: LoZZVoMgTM6Ob1o6fn_0qw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], local%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][INFO ][org.elasticsearch.cluster.service] [node_t3] removed {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] sending to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]%0Aversion: 6%0Astate uuid: LoZZVoMgTM6Ob1o6fn_0qw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A   {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[VNnQ6kJMRI-VQoe6OX0Rlg][V]%0A-----node_id[sCcm3X0AReC2623JV1nqUA][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] connecting (light) to {#zen_unicast_4_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: took 1ms done applying updated cluster_state (version: 6, uuid: LoZZVoMgTM6Ob1o6fn_0qw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,297][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30233];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30233%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] failed to connect to {#zen_unicast_4_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0AConnectTransportException[[][127.0.0.1:30233] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30233];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30233%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] connecting to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] sending to {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1309], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1311], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30233}%0AConnectTransportException[[][127.0.0.1:30233] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30233];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30233%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network])]: took 1ms done applying updated cluster_state (version: 6, uuid: LoZZVoMgTM6Ob1o6fn_0qw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to connect to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0ANodeDisconnectedException[[node_t1][127.0.0.1:30234][internal:discovery/zen/unicast] disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] connecting (light) to {#zen_unicast_4_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] received response from {node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1309], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1310], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1312], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] sending to {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [3] received response from {node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]: [ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1264], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1265], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1275], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1279], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], id[1280], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t3}{VNnQ6kJMRI-VQoe6OX0Rlg}{127.0.0.1}{127.0.0.1:30236}[mode=>network]], id[1293], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1297], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t0}{LjOjksDXR2GbagAUMwfHoQ}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], id[1303], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1309], master [{node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}, ping_response{node [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]], id[1313], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-2167855268204204833]-HASH=[142CBCAB6B3AC618]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] failed to connect to {node_t1}{QQmvjMD0T5irb3fyXN38uA}{127.0.0.1}{127.0.0.1:30234}[mode=>network]%0AConnectTransportException[[node_t1][127.0.0.1:30234] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30234];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:989)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:922)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:895)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNode(MockTransportService.java:408)%0A%09at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:235)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:398)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30234%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,302][TRACE][org.elasticsearch.discovery.zen.ping] [node_t2] pingAndWait interrupted%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,302][TRACE][org.elasticsearch.discovery.zen] [node_t2] No full ping responses%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,302][TRACE][org.elasticsearch.discovery.zen] [node_t2] thread is no longer in currentJoinThread. Stopping.%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [3] failed to connect to {#zen_unicast_4_LjOjksDXR2GbagAUMwfHoQ#}{127.0.0.1}{127.0.0.1:30233}[mode=>network]%0AConnectTransportException[[][127.0.0.1:30233] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30233];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30233%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,303][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] failed to send ping to [{node_t2}{sCcm3X0AReC2623JV1nqUA}{127.0.0.1}{127.0.0.1:30235}[mode=>network]]%0ARemoteTransportException[[node_t2][127.0.0.1:30235][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];%0ACaused by: java.lang.IllegalStateException: received ping request while not started%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:258)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:128)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,305][TRACE][org.elasticsearch.discovery.zen.ping] [node_t3] pingAndWait interrupted%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,305][TRACE][org.elasticsearch.discovery.zen] [node_t3] No full ping responses%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:34,305][TRACE][org.elasticsearch.discovery.zen] [node_t3] thread is no longer in currentJoinThread. Stopping.%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744224156,
  "executionTime": 10150
 }
]

[
 "TEST_STARTED",
 "ID#testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:40,630][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = transport disconnected), current nodes: {{node_t1}{2rAU4xfPRwyPA-j4Otj1RA}{127.0.0.1}{127.0.0.1:30238}[mode=>network, master=>false],{node_t2}{w8CAjUPKRXCQ9ZyF4qt3vg}{127.0.0.1}{127.0.0.1:30239}[master=>false, mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:40,630][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{2rAU4xfPRwyPA-j4Otj1RA}{127.0.0.1}{127.0.0.1:30238}[master=>false, mode=>network],{node_t2}{w8CAjUPKRXCQ9ZyF4qt3vg}{127.0.0.1}{127.0.0.1:30239}[mode=>network, master=>false],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744234307,
  "executionTime": 6330
 }
]

[
 "TEST_STARTED",
 "ID#testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:45,740][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{tB5bu-WWS86cH3ITcwFK3w}{127.0.0.1}{127.0.0.1:30240}[mode=>network],{node_t1}{oIBvtjefR7eBFT9qZA8Q-g}{127.0.0.1}{127.0.0.1:30241}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:49,494][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30241}]%0AReceiveTimeoutTransportException[[node_t1][127.0.0.1:30241][internal:discovery/zen/unicast] request_id [21] timed out after [3754ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:49,494][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{oIBvtjefR7eBFT9qZA8Q-g}{127.0.0.1}{127.0.0.1:30241}[mode=>network]]%0AReceiveTimeoutTransportException[[node_t1][127.0.0.1:30241][internal:discovery/zen/unicast] request_id [22] timed out after [3754ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:50,755][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{tB5bu-WWS86cH3ITcwFK3w}{127.0.0.1}{127.0.0.1:30240}[mode=>network],{node_t1}{oIBvtjefR7eBFT9qZA8Q-g}{127.0.0.1}{127.0.0.1:30241}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:53,790][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30241}]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:53,790][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{oIBvtjefR7eBFT9qZA8Q-g}{127.0.0.1}{127.0.0.1:30241}[mode=>network]]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:53,792][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{KVgQENVnQdSkobmw4Ke8ng}{127.0.0.1}{127.0.0.1:30242}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744240638,
  "executionTime": 13157
 }
]

[
 "TEST_STARTED",
 "ID#testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:50:57,893][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = transport disconnected), current nodes: {{node_t1}{XFxt-fVOSGi870x8FHhD9g}{127.0.0.1}{127.0.0.1:30244}[mode=>network],{node_t0}{QLR3DcF_SqyI1Q0gKPTkig}{127.0.0.1}{127.0.0.1:30243}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:51:00,914][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{K9PRxTHHTJyfcmQm6zHvfg}{127.0.0.1}{127.0.0.1:30245}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1453744253796,
  "executionTime": 7122
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
  "startTimestamp": 1453744114861,
  "executionTime": 146195
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.analyze.HunspellServiceIT",
   "displayName": "org.elasticsearch.indices.analyze.HunspellServiceIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
   "children": [
    {
     "id": "ID#testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testDicWithNoAff",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    },
    {
     "id": "ID#testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testLocaleDirectoryWithLocaleSpecificConfig",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    },
    {
     "id": "ID#testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testDicWithTwoAffs",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    },
    {
     "id": "ID#testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testLocaleDirectoryWithNodeLevelConfig",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744261060
 }
]

[
 "TEST_STARTED",
 "ID#testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1453744261068,
  "executionTime": 37
 }
]

[
 "TEST_STARTED",
 "ID#testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1453744261105,
  "executionTime": 1157
 }
]

[
 "TEST_STARTED",
 "ID#testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1453744262262,
  "executionTime": 34
 }
]

[
 "TEST_STARTED",
 "ID#testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1453744262296,
  "executionTime": 421
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.analyze.HunspellServiceIT",
  "startTimestamp": 1453744261060,
  "executionTime": 1666
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.ClusterInfoServiceIT",
   "displayName": "org.elasticsearch.cluster.ClusterInfoServiceIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.ClusterInfoServiceIT",
   "children": [
    {
     "id": "ID#testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "displayName": "testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "methodName": "testClusterInfoServiceCollectsInformation",
     "className": "org.elasticsearch.cluster.ClusterInfoServiceIT",
     "children": []
    },
    {
     "id": "ID#testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "displayName": "testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "methodName": "testClusterInfoServiceInformationClearOnError",
     "className": "org.elasticsearch.cluster.ClusterInfoServiceIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744262731
 }
]

[
 "TEST_STARTED",
 "ID#testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)",
  "startTimestamp": 1453744262739,
  "executionTime": 259
 }
]

[
 "TEST_STARTED",
 "ID#testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:51:05,253][WARN ][org.elasticsearch.cluster] [node_t0] Failed to execute NodeStatsAction for ClusterInfoUpdateJob%0AElasticsearchException[force exception on [cluster:monitor/nodes/stats]]%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT$BlockingActionFilter.apply(ClusterInfoServiceIT.java:105)%0A%09at org.elasticsearch.action.support.ActionFilter$Simple.apply(ActionFilter.java:64)%0A%09at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:134)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:108)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:255)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:291)%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT.testClusterInfoServiceInformationClearOnError(ClusterInfoServiceIT.java:250)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-01-25 12:51:05,254][WARN ][org.elasticsearch.cluster] [node_t0] Failed to execute IndicesStatsAction for ClusterInfoUpdateJob%0AElasticsearchException[force exception on [indices:monitor/stats]]%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT$BlockingActionFilter.apply(ClusterInfoServiceIT.java:105)%0A%09at org.elasticsearch.action.support.ActionFilter$Simple.apply(ActionFilter.java:64)%0A%09at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:134)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:108)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.updateIndicesStats(InternalClusterInfoService.java:269)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:320)%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT.testClusterInfoServiceInformationClearOnError(ClusterInfoServiceIT.java:250)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)",
  "startTimestamp": 1453744262998,
  "executionTime": 2365
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.ClusterInfoServiceIT",
  "startTimestamp": 1453744262731,
  "executionTime": 2644
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.document.AliasedIndexDocumentActionsIT",
   "displayName": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
   "methodName": null,
   "className": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
   "children": [
    {
     "id": "ID#testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "displayName": "testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "methodName": "testBulk",
     "className": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
     "children": []
    },
    {
     "id": "ID#testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "displayName": "testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "methodName": "testIndexActions",
     "className": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744265381
 }
]

[
 "TEST_STARTED",
 "ID#testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
  "startTimestamp": 1453744265390,
  "executionTime": 162
 }
]

[
 "TEST_STARTED",
 "ID#testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
  "startTimestamp": 1453744265552,
  "executionTime": 226
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.document.AliasedIndexDocumentActionsIT",
  "startTimestamp": 1453744265381,
  "executionTime": 405
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT",
   "displayName": "org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT",
   "methodName": null,
   "className": "org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT",
   "children": [
    {
     "id": "ID#testIndicesBoost(org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT)",
     "displayName": "testIndicesBoost(org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT)",
     "methodName": "testIndicesBoost",
     "className": "org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1453744265790
 }
]

[
 "TEST_STARTED",
 "ID#testIndicesBoost(org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndicesBoost(org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT)",
  "startTimestamp": 1453744265798,
  "executionTime": 503
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.indicesboost.SimpleIndicesBoostSearchIT",
  "startTimestamp": 1453744265790,
  "executionTime": 521
 }
]

[
 "IDLE",
 {}
]

[
 "QUIT",
 {}
]

