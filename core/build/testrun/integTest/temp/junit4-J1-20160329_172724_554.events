[
 "BOOTSTRAP",
 {
  "defaultCharset": "UTF-8",
  "pidString": "27395@host37-246.aruba.fit.edu",
  "systemProperties": {
   "awt.toolkit": "sun.lwawt.macosx.LWCToolkit",
   "es.logger.level": "WARN",
   "file.encoding": "UTF-8",
   "file.encoding.pkg": "sun.io",
   "file.separator": "/",
   "ftp.nonProxyHosts": "local|*.local|169.254/16|*.169.254/16",
   "gopherProxySet": "false",
   "http.nonProxyHosts": "local|*.local|169.254/16|*.169.254/16",
   "java.awt.graphicsenv": "sun.awt.CGraphicsEnvironment",
   "java.awt.headless": "true",
   "java.awt.printerjob": "sun.lwawt.macosx.CPrinterJob",
   "java.class.path": "/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/classes/test:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/resources/test:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/classes/main:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/resources/main:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-core/5.5.0-snapshot-1721183/f6854c65c7f4c6d9de583f4daa4fd3ae8a3800f1/lucene-core-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-analyzers-common/5.5.0-snapshot-1721183/69e187ef1d2d9c9570363eb4186821e0341df5b8/lucene-analyzers-common-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-backward-codecs/5.5.0-snapshot-1721183/fa00a45ff9bc6a4df44db81f2e4e44ea94bf88e/lucene-backward-codecs-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-grouping/5.5.0-snapshot-1721183/e996e6c723eb415ba2cfa7f5e98bbf194a4918dd/lucene-grouping-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-highlighter/5.5.0-snapshot-1721183/3b7a5d97b10885f16eb53deb15d64c942b9f9fdb/lucene-highlighter-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-join/5.5.0-snapshot-1721183/e4dda3eeb76e340aa4713a3b20d68c4a1504e505/lucene-join-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-memory/5.5.0-snapshot-1721183/800442a5d7612ce4c8748831871b4d436a50554e/lucene-memory-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-misc/5.5.0-snapshot-1721183/bdf184de9b5773c7af3ae908af78eeb1e512470c/lucene-misc-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queries/5.5.0-snapshot-1721183/fc59de52bd2c7e420edfd235723cb8b0dd44e92d/lucene-queries-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-queryparser/5.5.0-snapshot-1721183/1d341e6a4f11f3170773ccffdbe6815b45967e3d/lucene-queryparser-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-sandbox/5.5.0-snapshot-1721183/a1b02c2b595ac92f45f0d2be03841a3a7fcae1f1/lucene-sandbox-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial/5.5.0-snapshot-1721183/e3ea422b56734329fb6974e9cf9f66478adb5793/lucene-spatial-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-spatial3d/5.5.0-snapshot-1721183/5eadbd4e63120b59ab6445e39489205f98420471/lucene-spatial3d-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-suggest/5.5.0-snapshot-1721183/a336287e65d082535f02a8427666dbe46b1b9b74/lucene-suggest-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securesm/1.0/c0c6cf986ba0057390bfcc80c366a0e3157f944b/securesm-1.0.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.3.1/1303efbc4b181e5a58bf2e967dc156a3132b97c0/commons-cli-1.3.1.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch/hppc/0.7.1/8b5057f74ea378c0150a1860874a3ebdcb713767/hppc-0.7.1.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.8.2/d27c24204c5e507b16fec01006b3d0f1ec42aed4/joda-time-2.8.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.joda/joda-convert/1.2/35ec554f0cd00c956cc69051514d9488b1374dec/joda-convert-1.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.2/123f29333b2c6b3516b14252b6e93226bfcd6e37/jackson-core-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-smile/2.6.2/395d18c1a1dd730b8026ee59c4067e5d2b45ba6e/jackson-dataformat-smile-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-yaml/2.6.2/4ae23088dd3fae47c66843f2e4251d7255ee140e/jackson-dataformat-yaml-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-cbor/2.6.2/1e13c575f914c83761bb8e2aca7dfd9e4c647579/jackson-dataformat-cbor-2.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.10.5.Final/9ca7d55d246092bddd29b867706e2f6c7db701a0/netty-3.10.5.Final.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.tdunning/t-digest/3.0/84ccf145ac2215e6bfa63baa3101c0af41017cfc/t-digest-3.0.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.hdrhistogram/HdrHistogram/2.1.6/7495feb7f71ee124bd2a7e7d83590e296d71d80e/HdrHistogram-2.1.6.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.spatial4j/spatial4j/0.5/6e16edaf6b1ba76db7f08c2f3723fce3b358ecc3/spatial4j-0.5.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.vividsolutions/jts/1.13/3ccfb9b60f04d71add996a666ceb8902904fd805/jts-1.13.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/log4j/apache-log4j-extras/1.2.17/85863614d82185d7e51fe21c00aa9117a523a8b6/apache-log4j-extras-1.2.17.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.2/8619e95939167fb37245b5670135e4feb0ec7d50/slf4j-api-1.6.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/net.java.dev.jna/jna/4.1.0/1c12d070e602efd8021891cdd7fd18bc129372d4/jna-4.1.0.jar:/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/test/framework/build/libs/framework-3.0.0-SNAPSHOT.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/randomizedtesting-runner/2.3.2/307965917fe8a22b7ee72deba39ef4b8e6ebc069/randomizedtesting-runner-2.3.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-test-framework/5.5.0-snapshot-1721183/a8d851d0ad82182b3a02f4b30c336e7aa0e173cb/lucene-test-framework-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.lucene/lucene-codecs/5.5.0-snapshot-1721183/8aa59442b028c7a2c1a516accb6142a8910ba5fc/lucene-codecs-5.5.0-snapshot-1721183.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.3.6/4c47155e3e6c9a41a28db36680b828ced53b8af4/httpclient-4.3.6.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.3.3/f91b7a4aadc5cf486df6e4634748d7dd7a73f06d/httpcore-4.3.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.3/f6f66e966c70a83ffbdb6f17a0919eaf7c8aca7f/commons-logging-1.1.3.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.10/4b95f4897fa13f2cd904aee711aeafc0c5295cd8/commons-codec-1.10.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/org.elasticsearch/securemock/1.2/98201d4ad5ac93f6b415ae9172d52b5e7cda490e/securemock-1.2.jar:/Users/ogbonnayacngwu/.gradle/caches/modules-2/files-2.1/com.carrotsearch.randomizedtesting/junit4-ant/2.3.2/dc8f03f6111974092491f35b8269eb0fc57f52f7/junit4-ant-2.3.2.jar",
   "java.class.version": "52.0",
   "java.endorsed.dirs": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/endorsed",
   "java.ext.dirs": "/Users/ogbonnayacngwu/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java",
   "java.home": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre",
   "java.io.tmpdir": "./temp",
   "java.library.path": "/Users/ogbonnayacngwu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.",
   "java.runtime.name": "Java(TM) SE Runtime Environment",
   "java.runtime.version": "1.8.0_11-b12",
   "java.specification.name": "Java Platform API Specification",
   "java.specification.vendor": "Oracle Corporation",
   "java.specification.version": "1.8",
   "java.vendor": "Oracle Corporation",
   "java.vendor.url": "http://java.oracle.com/",
   "java.vendor.url.bug": "http://bugreport.sun.com/bugreport/",
   "java.version": "1.8.0_11",
   "java.vm.info": "mixed mode",
   "java.vm.name": "Java HotSpot(TM) 64-Bit Server VM",
   "java.vm.specification.name": "Java Virtual Machine Specification",
   "java.vm.specification.vendor": "Oracle Corporation",
   "java.vm.specification.version": "1.8",
   "java.vm.vendor": "Oracle Corporation",
   "java.vm.version": "25.11-b03",
   "junit4.childvm.count": "4",
   "junit4.childvm.cwd": "/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1",
   "junit4.childvm.id": "1",
   "junit4.memory.total": "514850816",
   "junit4.pidString": "27395@host37-246.aruba.fit.edu",
   "junit4.processors": "8",
   "line.separator": "\n",
   "os.arch": "x86_64",
   "os.name": "Mac OS X",
   "os.version": "10.11.4",
   "path.separator": ":",
   "socksNonProxyHosts": "local|*.local|169.254/16|*.169.254/16",
   "sun.arch.data.model": "64",
   "sun.boot.class.path": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/classes",
   "sun.boot.library.path": "/Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home/jre/lib",
   "sun.cpu.endian": "little",
   "sun.cpu.isalist": "",
   "sun.io.unicode.encoding": "UnicodeBig",
   "sun.java.command": "com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe -eventsfile /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160329_172724_554.events @/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/temp/junit4-J1-20160329_172724_554.suites -stdin",
   "sun.java.launcher": "SUN_STANDARD",
   "sun.jnu.encoding": "UTF-8",
   "sun.management.compiler": "HotSpot 64-Bit Tiered Compilers",
   "sun.os.patch.level": "unknown",
   "tests.artifact": "core",
   "tests.ifNoTests": "fail",
   "tests.maven": "true",
   "tests.prefix": "tests",
   "tests.security.manager": "true",
   "tests.seed": "4AA6DECDBC490785",
   "tests.task": ":core:integTest",
   "user.country": "US",
   "user.dir": "/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1",
   "user.home": "/Users/ogbonnayacngwu",
   "user.language": "en",
   "user.name": "ogbonnayacngwu",
   "user.timezone": "America/New_York"
  }
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.analyze.HunspellServiceIT",
   "displayName": "org.elasticsearch.indices.analyze.HunspellServiceIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
   "children": [
    {
     "id": "ID#testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testLocaleDirectoryWithLocaleSpecificConfig",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    },
    {
     "id": "ID#testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testDicWithTwoAffs",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    },
    {
     "id": "ID#testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testLocaleDirectoryWithNodeLevelConfig",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    },
    {
     "id": "ID#testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "displayName": "testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)",
     "methodName": "testDicWithNoAff",
     "className": "org.elasticsearch.indices.analyze.HunspellServiceIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286845318
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:27:25,572][WARN ][org.elasticsearch.bootstrap] Unable to lock JVM Memory: error=78,reason=Function not implemented%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:27:25,572][WARN ][org.elasticsearch.bootstrap] This can result in part of the JVM being swapped out.%0A"
 }
]

[
 "TEST_STARTED",
 "ID#testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLocaleDirectoryWithLocaleSpecificConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1459286847460,
  "executionTime": 9619
 }
]

[
 "TEST_STARTED",
 "ID#testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDicWithTwoAffs(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1459286857080,
  "executionTime": 482
 }
]

[
 "TEST_STARTED",
 "ID#testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLocaleDirectoryWithNodeLevelConfig(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1459286857562,
  "executionTime": 3250
 }
]

[
 "TEST_STARTED",
 "ID#testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:27:40,852][ERROR][org.elasticsearch.indices.analysis] [node_t0] exception while loading dictionary en_US%0Ajava.lang.IllegalStateException: failed to load hunspell dictionary for locale: en_US%0A%09at org.elasticsearch.indices.analysis.HunspellService.lambda$new$135(HunspellService.java:91)%0A%09at org.elasticsearch.indices.analysis.HunspellService$$Lambda$286/231930939.apply(Unknown Source)%0A%09at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)%0A%09at org.elasticsearch.indices.analysis.HunspellService.getDictionary(HunspellService.java:108)%0A%09at org.elasticsearch.indices.analysis.HunspellService.scanAndLoadDictionaries(HunspellService.java:132)%0A%09at org.elasticsearch.indices.analysis.HunspellService.<init>(HunspellService.java:95)%0A%09at org.elasticsearch.indices.analysis.AnalysisModule.configure(AnalysisModule.java:163)%0A%09at org.elasticsearch.common.inject.AbstractModule.configure(AbstractModule.java:59)%0A%09at org.elasticsearch.common.inject.spi.Elements$RecordingBinder.install(Elements.java:233)%0A%09at org.elasticsearch.common.inject.spi.Elements.getElements(Elements.java:103)%0A%09at org.elasticsearch.common.inject.InjectorShell$Builder.build(InjectorShell.java:148)%0A%09at org.elasticsearch.common.inject.InjectorBuilder.build(InjectorBuilder.java:99)%0A%09at org.elasticsearch.common.inject.Guice.createInjector(Guice.java:96)%0A%09at org.elasticsearch.common.inject.Guice.createInjector(Guice.java:70)%0A%09at org.elasticsearch.common.inject.ModulesBuilder.createInjector(ModulesBuilder.java:46)%0A%09at org.elasticsearch.node.Node.<init>(Node.java:203)%0A%09at org.elasticsearch.node.MockNode.<init>(MockNode.java:43)%0A%09at org.elasticsearch.test.InternalTestCluster.buildNode(InternalTestCluster.java:601)%0A%09at org.elasticsearch.test.InternalTestCluster.buildNode(InternalTestCluster.java:580)%0A%09at org.elasticsearch.test.InternalTestCluster.startNode(InternalTestCluster.java:1457)%0A%09at org.elasticsearch.test.InternalTestCluster.startNode(InternalTestCluster.java:1450)%0A%09at org.elasticsearch.indices.analyze.HunspellServiceIT.testDicWithNoAff(HunspellServiceIT.java:83)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ElasticsearchException[Missing affix file for hunspell dictionary [en_US]]%0A%09at org.elasticsearch.indices.analysis.HunspellService.loadDictionary(HunspellService.java:171)%0A%09at org.elasticsearch.indices.analysis.HunspellService.lambda$new$135(HunspellService.java:89)%0A%09... 58 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDicWithNoAff(org.elasticsearch.indices.analyze.HunspellServiceIT)",
  "startTimestamp": 1459286860813,
  "executionTime": 152
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.analyze.HunspellServiceIT",
  "startTimestamp": 1459286845318,
  "executionTime": 15677
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.SearchTimeoutIT",
   "displayName": "org.elasticsearch.search.SearchTimeoutIT",
   "methodName": null,
   "className": "org.elasticsearch.search.SearchTimeoutIT",
   "children": [
    {
     "id": "ID#testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)",
     "displayName": "testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)",
     "methodName": "testSimpleTimeout",
     "className": "org.elasticsearch.search.SearchTimeoutIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286861004
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleTimeout(org.elasticsearch.search.SearchTimeoutIT)",
  "startTimestamp": 1459286861023,
  "executionTime": 3986
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:27:45,015][WARN ][org.elasticsearch.test.transport] [node_s1] Transport response handler not found of id [62]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.SearchTimeoutIT",
  "startTimestamp": 1459286861004,
  "executionTime": 4027
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.recovery.SimpleRecoveryIT",
   "displayName": "org.elasticsearch.recovery.SimpleRecoveryIT",
   "methodName": null,
   "className": "org.elasticsearch.recovery.SimpleRecoveryIT",
   "children": [
    {
     "id": "ID#testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)",
     "displayName": "testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)",
     "methodName": "testSimpleRecovery",
     "className": "org.elasticsearch.recovery.SimpleRecoveryIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286865040
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleRecovery(org.elasticsearch.recovery.SimpleRecoveryIT)",
  "startTimestamp": 1459286865061,
  "executionTime": 3155
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.recovery.SimpleRecoveryIT",
  "startTimestamp": 1459286865040,
  "executionTime": 3250
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.ClusterInfoServiceIT",
   "displayName": "org.elasticsearch.cluster.ClusterInfoServiceIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.ClusterInfoServiceIT",
   "children": [
    {
     "id": "ID#testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "displayName": "testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "methodName": "testClusterInfoServiceInformationClearOnError",
     "className": "org.elasticsearch.cluster.ClusterInfoServiceIT",
     "children": []
    },
    {
     "id": "ID#testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "displayName": "testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)",
     "methodName": "testClusterInfoServiceCollectsInformation",
     "className": "org.elasticsearch.cluster.ClusterInfoServiceIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286868300
 }
]

[
 "TEST_STARTED",
 "ID#testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:27:50,712][WARN ][org.elasticsearch.cluster] [node_t0] Failed to execute NodeStatsAction for ClusterInfoUpdateJob%0AElasticsearchException[force exception on [cluster:monitor/nodes/stats]]%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT$BlockingActionFilter.apply(ClusterInfoServiceIT.java:105)%0A%09at org.elasticsearch.action.support.ActionFilter$Simple.apply(ActionFilter.java:64)%0A%09at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:134)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:108)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:255)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:291)%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT.testClusterInfoServiceInformationClearOnError(ClusterInfoServiceIT.java:250)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:27:50,714][WARN ][org.elasticsearch.cluster] [node_t0] Failed to execute IndicesStatsAction for ClusterInfoUpdateJob%0AElasticsearchException[force exception on [indices:monitor/stats]]%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT$BlockingActionFilter.apply(ClusterInfoServiceIT.java:105)%0A%09at org.elasticsearch.action.support.ActionFilter$Simple.apply(ActionFilter.java:64)%0A%09at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:134)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:108)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.updateIndicesStats(InternalClusterInfoService.java:269)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:320)%0A%09at org.elasticsearch.cluster.ClusterInfoServiceIT.testClusterInfoServiceInformationClearOnError(ClusterInfoServiceIT.java:250)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterInfoServiceInformationClearOnError(org.elasticsearch.cluster.ClusterInfoServiceIT)",
  "startTimestamp": 1459286868319,
  "executionTime": 2507
 }
]

[
 "TEST_STARTED",
 "ID#testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterInfoServiceCollectsInformation(org.elasticsearch.cluster.ClusterInfoServiceIT)",
  "startTimestamp": 1459286870827,
  "executionTime": 553
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.ClusterInfoServiceIT",
  "startTimestamp": 1459286868300,
  "executionTime": 3089
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.client.node.NodeClientIT",
   "displayName": "org.elasticsearch.client.node.NodeClientIT",
   "methodName": null,
   "className": "org.elasticsearch.client.node.NodeClientIT",
   "children": [
    {
     "id": "ID#testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)",
     "displayName": "testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)",
     "methodName": "testThatClientTypeSettingCannotBeChanged",
     "className": "org.elasticsearch.client.node.NodeClientIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286871397
 }
]

[
 "TEST_STARTED",
 "ID#testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThatClientTypeSettingCannotBeChanged(org.elasticsearch.client.node.NodeClientIT)",
  "startTimestamp": 1459286871413,
  "executionTime": 228
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.client.node.NodeClientIT",
  "startTimestamp": 1459286871397,
  "executionTime": 254
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.source.SourceFetchingIT",
   "displayName": "org.elasticsearch.search.source.SourceFetchingIT",
   "methodName": null,
   "className": "org.elasticsearch.search.source.SourceFetchingIT",
   "children": [
    {
     "id": "ID#testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)",
     "displayName": "testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)",
     "methodName": "testSourceDefaultBehavior",
     "className": "org.elasticsearch.search.source.SourceFetchingIT",
     "children": []
    },
    {
     "id": "ID#testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "displayName": "testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "methodName": "testSourceFiltering",
     "className": "org.elasticsearch.search.source.SourceFetchingIT",
     "children": []
    },
    {
     "id": "ID#testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "displayName": "testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
     "methodName": "testSourceWithWildcardFiltering",
     "className": "org.elasticsearch.search.source.SourceFetchingIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286871660
 }
]

[
 "TEST_STARTED",
 "ID#testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSourceDefaultBehavior(org.elasticsearch.search.source.SourceFetchingIT)",
  "startTimestamp": 1459286871676,
  "executionTime": 615
 }
]

[
 "TEST_STARTED",
 "ID#testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSourceFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
  "startTimestamp": 1459286872291,
  "executionTime": 489
 }
]

[
 "TEST_STARTED",
 "ID#testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSourceWithWildcardFiltering(org.elasticsearch.search.source.SourceFetchingIT)",
  "startTimestamp": 1459286872780,
  "executionTime": 965
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.source.SourceFetchingIT",
  "startTimestamp": 1459286871660,
  "executionTime": 2111
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.percolator.MultiPercolatorIT",
   "displayName": "org.elasticsearch.percolator.MultiPercolatorIT",
   "methodName": null,
   "className": "org.elasticsearch.percolator.MultiPercolatorIT",
   "children": [
    {
     "id": "ID#testBasics(org.elasticsearch.percolator.MultiPercolatorIT)",
     "displayName": "testBasics(org.elasticsearch.percolator.MultiPercolatorIT)",
     "methodName": "testBasics",
     "className": "org.elasticsearch.percolator.MultiPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testWithDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)",
     "displayName": "testWithDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)",
     "methodName": "testWithDocsOnly",
     "className": "org.elasticsearch.percolator.MultiPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testStartTimeIsPropagatedToShardRequests(org.elasticsearch.percolator.MultiPercolatorIT)",
     "displayName": "testStartTimeIsPropagatedToShardRequests(org.elasticsearch.percolator.MultiPercolatorIT)",
     "methodName": "testStartTimeIsPropagatedToShardRequests",
     "className": "org.elasticsearch.percolator.MultiPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testNestedMultiPercolation(org.elasticsearch.percolator.MultiPercolatorIT)",
     "displayName": "testNestedMultiPercolation(org.elasticsearch.percolator.MultiPercolatorIT)",
     "methodName": "testNestedMultiPercolation",
     "className": "org.elasticsearch.percolator.MultiPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testExistingDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)",
     "displayName": "testExistingDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)",
     "methodName": "testExistingDocsOnly",
     "className": "org.elasticsearch.percolator.MultiPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testWithRouting(org.elasticsearch.percolator.MultiPercolatorIT)",
     "displayName": "testWithRouting(org.elasticsearch.percolator.MultiPercolatorIT)",
     "methodName": "testWithRouting",
     "className": "org.elasticsearch.percolator.MultiPercolatorIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286873781
 }
]

[
 "TEST_STARTED",
 "ID#testBasics(org.elasticsearch.percolator.MultiPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBasics(org.elasticsearch.percolator.MultiPercolatorIT)",
  "startTimestamp": 1459286873802,
  "executionTime": 535
 }
]

[
 "TEST_STARTED",
 "ID#testWithDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)",
  "startTimestamp": 1459286874337,
  "executionTime": 1649
 }
]

[
 "TEST_STARTED",
 "ID#testStartTimeIsPropagatedToShardRequests(org.elasticsearch.percolator.MultiPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStartTimeIsPropagatedToShardRequests(org.elasticsearch.percolator.MultiPercolatorIT)",
  "startTimestamp": 1459286875986,
  "executionTime": 371
 }
]

[
 "TEST_STARTED",
 "ID#testNestedMultiPercolation(org.elasticsearch.percolator.MultiPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNestedMultiPercolation(org.elasticsearch.percolator.MultiPercolatorIT)",
  "startTimestamp": 1459286876358,
  "executionTime": 179
 }
]

[
 "TEST_STARTED",
 "ID#testExistingDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExistingDocsOnly(org.elasticsearch.percolator.MultiPercolatorIT)",
  "startTimestamp": 1459286876537,
  "executionTime": 465
 }
]

[
 "TEST_STARTED",
 "ID#testWithRouting(org.elasticsearch.percolator.MultiPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithRouting(org.elasticsearch.percolator.MultiPercolatorIT)",
  "startTimestamp": 1459286877002,
  "executionTime": 113
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.percolator.MultiPercolatorIT",
  "startTimestamp": 1459286873781,
  "executionTime": 3343
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.transport.ActionNamesIT",
   "displayName": "org.elasticsearch.transport.ActionNamesIT",
   "methodName": null,
   "className": "org.elasticsearch.transport.ActionNamesIT",
   "children": [
    {
     "id": "ID#testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)",
     "displayName": "testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)",
     "methodName": "testActionNamesCategories",
     "className": "org.elasticsearch.transport.ActionNamesIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286877131
 }
]

[
 "TEST_STARTED",
 "ID#testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testActionNamesCategories(org.elasticsearch.transport.ActionNamesIT)",
  "startTimestamp": 1459286877146,
  "executionTime": 118
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.transport.ActionNamesIT",
  "startTimestamp": 1459286877131,
  "executionTime": 144
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
   "displayName": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
   "methodName": null,
   "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
   "children": [
    {
     "id": "ID#testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteIndexDuringSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRestoreAliases",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testFreshIndexUUID",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotStatus",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testBatchingShardUpdateTask",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotName",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotMoreThanOnce",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRenameOnRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshotWithCorruptedSnapshotFile",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDataFileFailureDuringSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteRepositoryWhileSnapshotting",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testListCorruptedSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testUnallocatedShards",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotClosedIndex",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeletionOfFailingToRecoverIndexShouldStopRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testUrlRepository",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testBasicWorkFlow",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotFileFailureDuringSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testEmptySnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testReadonlyRepository",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDataFileFailureDuringRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRestoreWithDifferentMappingsAndSettings",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testIncludeGlobalState",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshotWithMissingMetadata",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteSnapshotWithMissingIndexAndShardMetadata",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRestoreTemplates",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotSingleClosedIndex",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testMoveShardWhileSnapshotting",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSnapshotRelocatingPrimary",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testDeleteOrphanSnapshot",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testThrottling",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testChangeSettingsOnRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testRecreateBlocksOnRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    },
    {
     "id": "ID#testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "displayName": "testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
     "methodName": "testSingleGetAfterRestore",
     "className": "org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286877302
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteIndexDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286877334,
  "executionTime": 5175
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreAliases(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286882510,
  "executionTime": 4068
 }
]

[
 "TEST_STARTED",
 "ID#testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFreshIndexUUID(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286886579,
  "executionTime": 2558
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotStatus(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286889137,
  "executionTime": 1521
 }
]

[
 "TEST_STARTED",
 "ID#testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,706][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,707][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,708][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index-template [random_index_template], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,708][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [136], source [create-index-template [random_index_template], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,708][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [136]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [136], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [136], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 136%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 136, uuid: yG487qMWRlu3pgfXKIvm5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,709][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 136%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,715][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 136, uuid: yG487qMWRlu3pgfXKIvm5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,715][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 136%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,719][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index-template [random_index_template], cause [api]]: took 11ms done applying updated cluster_state (version: 136, uuid: yG487qMWRlu3pgfXKIvm5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,720][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put_repository [test-repo]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [137], source [put_repository [test-repo]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [137]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [137], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 137%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 137, uuid: 3ch5diOYT7G9J7qwCysxhw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,722][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [137], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,723][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 137%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,728][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 137, uuid: 3ch5diOYT7G9J7qwCysxhw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,728][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 137%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,736][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put_repository [test-repo]]: took 15ms done applying updated cluster_state (version: 137, uuid: 3ch5diOYT7G9J7qwCysxhw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,737][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test-idx], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,740][INFO ][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] creating index, cause [api], templates [random_index_template], shards [7]/[0], mappings [_default_]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,742][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [138], source [create-index [test-idx], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [138]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [138], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 138%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [138], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,743][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 138%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,744][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 138, uuid: _JiHk6JXQyqwkejzGKgsAA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,868][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 2 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,869][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard started for [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,952][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 208ms done applying updated cluster_state (version: 138, uuid: _JiHk6JXQyqwkejzGKgsAA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,952][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 138%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,953][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 4 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:10,953][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard started for [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,022][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 6 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,023][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard started for [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,027][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,027][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,028][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,029][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,046][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create-index [test-idx], cause [api]]: took 309ms done applying updated cluster_state (version: 138, uuid: _JiHk6JXQyqwkejzGKgsAA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 3 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard started for [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,047][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [139], source [shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,048][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [139]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,049][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [139], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 139%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,049][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [139], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 139%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,050][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 139, uuid: Gl18JFAoT3yELUoyIV1YDQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,057][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 5 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,057][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard started for [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from store], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,061][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 11ms done applying updated cluster_state (version: 139, uuid: Gl18JFAoT3yELUoyIV1YDQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,062][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 139%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,063][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 3 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,063][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard started for [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,063][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 5 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,064][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard started for [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,069][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=YOikxL-aQlC-qPNGjfgbQg], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=F1tf5P7OSF-tn5_jvar_3Q], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=n8FGa0CeRxyOp-_8HA2KDw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], s[INITIALIZING], a[id=VxHYIrKdT4uTnJGXD-MmqQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=-NxnugfNRzqjoo-KEqocDA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store]]: took 22ms done applying updated cluster_state (version: 139, uuid: Gl18JFAoT3yELUoyIV1YDQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,070][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,070][INFO ][org.elasticsearch.cluster.routing.allocation] [node_s0] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test-idx][3], [test-idx][5], [test-idx][3], [test-idx][5]] ...]).%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [140], source [shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [140]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [140], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 140%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,071][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [140], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 140%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,072][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 140, uuid: 9amE80iXQuGYKOFG9CEX_Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,078][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 140, uuid: 9amE80iXQuGYKOFG9CEX_Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,078][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,078][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 140%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 8ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [after recovery from store],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=XsReXr1wTlOUOZW52Xb6Mw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started],shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], s[INITIALIZING], a[id=ekaSQeqJT6Wm544nIpiCKA], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:28:10.740Z]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 16ms done applying updated cluster_state (version: 140, uuid: 9amE80iXQuGYKOFG9CEX_Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,087][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,088][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,088][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,088][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,089][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,095][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,095][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,096][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,096][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,104][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,104][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,104][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,111][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,111][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,118][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 6ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,118][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,119][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,124][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,127][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] create_mapping [RANDOM_BOGUS_TYPE______] with source [{\"RANDOM_BOGUS_TYPE______\":{\"_timestamp\":{\"enabled\":false},\"dynamic_templates\":[{\"template-strings\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager_global_ordinals\"}},\"match_mapping_type\":\"string\"}},{\"template-longs\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"long\"}},{\"template-doubles\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"double\"}},{\"template-geo_points\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager\"}},\"match_mapping_type\":\"geo_point\"}},{\"template-booleans\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"boolean\"}}]}}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,133][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] create_mapping [type1] with source [{\"type1\":{\"_timestamp\":{\"enabled\":false},\"dynamic_templates\":[{\"template-strings\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager_global_ordinals\"}},\"match_mapping_type\":\"string\"}},{\"template-longs\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"long\"}},{\"template-doubles\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"double\"}},{\"template-geo_points\":{\"mapping\":{\"fielddata\":{\"loading\":\"eager\"}},\"match_mapping_type\":\"geo_point\"}},{\"template-booleans\":{\"mapping\":{\"fielddata\":{\"loading\":\"lazy\"}},\"match_mapping_type\":\"boolean\"}}],\"properties\":{\"field1\":{\"type\":\"string\",\"fielddata\":{\"loading\":\"eager_global_ordinals\"}}}}}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,141][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [141], source [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,141][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [141]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,142][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,143][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [141], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,143][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 141%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,143][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 141, uuid: 8X9mF9gRSZ-DZhiKMS1iTA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,142][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,144][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [141], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,144][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 141%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,152][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 8ms done applying updated cluster_state (version: 141, uuid: 8X9mF9gRSZ-DZhiKMS1iTA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,157][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 141%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,162][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1],put-mapping [type1],put-mapping [type1],put-mapping [type1]]: took 37ms done applying updated cluster_state (version: 141, uuid: 8X9mF9gRSZ-DZhiKMS1iTA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,185][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,206][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [RANDOM_BOGUS_TYPE______],put-mapping [type1]]: took 20ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create_snapshot [test-snap]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [142], source [create_snapshot [test-snap]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [142]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [142], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [142], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 142%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,924][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 142%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,924][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 142, uuid: lK95ctCGRsqCfCrr5wxNpA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,926][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 2ms done applying updated cluster_state (version: 142, uuid: lK95ctCGRsqCfCrr5wxNpA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,926][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 142%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,928][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [create_snapshot [test-snap]]: took 4ms done applying updated cluster_state (version: 142, uuid: lK95ctCGRsqCfCrr5wxNpA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update_snapshot [test-snap]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [143], source [update_snapshot [test-snap]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [143]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,932][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [143], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [143], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 143%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 143%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 143, uuid: VK3ffK9YRBya2UfesAUiDg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 143, uuid: VK3ffK9YRBya2UfesAUiDg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,933][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 143%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update_snapshot [test-snap]]: took 2ms done applying updated cluster_state (version: 143, uuid: VK3ffK9YRBya2UfesAUiDg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:11,935][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,207][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 272ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,207][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [144], source [update snapshot state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [144]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [144], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [144], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 144%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 144%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,208][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 144, uuid: QTPZSYPeRkmh5zX92WLGvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,210][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 144%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,210][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 1ms done applying updated cluster_state (version: 144, uuid: QTPZSYPeRkmh5zX92WLGvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 3ms done applying updated cluster_state (version: 144, uuid: QTPZSYPeRkmh5zX92WLGvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,211][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove snapshot metadata]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [145], source [remove snapshot metadata]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [145]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [145], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [145], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 145%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,212][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 145%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,213][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 145, uuid: 7TsUjeS6QVWeB08-jZ86FA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,213][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 145, uuid: 7TsUjeS6QVWeB08-jZ86FA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,213][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 145%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,214][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove snapshot metadata]: took 1ms done applying updated cluster_state (version: 145, uuid: 7TsUjeS6QVWeB08-jZ86FA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,214][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [close-indices [test-idx]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,214][INFO ][org.elasticsearch.cluster.metadata] [node_s0] closing indices [[test-idx]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [146], source [close-indices [test-idx]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [146]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [146], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 146%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [146], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,215][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 146%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,216][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 146, uuid: rpKSK5acQEa--KGz87l21g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,328][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 146%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,328][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 112ms done applying updated cluster_state (version: 146, uuid: rpKSK5acQEa--KGz87l21g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,370][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [close-indices [test-idx]]: took 155ms done applying updated cluster_state (version: 146, uuid: rpKSK5acQEa--KGz87l21g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,372][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [restore_snapshot[test-snap]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,377][DEBUG][org.elasticsearch.cluster.routing.allocation.allocator] [node_s0] skipping rebalance due to in-flight shard/store fetches%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,377][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [147], source [restore_snapshot[test-snap]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,378][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [147]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,381][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,378][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [147], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 147%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [147], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 147, uuid: iwY7Qlj-Tc6V6m8bq9zGlw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,382][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 147%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,388][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 6ms done applying updated cluster_state (version: 147, uuid: iwY7Qlj-Tc6V6m8bq9zGlw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,388][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 147%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,393][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [restore_snapshot[test-snap]]: took 20ms done applying updated cluster_state (version: 147, uuid: iwY7Qlj-Tc6V6m8bq9zGlw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,393][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_reroute(async_shard_fetch)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [148], source [cluster_reroute(async_shard_fetch)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [148]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [148], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 148%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,396][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,397][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 148, uuid: UO-y2AtgQkWvXqtLGT2J3A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,397][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [148], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,397][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 148%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,429][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 31ms done applying updated cluster_state (version: 148, uuid: UO-y2AtgQkWvXqtLGT2J3A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,429][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 148%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,460][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 4 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,460][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][4] received shard started for [[test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,464][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 2 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,464][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard started for [[test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,472][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [cluster_reroute(async_shard_fetch)]: took 78ms done applying updated cluster_state (version: 148, uuid: UO-y2AtgQkWvXqtLGT2J3A)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,473][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,474][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [149], source [shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,474][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [149]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,474][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [149], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [149], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 149%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,475][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 149%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,476][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 149, uuid: 9of1pkgRTRqBW2CQL6sH6w)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,484][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 9ms done applying updated cluster_state (version: 149, uuid: 9of1pkgRTRqBW2CQL6sH6w)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,484][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 149%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,490][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][4], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Fwvxs1nvTWuTlu3G83eMDQ], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=_6QertK2RtaZ50b5fRuydA], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: took 17ms done applying updated cluster_state (version: 149, uuid: 9of1pkgRTRqBW2CQL6sH6w)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,491][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,533][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 5 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,534][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][5] received shard started for [[test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,538][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 1 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,538][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][1] received shard started for [[test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,559][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 6 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,560][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][6] received shard started for [[test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,588][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] 3 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,589][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard started for [[test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,593][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 102ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,594][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,594][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,594][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [after recovery from repository], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,595][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [150], source [shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,596][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [150]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,596][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,596][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [150], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [150], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 150%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 150%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,597][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 150, uuid: CAC7dwrsQoS7i31fkflPrQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,599][DEBUG][org.elasticsearch.cluster.action.shard] [node_s1] 0 sending [internal:cluster/shard/started] to [-dn8ccnpRLqYmunDCVfdUA] for shard [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,599][DEBUG][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][0] received shard started for [[test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]], indexUUID [OVvfc1ywS6ew80mkZJlNzA], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started], failure [Unknown]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,605][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 8ms done applying updated cluster_state (version: 150, uuid: CAC7dwrsQoS7i31fkflPrQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,606][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 150%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,621][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][5], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=tpCx_qHzSQeEWjSZ7VCVEg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][1], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=6qFZBbQvQpCmCAIpUCZ9ag], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][6], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=S8NVu8UyQgak9k4d-m3Djw], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l7R5NpNKQ6ObrmZ9xxxacg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository]]: took 27ms done applying updated cluster_state (version: 150, uuid: CAC7dwrsQoS7i31fkflPrQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,621][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,622][INFO ][org.elasticsearch.cluster.routing.allocation] [node_s0] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test-idx][0], [test-idx][0]] ...]).%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,622][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [151], source [shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,622][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [151]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [151], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 151%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [151], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,623][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 151%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,624][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 151, uuid: _Bnqp7cQTHGqCa4GrCDnTQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,634][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 11ms done applying updated cluster_state (version: 151, uuid: _Bnqp7cQTHGqCa4GrCDnTQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,634][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 151%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,634][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,642][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][3]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,642][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [after recovery from repository],shard-started ([test-idx][0], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=lQ0BDyq6STC3A6TlePAhdg], unassigned_info[[reason=EXISTING_INDEX_RESTORED], at[2016-03-29T21:28:12.373Z], details[restore_source[test-repo/test-snap]]]), reason [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 21ms done applying updated cluster_state (version: 151, uuid: _Bnqp7cQTHGqCa4GrCDnTQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,643][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,649][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][1]] active fully on other nodes)]: took 6ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,650][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,653][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [test_block]: took 9ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [152], source [update snapshot state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [152]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [152], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 152%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,654][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 152, uuid: 9sISmQFaRJaZ-2wn3iYUiw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [indices_store ([[test-idx][5]] active fully on other nodes)]: took 7ms no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [152], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 152%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 152, uuid: 9sISmQFaRJaZ-2wn3iYUiw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,658][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 152%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 5ms done applying updated cluster_state (version: 152, uuid: 9sISmQFaRJaZ-2wn3iYUiw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,659][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [update snapshot state]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][6]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][2]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,660][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][4]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,661][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [indices_store ([[test-idx][0]] active fully on other nodes)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete-index [test-idx]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.metadata] [node_s0] [test-idx] deleting index%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [153], source [delete-index [test-idx]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [153]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [153], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 153%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,676][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,677][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 153, uuid: bVkafU97RwqzjXlMmO6P5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,677][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [153], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,677][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 153%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,834][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 157ms done applying updated cluster_state (version: 153, uuid: bVkafU97RwqzjXlMmO6P5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,835][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 153%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete-index [test-idx]]: took 246ms done applying updated cluster_state (version: 153, uuid: bVkafU97RwqzjXlMmO6P5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove-index-template [random_index_template]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [154], source [remove-index-template [random_index_template]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [154]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [154], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 154%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 154, uuid: U-04imVpRSKK49cI6glpaw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [154], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,923][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 154%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,929][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 154, uuid: U-04imVpRSKK49cI6glpaw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,929][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 154%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [remove-index-template [random_index_template]]: took 10ms done applying updated cluster_state (version: 154, uuid: U-04imVpRSKK49cI6glpaw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] cluster state updated, version [155], source [delete_repository [*]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s0] publishing cluster state version [155]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s1] cluster state updated, version [155], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,934][DEBUG][org.elasticsearch.cluster.service] [node_s2] cluster state updated, version [155], source [local-disco-receive(from master)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,935][DEBUG][org.elasticsearch.cluster.service] [node_s2] set local cluster state to version 155%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,935][DEBUG][org.elasticsearch.cluster.service] [node_s2] processing [local-disco-receive(from master)]: took 0s done applying updated cluster_state (version: 155, uuid: M7mgktV_QzKi9SjrJcZtuA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,935][DEBUG][org.elasticsearch.cluster.service] [node_s1] set local cluster state to version 155%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,939][DEBUG][org.elasticsearch.cluster.service] [node_s1] processing [local-disco-receive(from master)]: took 5ms done applying updated cluster_state (version: 155, uuid: M7mgktV_QzKi9SjrJcZtuA)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,939][DEBUG][org.elasticsearch.cluster.service] [node_s0] set local cluster state to version 155%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:12,944][DEBUG][org.elasticsearch.cluster.service] [node_s0] processing [delete_repository [*]]: took 10ms done applying updated cluster_state (version: 155, uuid: M7mgktV_QzKi9SjrJcZtuA)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBatchingShardUpdateTask(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286890658,
  "executionTime": 2287
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotName(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286892945,
  "executionTime": 109
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotMoreThanOnce(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286893054,
  "executionTime": 700
 }
]

[
 "TEST_STARTED",
 "ID#testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:17,729][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo][test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] indices [test-idx-2] and [test-idx-1] are renamed into the same index [same-name]]%0A%09at org.elasticsearch.snapshots.RestoreService.renamedIndices(RestoreService.java:694)%0A%09at org.elasticsearch.snapshots.RestoreService.restoreSnapshot(RestoreService.java:209)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:82)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:41)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:17,733][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo][test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] indices [test-idx-2] and [test-idx-1] are renamed into the same index [test-idx-1]]%0A%09at org.elasticsearch.snapshots.RestoreService.renamedIndices(RestoreService.java:694)%0A%09at org.elasticsearch.snapshots.RestoreService.restoreSnapshot(RestoreService.java:209)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:82)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.restore.TransportRestoreSnapshotAction.masterOperation(TransportRestoreSnapshotAction.java:41)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:17,773][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0A[__WRONG__] InvalidIndexNameException[Invalid index name [__WRONG__], must not start with '_']%0A%09at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:152)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:253)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:17,777][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0A[alias-3] InvalidIndexNameException[Invalid index name [alias-3], already exists as alias]%0A%09at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:170)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:253)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:17,780][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] cannot rename index [test-idx-1] into [alias-1] because of conflict with an alias with the same name]%0A%09at org.elasticsearch.snapshots.RestoreService$1.checkAliasNameConflicts(RestoreService.java:336)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:314)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:17,784][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] cannot rename index [test-idx-1] into [alias-2] because of conflict with an alias with the same name]%0A%09at org.elasticsearch.snapshots.RestoreService$1.checkAliasNameConflicts(RestoreService.java:336)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:314)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRenameOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286893754,
  "executionTime": 4868
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:19,555][WARN ][org.elasticsearch.repositories.fs] [node_s0] cannot read snapshot file [test-repo:test-snap-1]%0Ajava.lang.IllegalStateException: class org.apache.lucene.store.BufferedChecksumIndexInput cannot seek backwards (pos=-10 getFilePointer()=0)%0A%09at org.apache.lucene.store.ChecksumIndexInput.seek(ChecksumIndexInput.java:50)%0A%09at org.apache.lucene.codecs.CodecUtil.checksumEntireFile(CodecUtil.java:448)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:106)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshot(BlobStoreRepository.java:438)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.deleteSnapshot(BlobStoreRepository.java:298)%0A%09at org.elasticsearch.snapshots.SnapshotsService$8.run(SnapshotsService.java:1009)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithCorruptedSnapshotFile(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286898623,
  "executionTime": 1645
 }
]

[
 "TEST_STARTED",
 "ID#testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:21,320][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][5]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][5]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:21,324][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][2]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][2]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:21,325][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][4]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][4]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:21,328][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][3]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][3]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:21,331][WARN ][org.elasticsearch.snapshots] [node_s1] [[test-idx][0]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][0]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:21,339][WARN ][org.elasticsearch.snapshots] [node_s0] [[test-idx][1]] [test-repo:test-snap] failed to create snapshot%0A[test-idx][[test-idx][1]] IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:600)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:183)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.snapshot(SnapshotShardsService.java:343)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService.access$200(SnapshotShardsService.java:79)%0A%09at org.elasticsearch.snapshots.SnapshotShardsService$1.doRun(SnapshotShardsService.java:299)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:363)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:652)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:598)%0A%09... 8 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDataFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286900268,
  "executionTime": 1323
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286901591,
  "executionTime": 5043
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:27,097][WARN ][org.elasticsearch.repositories] [node_s0] failed to create repository [test-repo]%0Ajava.lang.IllegalStateException: trying to modify or unregister repository that is currently used %0A%09at org.elasticsearch.repositories.RepositoriesService.ensureRepositoryNotInUse(RepositoriesService.java:421)%0A%09at org.elasticsearch.repositories.RepositoriesService.access$000(RepositoriesService.java:60)%0A%09at org.elasticsearch.repositories.RepositoriesService$1.execute(RepositoriesService.java:113)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteRepositoryWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286906634,
  "executionTime": 1222
 }
]

[
 "TEST_STARTED",
 "ID#testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:28,735][WARN ][org.elasticsearch.snapshots] [node_s0] failed to get snapshot [test-repo:test-snap-2]%0Ajava.lang.IllegalStateException: class org.apache.lucene.store.BufferedChecksumIndexInput cannot seek backwards (pos=-12 getFilePointer()=0)%0A%09at org.apache.lucene.store.ChecksumIndexInput.seek(ChecksumIndexInput.java:50)%0A%09at org.apache.lucene.codecs.CodecUtil.checksumEntireFile(CodecUtil.java:448)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:106)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshot(BlobStoreRepository.java:438)%0A%09at org.elasticsearch.snapshots.SnapshotsService.snapshots(SnapshotsService.java:153)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.masterOperation(TransportGetSnapshotsAction.java:80)%0A%09at org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.masterOperation(TransportGetSnapshotsAction.java:49)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction.masterOperation(TransportMasterNodeAction.java:78)%0A%09at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$3.doRun(TransportMasterNodeAction.java:162)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testListCorruptedSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286907857,
  "executionTime": 1409
 }
]

[
 "TEST_STARTED",
 "ID#testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnallocatedShards(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286909266,
  "executionTime": 148
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286909415,
  "executionTime": 440
 }
]

[
 "TEST_STARTED",
 "ID#testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeletionOfFailingToRecoverIndexShouldStopRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286909855,
  "executionTime": 1100
 }
]

[
 "TEST_STARTED",
 "ID#testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUrlRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286910955,
  "executionTime": 1915
 }
]

[
 "TEST_STARTED",
 "ID#testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBasicWorkFlow(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286912870,
  "executionTime": 6936
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:41,127][WARN ][org.elasticsearch.snapshots] [node_s0] failed to create snapshot [test-repo:test-snap]%0ASnapshotCreationException[[test-repo:test-snap] failed to create snapshot]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:283)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository.initializeSnapshot(MockRepository.java:147)%0A%09at org.elasticsearch.snapshots.SnapshotsService.beginSnapshot(SnapshotsService.java:309)%0A%09at org.elasticsearch.snapshots.SnapshotsService.access$600(SnapshotsService.java:95)%0A%09at org.elasticsearch.snapshots.SnapshotsService$1$1.run(SnapshotsService.java:231)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:293)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.writeBlob(MockRepository.java:357)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.writeBlob(ChecksumBlobStoreFormat.java:182)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.write(ChecksumBlobStoreFormat.java:154)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:275)%0A%09... 7 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotFileFailureDuringSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286919807,
  "executionTime": 1715
 }
]

[
 "TEST_STARTED",
 "ID#testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptySnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286921523,
  "executionTime": 120
 }
]

[
 "TEST_STARTED",
 "ID#testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:43,118][WARN ][org.elasticsearch.snapshots] [node_s0] failed to create snapshot [readonly-repo:test-snap-2]%0ARepositoryException[[readonly-repo] cannot create snapshot in a readonly repository]%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.initializeSnapshot(BlobStoreRepository.java:267)%0A%09at org.elasticsearch.snapshots.SnapshotsService.beginSnapshot(SnapshotsService.java:309)%0A%09at org.elasticsearch.snapshots.SnapshotsService.access$600(SnapshotsService.java:95)%0A%09at org.elasticsearch.snapshots.SnapshotsService$1$1.run(SnapshotsService.java:231)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testReadonlyRepository(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286921643,
  "executionTime": 1614
 }
]

[
 "TEST_STARTED",
 "ID#testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,770][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,783][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=E7tXHvYuQe2IjirhNpwCMw], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-03-29T21:28:44.684Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,819][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,832][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[1], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Tu2o-TxURruH1W98WMmf6w], unassigned_info[[reason=NEW_INDEX_RESTORED], at[2016-03-29T21:28:44.684Z], details[restore_source[test-repo/test-snap]]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,884][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,896][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=gGjbWo3GQbeTSOWNS0L5ZQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.787Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,959][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,962][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=QA-y37LTRbWRKiTDFlyKyA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.907Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,977][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,979][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2vhs67oeT-SeCfGvDtXVCw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.841Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,980][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,980][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2vhs67oeT-SeCfGvDtXVCw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.841Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,985][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WTgyRZpuR3yKllT4jY4oEw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.963Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,991][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=WTgyRZpuR3yKllT4jY4oEw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.963Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:44,999][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[3], restoring[test-repo:test-snap], s[INITIALIZING], a[id=2vhs67oeT-SeCfGvDtXVCw], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:44.841Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,026][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,032][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=s3Zy87LiRXm8_Hb9U8WFPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,035][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[5], restoring[test-repo:test-snap], s[INITIALIZING], a[id=s3Zy87LiRXm8_Hb9U8WFPA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,038][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,039][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ZSckgv_NST-FlJjq6CX8bA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,040][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=ZSckgv_NST-FlJjq6CX8bA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.007Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,083][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,085][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[7], restoring[test-repo:test-snap], s[INITIALIZING], a[id=Hz5FAdLhRqmEQG-Yx5MmeQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.036Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,136][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,153][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=-_XaUSUWSpaeugwmeygucQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.042Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,204][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,208][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[9], restoring[test-repo:test-snap], s[INITIALIZING], a[id=uUmSQj2EQZ2yQJHwqyHJoA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.092Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,257][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,258][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=FvZrfk8GSAmOWDIlMEqPXA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.170Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,272][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,273][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=iIIF35OQQN-uAS0yG3MaDA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.219Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,308][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[11], restoring[test-repo:test-snap], s[INITIALIZING], a[id=iIIF35OQQN-uAS0yG3MaDA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.219Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,336][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,350][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=0P27PVX8R_ylIHvomD0yAg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.266Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,355][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,359][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pS3S1NwvS2C3xYryD4XDbQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.310Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,363][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pS3S1NwvS2C3xYryD4XDbQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.310Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,372][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[13], restoring[test-repo:test-snap], s[INITIALIZING], a[id=pS3S1NwvS2C3xYryD4XDbQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.310Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,385][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,387][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=uOuHgA35TtSELYl0S_I7Eg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.355Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,410][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[17], restoring[test-repo:test-snap], s[INITIALIZING], a[id=uOuHgA35TtSELYl0S_I7Eg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.355Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,417][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][2]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,418][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l_ogvAiLRg-S50-5pj8pNA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.380Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][2]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][2]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,440][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][2] received shard failed for [test-idx][2], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[15], restoring[test-repo:test-snap], s[INITIALIZING], a[id=l_ogvAiLRg-S50-5pj8pNA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.380Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[0], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,444][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,448][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=k-KYtiQgRnqjJeAAqDDMoA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,452][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[19], restoring[test-repo:test-snap], s[INITIALIZING], a[id=k-KYtiQgRnqjJeAAqDDMoA], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.411Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [master {node_s0}{-dn8ccnpRLqYmunDCVfdUA}{local}{local[40]}[mode=>local] marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,481][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,482][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[21], restoring[test-repo:test-snap], s[INITIALIZING], a[id=z13YA4MaQYGCBMzfhyn14g], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.454Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,513][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,518][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[23], restoring[test-repo:test-snap], s[INITIALIZING], a[id=NHpb3CzdQNeJi7w_TVtiQg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.484Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,613][WARN ][org.elasticsearch.indices.cluster] [node_s0] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,614][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[-dn8ccnpRLqYmunDCVfdUA], [P], v[25], restoring[test-repo:test-snap], s[INITIALIZING], a[id=oonwWq-HSFqKhLOwMWfF7A], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.521Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,735][WARN ][org.elasticsearch.indices.cluster] [node_s1] [[test-idx][3]] marking and sending shard failed due to [failed recovery]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:45,738][WARN ][org.elasticsearch.cluster.action.shard] [node_s0] [test-idx][3] received shard failed for [test-idx][3], node[i7ieD3CyQx2wMB7HGnZkHg], [P], v[27], restoring[test-repo:test-snap], s[INITIALIZING], a[id=YnZfFYQcRZOyxo-geJUGcQ], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-03-29T21:28:45.614Z], details[failed recovery, failure IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]], expected_shard_size[3891], indexUUID [D3Auo7VzQP6FNZ_qFx2Hvw], message [failed recovery], failure [IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException]; ]%0A[test-idx][[test-idx][3]] IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:165)%0A%09at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:97)%0A%09at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1065)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.lambda$applyInitializingShard$191(IndicesClusterStateService.java:665)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$$Lambda$802/56189618.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:265)%0A%09at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$185(StoreRecovery.java:99)%0A%09at org.elasticsearch.index.shard.StoreRecovery$$Lambda$803/1768888064.run(Unknown Source)%0A%09at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:122)%0A%09... 7 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[failed to restore snapshot [test-snap]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:207)%0A%09at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:260)%0A%09... 10 more%0ACaused by: [test-idx][[test-idx][3]] IndexShardRestoreFailedException[Failed to recover index]; nested: IOException[Random IOException];%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:866)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:205)%0A%09... 11 more%0ACaused by: java.io.IOException: Random IOException%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.maybeIOExceptionOrBlock(MockRepository.java:277)%0A%09at org.elasticsearch.snapshots.mockstore.MockRepository$MockBlobStore$MockBlobContainer.readBlob(MockRepository.java:321)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$PartSliceStream.openSlice(BlobStoreIndexShardRepository.java:768)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.nextStream(SlicedInputStream.java:53)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.currentStream(SlicedInputStream.java:67)%0A%09at org.elasticsearch.index.snapshots.blobstore.SlicedInputStream.read(SlicedInputStream.java:88)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:133)%0A%09at org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream.read(RateLimitingInputStream.java:69)%0A%09at java.io.FilterInputStream.read(FilterInputStream.java:107)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:923)%0A%09at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:863)%0A%09... 12 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDataFileFailureDuringRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286923257,
  "executionTime": 2891
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreWithDifferentMappingsAndSettings(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286926148,
  "executionTime": 1021
 }
]

[
 "TEST_STARTED",
 "ID#testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIncludeGlobalState(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286927169,
  "executionTime": 802
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:28:49,287][WARN ][org.elasticsearch.repositories.fs] [node_s0] cannot read metadata for snapshot [test-repo:test-snap-1]%0ASnapshotMissingException[[test-repo:test-snap-1] is missing]; nested: NoSuchFileException[/Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT_4AA6DECDBC490785-001/tempDir-001/repos/GhiXNtcjWT/meta-test-snap-1.dat];%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshotMetaData(BlobStoreRepository.java:470)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.deleteSnapshot(BlobStoreRepository.java:308)%0A%09at org.elasticsearch.snapshots.SnapshotsService$8.run(SnapshotsService.java:1009)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.nio.file.NoSuchFileException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT_4AA6DECDBC490785-001/tempDir-001/repos/GhiXNtcjWT/meta-test-snap-1.dat%0A%09at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)%0A%09at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)%0A%09at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)%0A%09at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)%0A%09at java.nio.file.Files.newByteChannel(Files.java:361)%0A%09at java.nio.file.Files.newByteChannel(Files.java:407)%0A%09at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.HandleTrackingFS.newInputStream(HandleTrackingFS.java:93)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newInputStream(FilterFileSystemProvider.java:193)%0A%09at org.apache.lucene.mockfile.HandleTrackingFS.newInputStream(HandleTrackingFS.java:93)%0A%09at java.nio.file.Files.newInputStream(Files.java:152)%0A%09at org.elasticsearch.common.blobstore.fs.FsBlobContainer.readBlob(FsBlobContainer.java:93)%0A%09at org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat.readBlob(ChecksumBlobStoreFormat.java:100)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreFormat.read(BlobStoreFormat.java:86)%0A%09at org.elasticsearch.repositories.blobstore.BlobStoreRepository.readSnapshotMetaData(BlobStoreRepository.java:468)%0A%09... 5 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithMissingMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286927971,
  "executionTime": 1951
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithMissingIndexAndShardMetadata(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286929922,
  "executionTime": 817
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreTemplates(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286930739,
  "executionTime": 182
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotSingleClosedIndex(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286930921,
  "executionTime": 1091
 }
]

[
 "TEST_STARTED",
 "ID#testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMoveShardWhileSnapshotting(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286932012,
  "executionTime": 1421
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotRelocatingPrimary(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286933433,
  "executionTime": 5342
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteOrphanSnapshot(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286938775,
  "executionTime": 882
 }
]

[
 "TEST_STARTED",
 "ID#testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThrottling(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286939657,
  "executionTime": 23885
 }
]

[
 "TEST_STARTED",
 "ID#testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:23,943][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0ASnapshotRestoreException[[test-repo:test-snap] cannot modify setting [index.number_of_shards] on restore]%0A%09at org.elasticsearch.snapshots.RestoreService$1.updateIndexSettings(RestoreService.java:416)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:241)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:23,947][WARN ][org.elasticsearch.snapshots] [node_s0] [test-repo:test-snap] failed to restore snapshot%0Ajava.lang.IllegalArgumentException: must specify non-negative number of shards for index [test-idx]%0A%09at org.elasticsearch.cluster.metadata.IndexMetaData$Builder.build(IndexMetaData.java:753)%0A%09at org.elasticsearch.snapshots.RestoreService$1.updateIndexSettings(RestoreService.java:422)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:241)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testChangeSettingsOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286963542,
  "executionTime": 953
 }
]

[
 "TEST_STARTED",
 "ID#testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecreateBlocksOnRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286964495,
  "executionTime": 1049
 }
]

[
 "TEST_STARTED",
 "ID#testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSingleGetAfterRestore(org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT)",
  "startTimestamp": 1459286965545,
  "executionTime": 1012
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.snapshots.SharedClusterSnapshotRestoreIT",
  "startTimestamp": 1459286877302,
  "executionTime": 89723
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
   "children": [
    {
     "id": "ID#testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "displayName": "testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "methodName": "testMultiValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
     "children": []
    },
    {
     "id": "ID#testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "displayName": "testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "methodName": "testSingleValueField",
     "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
     "children": []
    },
    {
     "id": "ID#testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "displayName": "testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
     "methodName": "testUnmapped",
     "className": "org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286967039
 }
]

[
 "TEST_STARTED",
 "ID#testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMultiValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
  "startTimestamp": 1459286967304,
  "executionTime": 148
 }
]

[
 "TEST_STARTED",
 "ID#testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSingleValueField(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
  "startTimestamp": 1459286967453,
  "executionTime": 23
 }
]

[
 "TEST_STARTED",
 "ID#testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnmapped(org.elasticsearch.search.aggregations.bucket.BooleanTermsIT)",
  "startTimestamp": 1459286967476,
  "executionTime": 20
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.BooleanTermsIT",
  "startTimestamp": 1459286967039,
  "executionTime": 555
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.percolator.RecoveryPercolatorIT",
   "displayName": "org.elasticsearch.percolator.RecoveryPercolatorIT",
   "methodName": null,
   "className": "org.elasticsearch.percolator.RecoveryPercolatorIT",
   "children": [
    {
     "id": "ID#testRestartNodePercolator1(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "displayName": "testRestartNodePercolator1(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "methodName": "testRestartNodePercolator1",
     "className": "org.elasticsearch.percolator.RecoveryPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testPercolatorRecovery(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "displayName": "testPercolatorRecovery(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "methodName": "testPercolatorRecovery",
     "className": "org.elasticsearch.percolator.RecoveryPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testRestartNodePercolator2(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "displayName": "testRestartNodePercolator2(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "methodName": "testRestartNodePercolator2",
     "className": "org.elasticsearch.percolator.RecoveryPercolatorIT",
     "children": []
    },
    {
     "id": "ID#testLoadingPercolateQueriesDuringCloseAndOpen(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "displayName": "testLoadingPercolateQueriesDuringCloseAndOpen(org.elasticsearch.percolator.RecoveryPercolatorIT)",
     "methodName": "testLoadingPercolateQueriesDuringCloseAndOpen",
     "className": "org.elasticsearch.percolator.RecoveryPercolatorIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286967604
 }
]

[
 "TEST_STARTED",
 "ID#testRestartNodePercolator1(org.elasticsearch.percolator.RecoveryPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestartNodePercolator1(org.elasticsearch.percolator.RecoveryPercolatorIT)",
  "startTimestamp": 1459286967616,
  "executionTime": 215
 }
]

[
 "TEST_STARTED",
 "ID#testPercolatorRecovery(org.elasticsearch.percolator.RecoveryPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPercolatorRecovery(org.elasticsearch.percolator.RecoveryPercolatorIT)",
  "startTimestamp": 1459286967831,
  "executionTime": 2537
 }
]

[
 "TEST_STARTED",
 "ID#testRestartNodePercolator2(org.elasticsearch.percolator.RecoveryPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestartNodePercolator2(org.elasticsearch.percolator.RecoveryPercolatorIT)",
  "startTimestamp": 1459286970368,
  "executionTime": 404
 }
]

[
 "TEST_STARTED",
 "ID#testLoadingPercolateQueriesDuringCloseAndOpen(org.elasticsearch.percolator.RecoveryPercolatorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testLoadingPercolateQueriesDuringCloseAndOpen(org.elasticsearch.percolator.RecoveryPercolatorIT)",
  "startTimestamp": 1459286970773,
  "executionTime": 531
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.percolator.RecoveryPercolatorIT",
  "startTimestamp": 1459286967604,
  "executionTime": 3719
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.query.ExistsIT",
   "displayName": "org.elasticsearch.search.query.ExistsIT",
   "methodName": null,
   "className": "org.elasticsearch.search.query.ExistsIT",
   "children": [
    {
     "id": "ID#testExists(org.elasticsearch.search.query.ExistsIT)",
     "displayName": "testExists(org.elasticsearch.search.query.ExistsIT)",
     "methodName": "testExists",
     "className": "org.elasticsearch.search.query.ExistsIT",
     "children": []
    },
    {
     "id": "ID#testEmptyIndex(org.elasticsearch.search.query.ExistsIT)",
     "displayName": "testEmptyIndex(org.elasticsearch.search.query.ExistsIT)",
     "methodName": "testEmptyIndex",
     "className": "org.elasticsearch.search.query.ExistsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286971331
 }
]

[
 "TEST_STARTED",
 "ID#testExists(org.elasticsearch.search.query.ExistsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExists(org.elasticsearch.search.query.ExistsIT)",
  "startTimestamp": 1459286971348,
  "executionTime": 262
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyIndex(org.elasticsearch.search.query.ExistsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyIndex(org.elasticsearch.search.query.ExistsIT)",
  "startTimestamp": 1459286971610,
  "executionTime": 73
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.query.ExistsIT",
  "startTimestamp": 1459286971331,
  "executionTime": 364
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
   "displayName": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
   "methodName": null,
   "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
   "children": [
    {
     "id": "ID#testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testCreateSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testRestoreSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testGetSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testDeleteSnapshotWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testCreateSnapshotWithIndexBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    },
    {
     "id": "ID#testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "displayName": "testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
     "methodName": "testSnapshotStatusWithBlocks",
     "className": "org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286971703
 }
]

[
 "TEST_STARTED",
 "ID#testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1459286971716,
  "executionTime": 381
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1459286972097,
  "executionTime": 606
 }
]

[
 "TEST_STARTED",
 "ID#testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1459286972704,
  "executionTime": 618
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteSnapshotWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1459286973322,
  "executionTime": 322
 }
]

[
 "TEST_STARTED",
 "ID#testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCreateSnapshotWithIndexBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1459286973644,
  "executionTime": 510
 }
]

[
 "TEST_STARTED",
 "ID#testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSnapshotStatusWithBlocks(org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT)",
  "startTimestamp": 1459286974154,
  "executionTime": 893
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.admin.cluster.snapshots.SnapshotBlocksIT",
  "startTimestamp": 1459286971703,
  "executionTime": 3443
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.suggest.stats.SuggestStatsIT",
   "displayName": "org.elasticsearch.index.suggest.stats.SuggestStatsIT",
   "methodName": null,
   "className": "org.elasticsearch.index.suggest.stats.SuggestStatsIT",
   "children": [
    {
     "id": "ID#testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)",
     "displayName": "testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)",
     "methodName": "testSimpleStats",
     "className": "org.elasticsearch.index.suggest.stats.SuggestStatsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286975153
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleStats(org.elasticsearch.index.suggest.stats.SuggestStatsIT)",
  "startTimestamp": 1459286975161,
  "executionTime": 2064
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.suggest.stats.SuggestStatsIT",
  "startTimestamp": 1459286975153,
  "executionTime": 2081
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT",
   "displayName": "org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT",
   "methodName": null,
   "className": "org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT",
   "children": [
    {
     "id": "ID#testDestructiveOperations(org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT)",
     "displayName": "testDestructiveOperations(org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT)",
     "methodName": "testDestructiveOperations",
     "className": "org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286977239
 }
]

[
 "TEST_STARTED",
 "ID#testDestructiveOperations(org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDestructiveOperations(org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT)",
  "startTimestamp": 1459286977248,
  "executionTime": 408
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.operateAllIndices.DestructiveOperationsIntegrationIT",
  "startTimestamp": 1459286977239,
  "executionTime": 421
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.allocation.ClusterRerouteIT",
   "displayName": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
   "children": [
    {
     "id": "ID#testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteExplain",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testDelayWithALargeAmountOfShards",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithCommands_disableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testClusterRerouteWithBlocks",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithAllocateLocalGateway_enableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithCommands_enableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    },
    {
     "id": "ID#testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "displayName": "testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
     "methodName": "testRerouteWithAllocateLocalGateway_disableAllocationSettings",
     "className": "org.elasticsearch.cluster.allocation.ClusterRerouteIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286977667
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteExplain(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286977676,
  "executionTime": 157
 }
]

[
 "TEST_STARTED",
 "ID#testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDelayWithALargeAmountOfShards(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286977833,
  "executionTime": 18006
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithCommands_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286995840,
  "executionTime": 115
 }
]

[
 "TEST_STARTED",
 "ID#testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterRerouteWithBlocks(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286995956,
  "executionTime": 165
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithAllocateLocalGateway_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286996121,
  "executionTime": 190
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithCommands_enableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286996311,
  "executionTime": 117
 }
]

[
 "TEST_STARTED",
 "ID#testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRerouteWithAllocateLocalGateway_disableAllocationSettings(org.elasticsearch.cluster.allocation.ClusterRerouteIT)",
  "startTimestamp": 1459286996428,
  "executionTime": 188
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.allocation.ClusterRerouteIT",
  "startTimestamp": 1459286977667,
  "executionTime": 19073
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.admin.indices.get.GetIndexIT",
   "displayName": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
   "methodName": null,
   "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
   "children": [
    {
     "id": "ID#testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testEmpty",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleSettings",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimple",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleUnknownIndex",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleMixedFeatures",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testGetIndexWithBlocks",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testEmptyMixedFeatures",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleAlias",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    },
    {
     "id": "ID#testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "displayName": "testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
     "methodName": "testSimpleMapping",
     "className": "org.elasticsearch.action.admin.indices.get.GetIndexIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286996746
 }
]

[
 "TEST_STARTED",
 "ID#testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmpty(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996831,
  "executionTime": 6
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleSettings(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996837,
  "executionTime": 4
 }
]

[
 "TEST_STARTED",
 "ID#testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimple(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996841,
  "executionTime": 5
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleUnknownIndex(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996846,
  "executionTime": 5
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996851,
  "executionTime": 8
 }
]

[
 "TEST_STARTED",
 "ID#testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetIndexWithBlocks(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996859,
  "executionTime": 25
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyMixedFeatures(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996885,
  "executionTime": 8
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleAlias(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996893,
  "executionTime": 7
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleMapping(org.elasticsearch.action.admin.indices.get.GetIndexIT)",
  "startTimestamp": 1459286996901,
  "executionTime": 6
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.admin.indices.get.GetIndexIT",
  "startTimestamp": 1459286996746,
  "executionTime": 177
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
   "displayName": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
   "methodName": null,
   "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
   "children": [
    {
     "id": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "displayName": "testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "methodName": "testGetAliases",
     "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
     "children": []
    },
    {
     "id": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "displayName": "testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "methodName": "testGetMappings",
     "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
     "children": []
    },
    {
     "id": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "displayName": "testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
     "methodName": "testGetSettings",
     "className": "org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286996931
 }
]

[
 "TEST_STARTED",
 "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1459286996936,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "message": "'backwards' test group is disabled (@Backwards())",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:668)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$200(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:591)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetAliases(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1459286996935,
  "executionTime": 5
 }
]

[
 "TEST_STARTED",
 "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1459286996940,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "message": "'backwards' test group is disabled (@Backwards())",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:668)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$200(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:591)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetMappings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1459286996940,
  "executionTime": 1
 }
]

[
 "TEST_STARTED",
 "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1459286996941,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "message": "'backwards' test group is disabled (@Backwards())",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:668)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$200(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:591)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'backwards' test group is disabled (@Backwards())",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetSettings(org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT)",
  "startTimestamp": 1459286996941,
  "executionTime": 0
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.bwcompat.GetIndexBackwardsCompatibilityIT",
  "startTimestamp": 1459286996931,
  "executionTime": 10
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.routing.AliasResolveRoutingIT",
   "displayName": "org.elasticsearch.routing.AliasResolveRoutingIT",
   "methodName": null,
   "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
   "children": [
    {
     "id": "ID#testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "displayName": "testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "methodName": "testResolveIndexRouting",
     "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
     "children": []
    },
    {
     "id": "ID#testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "displayName": "testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "methodName": "testResolveSearchRouting",
     "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
     "children": []
    },
    {
     "id": "ID#testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "displayName": "testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)",
     "methodName": "testSearchClosedWildcardIndex",
     "className": "org.elasticsearch.routing.AliasResolveRoutingIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286996946
 }
]

[
 "TEST_STARTED",
 "ID#testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResolveIndexRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
  "startTimestamp": 1459286996955,
  "executionTime": 218
 }
]

[
 "TEST_STARTED",
 "ID#testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResolveSearchRouting(org.elasticsearch.routing.AliasResolveRoutingIT)",
  "startTimestamp": 1459286997173,
  "executionTime": 133
 }
]

[
 "TEST_STARTED",
 "ID#testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchClosedWildcardIndex(org.elasticsearch.routing.AliasResolveRoutingIT)",
  "startTimestamp": 1459286997306,
  "executionTime": 193
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.routing.AliasResolveRoutingIT",
  "startTimestamp": 1459286996946,
  "executionTime": 558
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
   "displayName": "org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
   "children": [
    {
     "id": "ID#testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)",
     "displayName": "testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)",
     "methodName": "testBreakerWithRandomExceptions",
     "className": "org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286997508
 }
]

[
 "TEST_STARTED",
 "ID#testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,709][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,709][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,709][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,709][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,717][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,717][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,717][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,717][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,726][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,726][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,726][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,726][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,733][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,733][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,733][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,733][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,741][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,741][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,741][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,741][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,752][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,752][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,752][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,752][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,761][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,761][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,761][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,761][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,766][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,766][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,766][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,766][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,773][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,773][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,773][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,773][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,780][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,780][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,780][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,780][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,784][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,784][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,784][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,784][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,790][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,790][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,790][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,790][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,797][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,797][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,797][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,797][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,805][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,805][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,805][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,805][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,821][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,821][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,821][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,821][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,827][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,827][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,827][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,827][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,832][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,832][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,832][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,832][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,837][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,838][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,837][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,837][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,846][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,846][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,846][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,847][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,856][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,856][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,856][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,856][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,861][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,861][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,861][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,861][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,866][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,867][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,866][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,866][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,872][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,872][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,872][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,872][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,882][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,882][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,882][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,882][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,890][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,890][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,890][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,890][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,898][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,898][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,898][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,898][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,911][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,911][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,911][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,911][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,917][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,917][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,917][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,917][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,921][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,921][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,921][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,921][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,927][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,927][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,927][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,927][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,931][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,931][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,931][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,931][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,938][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,938][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,938][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,938][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,944][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,944][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,944][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,944][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,950][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,950][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,950][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,950][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,954][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,954][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,954][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,954][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,959][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,959][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,959][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,959][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,964][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,964][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,964][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,964][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,971][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,971][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,971][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,971][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,976][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,976][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,976][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,976][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,980][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,981][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,980][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,980][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:281)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:293)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:354)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:351)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,986][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,986][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,986][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,986][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,990][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,991][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,991][WARN ][org.elasticsearch.index.fielddata.plain] [node_s1] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:342)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:57,990][WARN ][org.elasticsearch.index.fielddata.plain] [node_s0] [test] Unable to estimate memory overhead%0Ajava.io.IOException: Forced top level Exception on [Terms]%0A%09at org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT$RandomExceptionDirectoryReaderWrapper$ThrowingSubReaderWrapper.maybeThrow(RandomExceptionCircuitBreakerIT.java:251)%0A%09at org.elasticsearch.test.engine.ThrowingLeafReaderWrapper$ThrowingFields.terms(ThrowingLeafReaderWrapper.java:114)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.estimateStringFieldData(PagedBytesIndexFieldData.java:173)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData$PagedBytesEstimator.beforeLoad(PagedBytesIndexFieldData.java:221)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:98)%0A%09at org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData.loadDirect(PagedBytesIndexFieldData.java:52)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.lambda$load$62(IndicesFieldDataCache.java:155)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache$$Lambda$754/1732080660.load(Unknown Source)%0A%09at org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:385)%0A%09at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.load(IndicesFieldDataCache.java:150)%0A%09at org.elasticsearch.index.fielddata.plain.AbstractIndexFieldData.load(AbstractIndexFieldData.java:78)%0A%09at org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$1.getSortedDocValues(BytesRefFieldComparatorSource.java:92)%0A%09at org.apache.lucene.search.FieldComparator$TermOrdValComparator.getLeafComparator(FieldComparator.java:767)%0A%09at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)%0A%09at org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)%0A%09at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:386)%0A%09at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:126)%0A%09at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:348)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:362)%0A%09at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:359)%0A%09at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)%0A%09at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:65)%0A%09at org.elasticsearch.transport.local.LocalTransport$2.doRun(LocalTransport.java:296)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBreakerWithRandomExceptions(org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT)",
  "startTimestamp": 1459286997516,
  "executionTime": 502
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.memory.breaker.RandomExceptionCircuitBreakerIT",
  "startTimestamp": 1459286997508,
  "executionTime": 515
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.bulk.BulkProcessorIT",
   "displayName": "org.elasticsearch.action.bulk.BulkProcessorIT",
   "methodName": null,
   "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
   "children": [
    {
     "id": "ID#testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorConcurrentRequests",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorWaitOnClose",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorFlush",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorConcurrentRequestsReadOnlyIndex",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testBulkProcessorConcurrentRequestsNoNodeAvailableException",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    },
    {
     "id": "ID#testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "displayName": "testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)",
     "methodName": "testThatBulkProcessorCountIsCorrect",
     "className": "org.elasticsearch.action.bulk.BulkProcessorIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286998032
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorConcurrentRequests(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1459286998043,
  "executionTime": 237
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorWaitOnClose(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1459286998281,
  "executionTime": 97
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorFlush(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1459286998378,
  "executionTime": 416
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorConcurrentRequestsReadOnlyIndex(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1459286998794,
  "executionTime": 193
 }
]

[
 "TEST_STARTED",
 "ID#testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:59,088][WARN ][org.elasticsearch.action.bulk] [Grog the God-Crusher] Failed to execute bulk request 1.%0ANoNodeAvailableException[None of the configured nodes are available: []]%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:289)%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:206)%0A%09at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:62)%0A%09at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:283)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:464)%0A%09at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:209)%0A%09at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72)%0A%09at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:315)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:306)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:253)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.indexDocs(BulkProcessorIT.java:298)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.testBulkProcessorConcurrentRequestsNoNodeAvailableException(BulkProcessorIT.java:180)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:59,089][WARN ][org.elasticsearch.action.bulk] [Grog the God-Crusher] Failed to execute bulk request 2.%0ANoNodeAvailableException[None of the configured nodes are available: []]%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:289)%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:206)%0A%09at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:62)%0A%09at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:283)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:464)%0A%09at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:209)%0A%09at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72)%0A%09at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:315)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:306)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:253)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.indexDocs(BulkProcessorIT.java:298)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.testBulkProcessorConcurrentRequestsNoNodeAvailableException(BulkProcessorIT.java:180)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:29:59,090][WARN ][org.elasticsearch.action.bulk] [Grog the God-Crusher] Failed to execute bulk request 3.%0ANoNodeAvailableException[None of the configured nodes are available: []]%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:289)%0A%09at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:206)%0A%09at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:62)%0A%09at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:283)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:464)%0A%09at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:209)%0A%09at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72)%0A%09at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:315)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.awaitClose(BulkProcessor.java:243)%0A%09at org.elasticsearch.action.bulk.BulkProcessor.close(BulkProcessor.java:215)%0A%09at org.elasticsearch.action.bulk.BulkProcessorIT.testBulkProcessorConcurrentRequestsNoNodeAvailableException(BulkProcessorIT.java:188)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulkProcessorConcurrentRequestsNoNodeAvailableException(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1459286998987,
  "executionTime": 116
 }
]

[
 "TEST_STARTED",
 "ID#testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThatBulkProcessorCountIsCorrect(org.elasticsearch.action.bulk.BulkProcessorIT)",
  "startTimestamp": 1459286999103,
  "executionTime": 93
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.bulk.BulkProcessorIT",
  "startTimestamp": 1459286998032,
  "executionTime": 1175
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.GlobalIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.GlobalIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.GlobalIT",
   "children": [
    {
     "id": "ID#testWithStatsSubAggregator(org.elasticsearch.search.aggregations.bucket.GlobalIT)",
     "displayName": "testWithStatsSubAggregator(org.elasticsearch.search.aggregations.bucket.GlobalIT)",
     "methodName": "testWithStatsSubAggregator",
     "className": "org.elasticsearch.search.aggregations.bucket.GlobalIT",
     "children": []
    },
    {
     "id": "ID#testNonTopLevel(org.elasticsearch.search.aggregations.bucket.GlobalIT)",
     "displayName": "testNonTopLevel(org.elasticsearch.search.aggregations.bucket.GlobalIT)",
     "methodName": "testNonTopLevel",
     "className": "org.elasticsearch.search.aggregations.bucket.GlobalIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286999213
 }
]

[
 "TEST_STARTED",
 "ID#testWithStatsSubAggregator(org.elasticsearch.search.aggregations.bucket.GlobalIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithStatsSubAggregator(org.elasticsearch.search.aggregations.bucket.GlobalIT)",
  "startTimestamp": 1459286999506,
  "executionTime": 52
 }
]

[
 "TEST_STARTED",
 "ID#testNonTopLevel(org.elasticsearch.search.aggregations.bucket.GlobalIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNonTopLevel(org.elasticsearch.search.aggregations.bucket.GlobalIT)",
  "startTimestamp": 1459286999558,
  "executionTime": 14
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.GlobalIT",
  "startTimestamp": 1459286999213,
  "executionTime": 455
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.similarity.SimilarityIT",
   "displayName": "org.elasticsearch.similarity.SimilarityIT",
   "methodName": null,
   "className": "org.elasticsearch.similarity.SimilarityIT",
   "children": [
    {
     "id": "ID#testCustomBM25Similarity(org.elasticsearch.similarity.SimilarityIT)",
     "displayName": "testCustomBM25Similarity(org.elasticsearch.similarity.SimilarityIT)",
     "methodName": "testCustomBM25Similarity",
     "className": "org.elasticsearch.similarity.SimilarityIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286999672
 }
]

[
 "TEST_STARTED",
 "ID#testCustomBM25Similarity(org.elasticsearch.similarity.SimilarityIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCustomBM25Similarity(org.elasticsearch.similarity.SimilarityIT)",
  "startTimestamp": 1459286999679,
  "executionTime": 147
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.similarity.SimilarityIT",
  "startTimestamp": 1459286999672,
  "executionTime": 168
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
   "displayName": "org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
   "methodName": null,
   "className": "org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
   "children": [
    {
     "id": "ID#testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)",
     "displayName": "testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)",
     "methodName": "testThatRelativePathsDontAffectPlugins",
     "className": "org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459286999844
 }
]

[
 "TEST_STARTED",
 "ID#testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testThatRelativePathsDontAffectPlugins(org.elasticsearch.plugins.SitePluginRelativePathConfigIT)",
  "startTimestamp": 1459286999852,
  "executionTime": 5390
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.plugins.SitePluginRelativePathConfigIT",
  "startTimestamp": 1459286999844,
  "executionTime": 5437
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.geo.GeoFilterIT",
   "displayName": "org.elasticsearch.search.geo.GeoFilterIT",
   "methodName": null,
   "className": "org.elasticsearch.search.geo.GeoFilterIT",
   "children": [
    {
     "id": "ID#testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testGeohashCellFilter",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testBulk(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testBulk(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testBulk",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testShapeBuilders",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testNeighbors",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    },
    {
     "id": "ID#testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)",
     "displayName": "testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)",
     "methodName": "testShapeRelations",
     "className": "org.elasticsearch.search.geo.GeoFilterIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287005306
 }
]

[
 "TEST_STARTED",
 "ID#testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGeohashCellFilter(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1459287005356,
  "executionTime": 727
 }
]

[
 "TEST_STARTED",
 "ID#testBulk(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulk(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1459287006083,
  "executionTime": 2882
 }
]

[
 "TEST_STARTED",
 "ID#testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShapeBuilders(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1459287008966,
  "executionTime": 76
 }
]

[
 "TEST_STARTED",
 "ID#testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNeighbors(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1459287009042,
  "executionTime": 95
 }
]

[
 "TEST_STARTED",
 "ID#testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShapeRelations(org.elasticsearch.search.geo.GeoFilterIT)",
  "startTimestamp": 1459287009137,
  "executionTime": 729
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:09,873][WARN ][org.elasticsearch.transport] [node_s1] Transport response handler not found of id [138]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.geo.GeoFilterIT",
  "startTimestamp": 1459287005306,
  "executionTime": 4575
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
   "displayName": "org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
   "methodName": null,
   "className": "org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
   "children": [
    {
     "id": "ID#testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)",
     "displayName": "testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)",
     "methodName": "testRegexpFilter",
     "className": "org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287009886
 }
]

[
 "TEST_STARTED",
 "ID#testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRegexpFilter(org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT)",
  "startTimestamp": 1459287009899,
  "executionTime": 411
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.fielddata.FieldDataFilterIntegrationIT",
  "startTimestamp": 1459287009886,
  "executionTime": 432
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
   "displayName": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
   "methodName": null,
   "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
   "children": [
    {
     "id": "ID#testFacetByTokenCount",
     "displayName": "testFacetByTokenCount",
     "methodName": null,
     "className": "testFacetByTokenCount",
     "children": [
      {
       "id": "ID#testFacetByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testFacetByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testFacetByTokenCount {storeCountedFields=false loadCountedFields=true}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testFacetByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testFacetByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testFacetByTokenCount {storeCountedFields=true loadCountedFields=false}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testFacetByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testFacetByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testFacetByTokenCount {storeCountedFields=false loadCountedFields=false}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testFacetByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testFacetByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testFacetByTokenCount {storeCountedFields=true loadCountedFields=true}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      }
     ]
    },
    {
     "id": "ID#testSearchByTokenCount",
     "displayName": "testSearchByTokenCount",
     "methodName": null,
     "className": "testSearchByTokenCount",
     "children": [
      {
       "id": "ID#testSearchByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchByTokenCount {storeCountedFields=false loadCountedFields=true}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testSearchByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchByTokenCount {storeCountedFields=true loadCountedFields=false}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testSearchByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchByTokenCount {storeCountedFields=false loadCountedFields=false}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testSearchByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchByTokenCount {storeCountedFields=true loadCountedFields=true}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      }
     ]
    },
    {
     "id": "ID#testSearchReturnsTokenCount",
     "displayName": "testSearchReturnsTokenCount",
     "methodName": null,
     "className": "testSearchReturnsTokenCount",
     "children": [
      {
       "id": "ID#testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=true}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=false}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=false}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      },
      {
       "id": "ID#testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "displayName": "testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
       "methodName": "testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=true}",
       "className": "org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
       "children": []
      }
     ]
    }
   ]
  },
  "startTimestamp": 1459287010330
 }
]

[
 "TEST_STARTED",
 "ID#testFacetByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFacetByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287010343,
  "executionTime": 367
 }
]

[
 "TEST_STARTED",
 "ID#testSearchByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchByTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287010710,
  "executionTime": 229
 }
]

[
 "TEST_STARTED",
 "ID#testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287010939,
  "executionTime": 101
 }
]

[
 "TEST_STARTED",
 "ID#testFacetByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFacetByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287011040,
  "executionTime": 570
 }
]

[
 "TEST_STARTED",
 "ID#testSearchByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchByTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287011610,
  "executionTime": 407
 }
]

[
 "TEST_STARTED",
 "ID#testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287012017,
  "executionTime": 314
 }
]

[
 "TEST_STARTED",
 "ID#testFacetByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFacetByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287012332,
  "executionTime": 388
 }
]

[
 "TEST_STARTED",
 "ID#testSearchByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchByTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287012721,
  "executionTime": 209
 }
]

[
 "TEST_STARTED",
 "ID#testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchReturnsTokenCount {storeCountedFields=false loadCountedFields=false}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287012930,
  "executionTime": 183
 }
]

[
 "TEST_STARTED",
 "ID#testFacetByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFacetByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287013113,
  "executionTime": 254
 }
]

[
 "TEST_STARTED",
 "ID#testSearchByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchByTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287013367,
  "executionTime": 250
 }
]

[
 "TEST_STARTED",
 "ID#testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchReturnsTokenCount {storeCountedFields=true loadCountedFields=true}(org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT)",
  "startTimestamp": 1459287013617,
  "executionTime": 122
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.mapper.core.TokenCountFieldMapperIntegrationIT",
  "startTimestamp": 1459287010330,
  "executionTime": 3417
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.broadcast.BroadcastActionsIT",
   "displayName": "org.elasticsearch.broadcast.BroadcastActionsIT",
   "methodName": null,
   "className": "org.elasticsearch.broadcast.BroadcastActionsIT",
   "children": [
    {
     "id": "ID#testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)",
     "displayName": "testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)",
     "methodName": "testBroadcastOperations",
     "className": "org.elasticsearch.broadcast.BroadcastActionsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287013754
 }
]

[
 "TEST_STARTED",
 "ID#testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBroadcastOperations(org.elasticsearch.broadcast.BroadcastActionsIT)",
  "startTimestamp": 1459287013767,
  "executionTime": 192
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.broadcast.BroadcastActionsIT",
  "startTimestamp": 1459287013754,
  "executionTime": 211
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.settings.ClusterSettingsIT",
   "displayName": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
   "children": [
    {
     "id": "ID#testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testUpdateDiscoveryPublishTimeout",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testClusterNonExistingSettingsUpdate",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testClusterUpdateSettingsWithBlocks",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testDeleteIsAppliedFirst",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testMissingUnits",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testResetClusterSetting",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testClusterSettingsUpdateResponse",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    },
    {
     "id": "ID#testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "displayName": "testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
     "methodName": "testCanUpdateTracerSettings",
     "className": "org.elasticsearch.cluster.settings.ClusterSettingsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287013974
 }
]

[
 "TEST_STARTED",
 "ID#testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUpdateDiscoveryPublishTimeout(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287013988,
  "executionTime": 126
 }
]

[
 "TEST_STARTED",
 "ID#testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterNonExistingSettingsUpdate(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287014114,
  "executionTime": 128
 }
]

[
 "TEST_STARTED",
 "ID#testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterUpdateSettingsWithBlocks(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287014242,
  "executionTime": 133
 }
]

[
 "TEST_STARTED",
 "ID#testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeleteIsAppliedFirst(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287014375,
  "executionTime": 292
 }
]

[
 "TEST_STARTED",
 "ID#testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMissingUnits(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287014667,
  "executionTime": 210
 }
]

[
 "TEST_STARTED",
 "ID#testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:15,155][WARN ][org.elasticsearch.transport] [node_t1] Transport response handler not found of id [6]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testResetClusterSetting(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287014877,
  "executionTime": 291
 }
]

[
 "TEST_STARTED",
 "ID#testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterSettingsUpdateResponse(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287015168,
  "executionTime": 402
 }
]

[
 "TEST_STARTED",
 "ID#testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCanUpdateTracerSettings(org.elasticsearch.cluster.settings.ClusterSettingsIT)",
  "startTimestamp": 1459287015570,
  "executionTime": 317
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.settings.ClusterSettingsIT",
  "startTimestamp": 1459287013974,
  "executionTime": 1976
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.ParentIdAggIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.ParentIdAggIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.ParentIdAggIT",
   "children": [
    {
     "id": "ID#testParentIdAggregation(org.elasticsearch.search.aggregations.bucket.ParentIdAggIT)",
     "displayName": "testParentIdAggregation(org.elasticsearch.search.aggregations.bucket.ParentIdAggIT)",
     "methodName": "testParentIdAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.ParentIdAggIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287015956
 }
]

[
 "TEST_STARTED",
 "ID#testParentIdAggregation(org.elasticsearch.search.aggregations.bucket.ParentIdAggIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testParentIdAggregation(org.elasticsearch.search.aggregations.bucket.ParentIdAggIT)",
  "startTimestamp": 1459287015967,
  "executionTime": 600
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:16,598][WARN ][org.elasticsearch.transport] [node_s1] Transport response handler not found of id [77]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.ParentIdAggIT",
  "startTimestamp": 1459287015956,
  "executionTime": 661
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
   "displayName": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
   "children": [
    {
     "id": "ID#testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testMetricAsSubAgg",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    },
    {
     "id": "ID#testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testDocCountTopLevel",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    },
    {
     "id": "ID#testNested(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testNested(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testNested",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    },
    {
     "id": "ID#testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testDocCountAsSubAgg",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    },
    {
     "id": "ID#testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testMetricTopLevel",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    },
    {
     "id": "ID#testNoBuckets(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testNoBuckets(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testNoBuckets",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    },
    {
     "id": "ID#testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "displayName": "testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
     "methodName": "testMetricAsSubAggWithInsertZeros",
     "className": "org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287016631
 }
]

[
 "TEST_STARTED",
 "ID#testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMetricAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287017889,
  "executionTime": 99
 }
]

[
 "TEST_STARTED",
 "ID#testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDocCountTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287017989,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testNested(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNested(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287018015,
  "executionTime": 43
 }
]

[
 "TEST_STARTED",
 "ID#testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDocCountAsSubAgg(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287018058,
  "executionTime": 26
 }
]

[
 "TEST_STARTED",
 "ID#testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMetricTopLevel(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287018084,
  "executionTime": 23
 }
]

[
 "TEST_STARTED",
 "ID#testNoBuckets(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoBuckets(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287018107,
  "executionTime": 46
 }
]

[
 "TEST_STARTED",
 "ID#testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMetricAsSubAggWithInsertZeros(org.elasticsearch.search.aggregations.pipeline.StatsBucketIT)",
  "startTimestamp": 1459287018154,
  "executionTime": 41
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.pipeline.StatsBucketIT",
  "startTimestamp": 1459287016631,
  "executionTime": 2604
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.gateway.RecoverAfterNodesIT",
   "displayName": "org.elasticsearch.gateway.RecoverAfterNodesIT",
   "methodName": null,
   "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
   "children": [
    {
     "id": "ID#testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "displayName": "testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "methodName": "testRecoverAfterDataNodes",
     "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
     "children": []
    },
    {
     "id": "ID#testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "displayName": "testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "methodName": "testRecoverAfterMasterNodes",
     "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
     "children": []
    },
    {
     "id": "ID#testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "displayName": "testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
     "methodName": "testRecoverAfterNodes",
     "className": "org.elasticsearch.gateway.RecoverAfterNodesIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287019242
 }
]

[
 "TEST_STARTED",
 "ID#testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecoverAfterDataNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
  "startTimestamp": 1459287019256,
  "executionTime": 271
 }
]

[
 "TEST_STARTED",
 "ID#testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecoverAfterMasterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
  "startTimestamp": 1459287019527,
  "executionTime": 216
 }
]

[
 "TEST_STARTED",
 "ID#testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRecoverAfterNodes(org.elasticsearch.gateway.RecoverAfterNodesIT)",
  "startTimestamp": 1459287019743,
  "executionTime": 10224
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.gateway.RecoverAfterNodesIT",
  "startTimestamp": 1459287019242,
  "executionTime": 10737
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.tribe.TribeIT",
   "displayName": "org.elasticsearch.tribe.TribeIT",
   "methodName": null,
   "className": "org.elasticsearch.tribe.TribeIT",
   "children": [
    {
     "id": "ID#testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testCloseAndOpenIndex",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testOnConflictPrefer",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testOnConflictDrop(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testOnConflictDrop(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testOnConflictDrop",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testIndexWriteBlocks",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testGlobalReadWriteBlocks",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    },
    {
     "id": "ID#testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)",
     "displayName": "testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)",
     "methodName": "testTribeOnOneCluster",
     "className": "org.elasticsearch.tribe.TribeIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287029989
 }
]

[
 "TEST_STARTED",
 "ID#testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:30,412][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCloseAndOpenIndex(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1459287030094,
  "executionTime": 834
 }
]

[
 "TEST_STARTED",
 "ID#testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:31,241][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testOnConflictPrefer(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1459287030928,
  "executionTime": 538
 }
]

[
 "TEST_STARTED",
 "ID#testOnConflictDrop(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:31,864][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testOnConflictDrop(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1459287031466,
  "executionTime": 640
 }
]

[
 "TEST_STARTED",
 "ID#testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:32,323][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexWriteBlocks(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1459287032106,
  "executionTime": 417
 }
]

[
 "TEST_STARTED",
 "ID#testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:32,732][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGlobalReadWriteBlocks(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1459287032523,
  "executionTime": 334
 }
]

[
 "TEST_STARTED",
 "ID#testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:33,001][WARN ][org.elasticsearch.discovery] [tribe_node] waited for 0s and no initial state was set by the discovery%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTribeOnOneCluster(org.elasticsearch.tribe.TribeIT)",
  "startTimestamp": 1459287032857,
  "executionTime": 713
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.tribe.TribeIT",
  "startTimestamp": 1459287029989,
  "executionTime": 3603
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.msearch.SimpleMultiSearchIT",
   "displayName": "org.elasticsearch.search.msearch.SimpleMultiSearchIT",
   "methodName": null,
   "className": "org.elasticsearch.search.msearch.SimpleMultiSearchIT",
   "children": [
    {
     "id": "ID#testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)",
     "displayName": "testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)",
     "methodName": "testSimpleMultiSearch",
     "className": "org.elasticsearch.search.msearch.SimpleMultiSearchIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287033598
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleMultiSearch(org.elasticsearch.search.msearch.SimpleMultiSearchIT)",
  "startTimestamp": 1459287033617,
  "executionTime": 1354
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.msearch.SimpleMultiSearchIT",
  "startTimestamp": 1459287033598,
  "executionTime": 1385
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.routing.DelayedAllocationIT",
   "displayName": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
   "children": [
    {
     "id": "ID#testDelayedAllocationChangeWithSettingTo100ms(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "displayName": "testDelayedAllocationChangeWithSettingTo100ms(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "methodName": "testDelayedAllocationChangeWithSettingTo100ms",
     "className": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
     "children": []
    },
    {
     "id": "ID#testDelayedAllocationChangeWithSettingTo0(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "displayName": "testDelayedAllocationChangeWithSettingTo0(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "methodName": "testDelayedAllocationChangeWithSettingTo0",
     "className": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
     "children": []
    },
    {
     "id": "ID#testDelayedAllocationTimesOut(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "displayName": "testDelayedAllocationTimesOut(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "methodName": "testDelayedAllocationTimesOut",
     "className": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
     "children": []
    },
    {
     "id": "ID#testDelayedAllocationNodeLeavesAndComesBack(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "displayName": "testDelayedAllocationNodeLeavesAndComesBack(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "methodName": "testDelayedAllocationNodeLeavesAndComesBack",
     "className": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
     "children": []
    },
    {
     "id": "ID#testNoDelayedTimeout(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "displayName": "testNoDelayedTimeout(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
     "methodName": "testNoDelayedTimeout",
     "className": "org.elasticsearch.cluster.routing.DelayedAllocationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287034991
 }
]

[
 "TEST_STARTED",
 "ID#testDelayedAllocationChangeWithSettingTo100ms(org.elasticsearch.cluster.routing.DelayedAllocationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDelayedAllocationChangeWithSettingTo100ms(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
  "startTimestamp": 1459287035003,
  "executionTime": 561
 }
]

[
 "TEST_STARTED",
 "ID#testDelayedAllocationChangeWithSettingTo0(org.elasticsearch.cluster.routing.DelayedAllocationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDelayedAllocationChangeWithSettingTo0(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
  "startTimestamp": 1459287035564,
  "executionTime": 688
 }
]

[
 "TEST_STARTED",
 "ID#testDelayedAllocationTimesOut(org.elasticsearch.cluster.routing.DelayedAllocationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDelayedAllocationTimesOut(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
  "startTimestamp": 1459287036252,
  "executionTime": 2111
 }
]

[
 "TEST_STARTED",
 "ID#testDelayedAllocationNodeLeavesAndComesBack(org.elasticsearch.cluster.routing.DelayedAllocationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDelayedAllocationNodeLeavesAndComesBack(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
  "startTimestamp": 1459287038363,
  "executionTime": 572
 }
]

[
 "TEST_STARTED",
 "ID#testNoDelayedTimeout(org.elasticsearch.cluster.routing.DelayedAllocationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoDelayedTimeout(org.elasticsearch.cluster.routing.DelayedAllocationIT)",
  "startTimestamp": 1459287038935,
  "executionTime": 605
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.routing.DelayedAllocationIT",
  "startTimestamp": 1459287034991,
  "executionTime": 4601
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
   "displayName": "org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
   "methodName": null,
   "className": "org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
   "children": [
    {
     "id": "ID#testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)",
     "displayName": "testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)",
     "methodName": "testFieldValueFactor",
     "className": "org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287039598
 }
]

[
 "TEST_STARTED",
 "ID#testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFieldValueFactor(org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT)",
  "startTimestamp": 1459287039625,
  "executionTime": 555
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:40,192][WARN ][org.elasticsearch.test.transport] [node_s1] Transport response handler not found of id [28]%0A"
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.functionscore.FunctionScoreFieldValueIT",
  "startTimestamp": 1459287039598,
  "executionTime": 606
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.FilterIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.FilterIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
   "children": [
    {
     "id": "ID#testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testAsSubAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testWithContextBasedSubAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testSimple",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testEmptyFilterDeclarations",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testEmptyAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    },
    {
     "id": "ID#testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "displayName": "testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
     "methodName": "testWithSubAggregation",
     "className": "org.elasticsearch.search.aggregations.bucket.FilterIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287040213
 }
]

[
 "TEST_STARTED",
 "ID#testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testAsSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1459287040598,
  "executionTime": 18
 }
]

[
 "TEST_STARTED",
 "ID#testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithContextBasedSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1459287040616,
  "executionTime": 12
 }
]

[
 "TEST_STARTED",
 "ID#testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimple(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1459287040628,
  "executionTime": 16
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyFilterDeclarations(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1459287040644,
  "executionTime": 14
 }
]

[
 "TEST_STARTED",
 "ID#testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testEmptyAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1459287040658,
  "executionTime": 18
 }
]

[
 "TEST_STARTED",
 "ID#testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithSubAggregation(org.elasticsearch.search.aggregations.bucket.FilterIT)",
  "startTimestamp": 1459287040677,
  "executionTime": 17
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.FilterIT",
  "startTimestamp": 1459287040213,
  "executionTime": 631
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.fetch.FetchSubPhasePluginIT",
   "displayName": "org.elasticsearch.search.fetch.FetchSubPhasePluginIT",
   "methodName": null,
   "className": "org.elasticsearch.search.fetch.FetchSubPhasePluginIT",
   "children": [
    {
     "id": "ID#testPlugin(org.elasticsearch.search.fetch.FetchSubPhasePluginIT)",
     "displayName": "testPlugin(org.elasticsearch.search.fetch.FetchSubPhasePluginIT)",
     "methodName": "testPlugin",
     "className": "org.elasticsearch.search.fetch.FetchSubPhasePluginIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287040850
 }
]

[
 "TEST_STARTED",
 "ID#testPlugin(org.elasticsearch.search.fetch.FetchSubPhasePluginIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPlugin(org.elasticsearch.search.fetch.FetchSubPhasePluginIT)",
  "startTimestamp": 1459287040865,
  "executionTime": 179
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.fetch.FetchSubPhasePluginIT",
  "startTimestamp": 1459287040850,
  "executionTime": 201
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.http.netty.HttpPublishPortIT",
   "displayName": "org.elasticsearch.http.netty.HttpPublishPortIT",
   "methodName": null,
   "className": "org.elasticsearch.http.netty.HttpPublishPortIT",
   "children": [
    {
     "id": "ID#testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)",
     "displayName": "testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)",
     "methodName": "testHttpPublishPort",
     "className": "org.elasticsearch.http.netty.HttpPublishPortIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287041057
 }
]

[
 "TEST_STARTED",
 "ID#testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testHttpPublishPort(org.elasticsearch.http.netty.HttpPublishPortIT)",
  "startTimestamp": 1459287041069,
  "executionTime": 61
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.http.netty.HttpPublishPortIT",
  "startTimestamp": 1459287041057,
  "executionTime": 79
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.action.termvectors.GetTermVectorsIT",
   "displayName": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
   "methodName": null,
   "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
   "children": [
    {
     "id": "ID#testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testNoSuchDoc",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testFilterLength",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testExistingFieldButNotInDocNPE",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testSimpleTermVectors",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testExistingFieldWithNoTermVectorsNoNPE",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testArtificialNoDoc",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testDuelWithAndWithoutTermVectors",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testSimpleWildCards",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testDfs",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testRandomSingleTermVectors",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testArtificialNonExistingField",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testDuelESLucene",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testPerFieldAnalyzer",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testArtificialVsExisting",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testSimpleTermVectorsWithGenerate",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testFilterTermFreq",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testNotIndexedField",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testRandomPayloadWithDelimitedPayloadTokenFilter",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testFilterDocFreq",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    },
    {
     "id": "ID#testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "displayName": "testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
     "methodName": "testTermVectorsWithVersion",
     "className": "org.elasticsearch.action.termvectors.GetTermVectorsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287041153
 }
]

[
 "TEST_STARTED",
 "ID#testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoSuchDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287041163,
  "executionTime": 308
 }
]

[
 "TEST_STARTED",
 "ID#testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFilterLength(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287041471,
  "executionTime": 175
 }
]

[
 "TEST_STARTED",
 "ID#testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExistingFieldButNotInDocNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287041647,
  "executionTime": 146
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287041793,
  "executionTime": 387
 }
]

[
 "TEST_STARTED",
 "ID#testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testExistingFieldWithNoTermVectorsNoNPE(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287042180,
  "executionTime": 140
 }
]

[
 "TEST_STARTED",
 "ID#testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArtificialNoDoc(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287042320,
  "executionTime": 155
 }
]

[
 "TEST_STARTED",
 "ID#testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelWithAndWithoutTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287042475,
  "executionTime": 286
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleWildCards(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287042762,
  "executionTime": 177
 }
]

[
 "TEST_STARTED",
 "ID#testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDfs(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287042939,
  "executionTime": 178
 }
]

[
 "TEST_STARTED",
 "ID#testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRandomSingleTermVectors(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287043118,
  "executionTime": 285
 }
]

[
 "TEST_STARTED",
 "ID#testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArtificialNonExistingField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287043403,
  "executionTime": 149
 }
]

[
 "TEST_STARTED",
 "ID#testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelESLucene(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287043552,
  "executionTime": 121
 }
]

[
 "TEST_STARTED",
 "ID#testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPerFieldAnalyzer(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287043673,
  "executionTime": 182
 }
]

[
 "TEST_STARTED",
 "ID#testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArtificialVsExisting(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287043855,
  "executionTime": 111
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleTermVectorsWithGenerate(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287043966,
  "executionTime": 244
 }
]

[
 "TEST_STARTED",
 "ID#testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFilterTermFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287044210,
  "executionTime": 212
 }
]

[
 "TEST_STARTED",
 "ID#testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNotIndexedField(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287044422,
  "executionTime": 307
 }
]

[
 "TEST_STARTED",
 "ID#testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRandomPayloadWithDelimitedPayloadTokenFilter(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287044729,
  "executionTime": 90
 }
]

[
 "TEST_STARTED",
 "ID#testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFilterDocFreq(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287044819,
  "executionTime": 129
 }
]

[
 "TEST_STARTED",
 "ID#testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTermVectorsWithVersion(org.elasticsearch.action.termvectors.GetTermVectorsIT)",
  "startTimestamp": 1459287044948,
  "executionTime": 169
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.action.termvectors.GetTermVectorsIT",
  "startTimestamp": 1459287041153,
  "executionTime": 3974
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
   "displayName": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
   "methodName": null,
   "className": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
   "children": [
    {
     "id": "ID#testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "displayName": "testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "methodName": "testRestoreUnsupportedSnapshots",
     "className": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
     "children": []
    },
    {
     "id": "ID#testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "displayName": "testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
     "methodName": "testRestoreOldSnapshots",
     "className": "org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287045132
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,237][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,237][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.6.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.6.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.6.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,248][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0.rc1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0.rc1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0.rc1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,260][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,260][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,266][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,266][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,272][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,273][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.6.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.6.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.6.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,279][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,285][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,285][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,292][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,292][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.5.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.5.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.5.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,299][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,299][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.8] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.8] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.8] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,306][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,306][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.1.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.1.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.1.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,311][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,324][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,324][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,332][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,339][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,339][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.4] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,346][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,346][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,352][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,352][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.7] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.7] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.7] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,359][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,359][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.1.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.1.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.1.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,365][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,365][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,371][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,371][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.5] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,376][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,377][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.4] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,382][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,382][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.5.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.5.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.5.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,389][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,390][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.1.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,396][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,396][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,406][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,406][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,412][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,412][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,418][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,418][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,424][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,424][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.9] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.9] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.9] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,431][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,431][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.6.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.6.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.6.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,438][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-0.20.6-and-1.1.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-0.20.6-and-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-0.20.6-and-1.1.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,447][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0.rc2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0.rc2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0.rc2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,453][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,454][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.6] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.6] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.6] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,460][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,460][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.5] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.5] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,467][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,467][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,473][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0.beta2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0.beta2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0.beta2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,479][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,480][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.2.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.2.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.2.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,486][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,486][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.4] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.4] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,493][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,493][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,499][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,499][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.3.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.3.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.3.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,506][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.0.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.0.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.0.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,511][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,511][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.0.beta1] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.0.beta1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.0.beta1] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,516][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,517][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.7.2] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.7.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.7.2] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,522][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,522][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.5.0] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.5.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.5.0] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,527][WARN ][org.elasticsearch.snapshots] [node_t0] time cluster setting [discovery.zen.publish_timeout] with value [30000] is missing units; assuming default units (ms) but in future versions this will be a hard error%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:45,527][WARN ][org.elasticsearch.snapshots] [node_t0] [test_repo:test_1] failed to restore snapshot%0ASnapshotRestoreException[[test_repo:test_1] cannot restore index [index-1.4.3] because it cannot be upgraded]; nested: IllegalStateException[The index [index-1.4.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.];%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:245)%0A%09at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:447)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.lang.IllegalStateException: The index [index-1.4.3] was created before v2.0.0.beta1 and wasn't upgraded. This index should be open using a version before 3.0.0-SNAPSHOT and upgraded using the upgrade API.%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.checkSupportedVersion(MetaDataIndexUpgradeService.java:93)%0A%09at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:70)%0A%09at org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:243)%0A%09... 8 more%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreUnsupportedSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
  "startTimestamp": 1459287045141,
  "executionTime": 399
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:46,028][WARN ][org.elasticsearch.bwcompat] Old repositories tests contain extra repo: 2.0.0-beta1%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreOldSnapshots(org.elasticsearch.bwcompat.RestoreBackwardsCompatIT)",
  "startTimestamp": 1459287045540,
  "executionTime": 493
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.bwcompat.RestoreBackwardsCompatIT",
  "startTimestamp": 1459287045132,
  "executionTime": 906
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.index.IndexWithShadowReplicasIT",
   "displayName": "org.elasticsearch.index.IndexWithShadowReplicasIT",
   "methodName": null,
   "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
   "children": [
    {
     "id": "ID#testCannotCreateWithBadPath(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testCannotCreateWithBadPath(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testCannotCreateWithBadPath",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testRestoreToShadow(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testRestoreToShadow(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testRestoreToShadow",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testPrimaryRelocationWhereRecoveryFails(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testPrimaryRelocationWhereRecoveryFails(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testPrimaryRelocationWhereRecoveryFails",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testIndexWithFewDocuments(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testIndexWithFewDocuments(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testIndexWithFewDocuments",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testPrimaryRelocationWithConcurrentIndexing(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testPrimaryRelocationWithConcurrentIndexing(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testPrimaryRelocationWithConcurrentIndexing",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testIndexOnSharedFSRecoversToAnyNode(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testIndexOnSharedFSRecoversToAnyNode(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testIndexOnSharedFSRecoversToAnyNode",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testDeletingClosedIndexRemovesFiles(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testDeletingClosedIndexRemovesFiles(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testDeletingClosedIndexRemovesFiles",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testShadowReplicaNaturalRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testShadowReplicaNaturalRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testShadowReplicaNaturalRelocation",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testReplicaToPrimaryPromotion(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testReplicaToPrimaryPromotion(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testReplicaToPrimaryPromotion",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testIndexWithShadowReplicasCleansUp(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testIndexWithShadowReplicasCleansUp(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testIndexWithShadowReplicasCleansUp",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testPrimaryRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testPrimaryRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testPrimaryRelocation",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    },
    {
     "id": "ID#testShadowReplicasUsingFieldData(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "displayName": "testShadowReplicasUsingFieldData(org.elasticsearch.index.IndexWithShadowReplicasIT)",
     "methodName": "testShadowReplicasUsingFieldData",
     "className": "org.elasticsearch.index.IndexWithShadowReplicasIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287046046
 }
]

[
 "TEST_STARTED",
 "ID#testCannotCreateWithBadPath(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testCannotCreateWithBadPath(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287046054,
  "executionTime": 29
 }
]

[
 "TEST_STARTED",
 "ID#testRestoreToShadow(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRestoreToShadow(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287046083,
  "executionTime": 273
 }
]

[
 "TEST_STARTED",
 "ID#testPrimaryRelocationWhereRecoveryFails(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPrimaryRelocationWhereRecoveryFails(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287046356,
  "executionTime": 267
 }
]

[
 "TEST_STARTED",
 "ID#testIndexWithFewDocuments(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexWithFewDocuments(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287046623,
  "executionTime": 1284
 }
]

[
 "TEST_STARTED",
 "ID#testPrimaryRelocationWithConcurrentIndexing(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPrimaryRelocationWithConcurrentIndexing(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287047908,
  "executionTime": 258
 }
]

[
 "TEST_STARTED",
 "ID#testIndexOnSharedFSRecoversToAnyNode(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,437][WARN ][org.elasticsearch.index.engine] [node_t2] [test][3] failed engine [primary relocation failed on shared filesystem]%0ANodeDisconnectedException[[node_t0][local[402]][internal:index/shard/recovery/prepare_translog] disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,439][WARN ][org.elasticsearch.test.transport] [node_t0] Transport response handler not found of id [29]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,450][WARN ][org.elasticsearch.indices.cluster] [node_t2] [[test][3]] marking and sending shard failed due to [shard failure, reason [primary relocation failed on shared filesystem]]%0ANodeDisconnectedException[[node_t0][local[402]][internal:index/shard/recovery/prepare_translog] disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,450][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][3] received shard failed for [test][3], node[85OULvz-TWa_uHkS5pjLxg], [P], v[6], s[STARTED], a[id=c_GihHjzSQK7bFt0Sm98mQ], indexUUID [lT-fMdQYRIKoyIjSmH6J3A], message [shard failure, reason [primary relocation failed on shared filesystem]], failure [NodeDisconnectedException[[node_t0][local[402]][internal:index/shard/recovery/prepare_translog] disconnected]]%0ANodeDisconnectedException[[node_t0][local[402]][internal:index/shard/recovery/prepare_translog] disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,452][WARN ][org.elasticsearch.test.transport] [node_t2] Transport response handler not found of id [17]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,452][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][3] received shard failed for [test][3], node[85OULvz-TWa_uHkS5pjLxg], [P], v[6], s[STARTED], a[id=c_GihHjzSQK7bFt0Sm98mQ], indexUUID [lT-fMdQYRIKoyIjSmH6J3A], message [master {node_t1}{g7TulKWxS-ylDVGJwaxlPQ}{local}{local[403]}[mode=>local, add_id_to_custom_path=>false, affinity=>foo] marked shard as started, but shard has previous failed. resending shard failure.], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,452][WARN ][org.elasticsearch.indices.cluster] [node_t0] [[test][3]] marking and sending shard failed due to [failed recovery]%0ARecoveryFailedException[[test][3]: Recovery failed from {node_t2}{85OULvz-TWa_uHkS5pjLxg}{local}{local[404]}[affinity=>bar, add_id_to_custom_path=>false, mode=>local] into {node_t0}{vs2dBYgeQpON9DJHE4Dr3Q}{local}{local[402]}[affinity=>foo, add_id_to_custom_path=>false, mode=>local]]; nested: TransportException[transport stopped, action: internal:index/shard/recovery/start_recovery];%0A%09at org.elasticsearch.indices.recovery.RecoveryTarget.doRecovery(RecoveryTarget.java:271)%0A%09at org.elasticsearch.indices.recovery.RecoveryTarget.access$1100(RecoveryTarget.java:79)%0A%09at org.elasticsearch.indices.recovery.RecoveryTarget$RecoveryRunner.doRun(RecoveryTarget.java:521)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: TransportException[transport stopped, action: internal:index/shard/recovery/start_recovery]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,453][WARN ][org.elasticsearch.cluster.action.shard] [node_t0] [test][3] unexpected failure while sending request [internal:cluster/shard/failure] to [{node_t0}{vs2dBYgeQpON9DJHE4Dr3Q}{local}{local[402]}[affinity=>foo, add_id_to_custom_path=>false, mode=>local]] for shard [[test][3], node[vs2dBYgeQpON9DJHE4Dr3Q], relocating [85OULvz-TWa_uHkS5pjLxg], [P], v[5], s[INITIALIZING], a[id=UXjvRXZQT6qHINKtKMQ4fw, rId=c_GihHjzSQK7bFt0Sm98mQ], indexUUID [lT-fMdQYRIKoyIjSmH6J3A], message [failed recovery], failure [RecoveryFailedException[[test][3]: Recovery failed from {node_t2}{85OULvz-TWa_uHkS5pjLxg}{local}{local[404]}[affinity=>bar, add_id_to_custom_path=>false, mode=>local] into {node_t0}{vs2dBYgeQpON9DJHE4Dr3Q}{local}{local[402]}[affinity=>foo, add_id_to_custom_path=>false, mode=>local]]; nested: TransportException[transport stopped, action: internal:index/shard/recovery/start_recovery]; ]]%0ASendRequestTransportException[[node_t0][local[402]][internal:cluster/shard/failure]]; nested: TransportException[TransportService is closed stopped can't send request];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:274)%0A%09at org.elasticsearch.cluster.action.shard.ShardStateAction.sendShardAction(ShardStateAction.java:93)%0A%09at org.elasticsearch.cluster.action.shard.ShardStateAction.shardFailed(ShardStateAction.java:126)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.sendFailShard(IndicesClusterStateService.java:791)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.failAndRemoveShard(IndicesClusterStateService.java:783)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.handleRecoveryFailure(IndicesClusterStateService.java:748)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.access$400(IndicesClusterStateService.java:85)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService$PeerRecoveryListener.onRecoveryFailure(IndicesClusterStateService.java:742)%0A%09at org.elasticsearch.indices.recovery.RecoveryStatus.fail(RecoveryStatus.java:176)%0A%09at org.elasticsearch.indices.recovery.RecoveriesCollection.failRecovery(RecoveriesCollection.java:121)%0A%09at org.elasticsearch.indices.recovery.RecoveryTarget.doRecovery(RecoveryTarget.java:271)%0A%09at org.elasticsearch.indices.recovery.RecoveryTarget.access$1100(RecoveryTarget.java:79)%0A%09at org.elasticsearch.indices.recovery.RecoveryTarget$RecoveryRunner.doRun(RecoveryTarget.java:521)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: TransportException[TransportService is closed stopped can't send request]%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:295)%0A%09... 17 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,636][WARN ][org.elasticsearch.indices] [node_t3] [test] failed to delete index%0Ajava.io.IOException: Could not remove the following files (in the order of attempts):%0A   /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-011/test/0: java.nio.file.NoSuchFileException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-011/test/0%0A%0A%09at org.apache.lucene.util.IOUtils.rm(IOUtils.java:295)%0A%09at org.elasticsearch.env.NodeEnvironment.deleteIndexDirectoryUnderLock(NodeEnvironment.java:431)%0A%09at org.elasticsearch.env.NodeEnvironment.deleteIndexDirectorySafe(NodeEnvironment.java:411)%0A%09at org.elasticsearch.indices.IndicesService.deleteIndexStore(IndicesService.java:450)%0A%09at org.elasticsearch.indices.IndicesService.deleteIndexStore(IndicesService.java:438)%0A%09at org.elasticsearch.indices.IndicesService.deleteClosedIndex(IndicesService.java:410)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyDeletedIndices(IndicesClusterStateService.java:261)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:194)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:596)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:48,642][WARN ][org.elasticsearch.index.engine] [node_t4] [test][4] failed to rollback writer on close%0Ajava.nio.file.NoSuchFileException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-011/test/4/index%0A%09at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)%0A%09at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)%0A%09at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)%0A%09at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:406)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newDirectoryStream(FilterFileSystemProvider.java:224)%0A%09at org.apache.lucene.mockfile.FilterFileSystemProvider.newDirectoryStream(FilterFileSystemProvider.java:224)%0A%09at org.apache.lucene.mockfile.ShuffleFS.newDirectoryStream(ShuffleFS.java:51)%0A%09at org.apache.lucene.mockfile.HandleTrackingFS.newDirectoryStream(HandleTrackingFS.java:284)%0A%09at org.apache.lucene.mockfile.HandleTrackingFS.newDirectoryStream(HandleTrackingFS.java:284)%0A%09at java.nio.file.Files.newDirectoryStream(Files.java:457)%0A%09at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:190)%0A%09at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:202)%0A%09at org.elasticsearch.index.store.FsDirectoryService$1.listAll(FsDirectoryService.java:129)%0A%09at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57)%0A%09at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57)%0A%09at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57)%0A%09at org.apache.lucene.index.IndexFileDeleter.refresh(IndexFileDeleter.java:426)%0A%09at org.apache.lucene.index.IndexWriter.rollbackInternalNoCommit(IndexWriter.java:2099)%0A%09at org.apache.lucene.index.IndexWriter.rollbackInternal(IndexWriter.java:2041)%0A%09at org.apache.lucene.index.IndexWriter.rollback(IndexWriter.java:2034)%0A%09at org.elasticsearch.index.engine.InternalEngine.closeNoLock(InternalEngine.java:877)%0A%09at org.elasticsearch.index.engine.Engine.close(Engine.java:1063)%0A%09at org.apache.lucene.util.IOUtils.close(IOUtils.java:97)%0A%09at org.apache.lucene.util.IOUtils.close(IOUtils.java:84)%0A%09at org.elasticsearch.index.shard.IndexShard.close(IndexShard.java:809)%0A%09at org.elasticsearch.index.IndexService.closeShard(IndexService.java:367)%0A%09at org.elasticsearch.index.IndexService.removeShard(IndexService.java:351)%0A%09at org.elasticsearch.index.IndexService.close(IndexService.java:226)%0A%09at org.elasticsearch.indices.IndicesService.removeIndex(IndicesService.java:351)%0A%09at org.elasticsearch.indices.IndicesService.deleteIndex(IndicesService.java:399)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.deleteIndex(IndicesClusterStateService.java:763)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyDeletedIndices(IndicesClusterStateService.java:256)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:194)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:596)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexOnSharedFSRecoversToAnyNode(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287048166,
  "executionTime": 491
 }
]

[
 "TEST_STARTED",
 "ID#testDeletingClosedIndexRemovesFiles(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDeletingClosedIndexRemovesFiles(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287048657,
  "executionTime": 397
 }
]

[
 "TEST_STARTED",
 "ID#testShadowReplicaNaturalRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:49,442][WARN ][org.elasticsearch.test.transport] [node_t1] Transport response handler not found of id [83]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShadowReplicaNaturalRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287049054,
  "executionTime": 391
 }
]

[
 "TEST_STARTED",
 "ID#testReplicaToPrimaryPromotion(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testReplicaToPrimaryPromotion(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287049445,
  "executionTime": 129
 }
]

[
 "TEST_STARTED",
 "ID#testIndexWithShadowReplicasCleansUp(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:49,735][WARN ][org.elasticsearch.indices] [node_t2] [test] failed to delete index%0Ajava.io.IOException: Could not remove the following files (in the order of attempts):%0A   /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-020/test/0: java.nio.file.DirectoryNotEmptyException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-020/test/0%0A   /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-020/test: java.nio.file.DirectoryNotEmptyException: /Users/ogbonnayacngwu/CSE2410_spring2016_projectileDysfunction/core/build/testrun/integTest/J1/temp/org.elasticsearch.index.IndexWithShadowReplicasIT_4AA6DECDBC490785-001/tempDir-020/test%0A%0A%09at org.apache.lucene.util.IOUtils.rm(IOUtils.java:295)%0A%09at org.elasticsearch.env.NodeEnvironment.deleteIndexDirectoryUnderLock(NodeEnvironment.java:431)%0A%09at org.elasticsearch.env.NodeEnvironment.deleteIndexDirectorySafe(NodeEnvironment.java:411)%0A%09at org.elasticsearch.indices.IndicesService.deleteIndexStore(IndicesService.java:450)%0A%09at org.elasticsearch.indices.IndicesService.deleteIndexStore(IndicesService.java:438)%0A%09at org.elasticsearch.indices.IndicesService.deleteClosedIndex(IndicesService.java:410)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyDeletedIndices(IndicesClusterStateService.java:261)%0A%09at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:194)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:596)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:49,742][WARN ][org.elasticsearch.test.transport] [node_t1] Transport response handler not found of id [17]%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexWithShadowReplicasCleansUp(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287049574,
  "executionTime": 179
 }
]

[
 "TEST_STARTED",
 "ID#testPrimaryRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testPrimaryRelocation(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287049753,
  "executionTime": 199
 }
]

[
 "TEST_STARTED",
 "ID#testShadowReplicasUsingFieldData(org.elasticsearch.index.IndexWithShadowReplicasIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShadowReplicasUsingFieldData(org.elasticsearch.index.IndexWithShadowReplicasIT)",
  "startTimestamp": 1459287049952,
  "executionTime": 164
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.index.IndexWithShadowReplicasIT",
  "startTimestamp": 1459287046046,
  "executionTime": 4131
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.cluster.NoMasterNodeIT",
   "displayName": "org.elasticsearch.cluster.NoMasterNodeIT",
   "methodName": null,
   "className": "org.elasticsearch.cluster.NoMasterNodeIT",
   "children": [
    {
     "id": "ID#testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)",
     "displayName": "testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)",
     "methodName": "testNoMasterActionsWriteMasterBlock",
     "className": "org.elasticsearch.cluster.NoMasterNodeIT",
     "children": []
    },
    {
     "id": "ID#testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)",
     "displayName": "testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)",
     "methodName": "testNoMasterActions",
     "className": "org.elasticsearch.cluster.NoMasterNodeIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287050183
 }
]

[
 "TEST_STARTED",
 "ID#testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:50,776][WARN ][org.elasticsearch.discovery] [node_t0] waited for 500ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:51,250][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = shut_down), current nodes: {{node_t0}{zSLgSv1JRheyM-Fx8w2XNg}{127.0.0.1}{127.0.0.1:9500}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:52,078][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{Ldymfa8sQtKpN0LqfGhdUg}{127.0.0.1}{127.0.0.1:9501}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoMasterActionsWriteMasterBlock(org.elasticsearch.cluster.NoMasterNodeIT)",
  "startTimestamp": 1459287050191,
  "executionTime": 1895
 }
]

[
 "TEST_STARTED",
 "ID#testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:52,633][WARN ][org.elasticsearch.discovery] [node_t0] waited for 500ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:53,002][WARN ][org.elasticsearch.discovery.zen] [node_t1] not enough master nodes, current nodes: {{node_t1}{-fBjtCMrT4ibcCs6m3msmg}{127.0.0.1}{127.0.0.1:9521}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:54,131][WARN ][org.elasticsearch.indices.cluster] [node_t1] [[test][1]] marking and sending shard failed due to [master [{node_t1}{-fBjtCMrT4ibcCs6m3msmg}{127.0.0.1}{127.0.0.1:9521}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:54,131][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][1] received shard failed for [test][1], node[-fBjtCMrT4ibcCs6m3msmg], [P], v[4], s[STARTED], a[id=v7Uk48BNTJ2nQBlJsWfSfg], indexUUID [FVKJK-VZTneQ_kZBgfJoBw], message [master [{node_t1}{-fBjtCMrT4ibcCs6m3msmg}{127.0.0.1}{127.0.0.1:9521}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:54,131][WARN ][org.elasticsearch.indices.cluster] [node_t1] [[test][0]] marking and sending shard failed due to [master [{node_t1}{-fBjtCMrT4ibcCs6m3msmg}{127.0.0.1}{127.0.0.1:9521}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:54,131][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][0] received shard failed for [test][0], node[-fBjtCMrT4ibcCs6m3msmg], [P], v[5], s[STARTED], a[id=b-UXhODURPaoByOaFCnsXg], indexUUID [FVKJK-VZTneQ_kZBgfJoBw], message [master [{node_t1}{-fBjtCMrT4ibcCs6m3msmg}{127.0.0.1}{127.0.0.1:9521}[mode=>network]] marked shard as started, but shard has not been created, mark shard as failed], failure [Unknown]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:30:54,318][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{W27DeOCLTQe4Rau6csGGJA}{127.0.0.1}{127.0.0.1:9520}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoMasterActions(org.elasticsearch.cluster.NoMasterNodeIT)",
  "startTimestamp": 1459287052087,
  "executionTime": 2240
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.cluster.NoMasterNodeIT",
  "startTimestamp": 1459287050183,
  "executionTime": 4160
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
   "displayName": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
   "children": [
    {
     "id": "ID#testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "displayName": "testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "methodName": "testGetMappingsWhereThereAreNone",
     "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
     "children": []
    },
    {
     "id": "ID#testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "displayName": "testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "methodName": "testGetMappingsWithBlocks",
     "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
     "children": []
    },
    {
     "id": "ID#testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "displayName": "testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
     "methodName": "testSimpleGetMappings",
     "className": "org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287054350
 }
]

[
 "TEST_STARTED",
 "ID#testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetMappingsWhereThereAreNone(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
  "startTimestamp": 1459287054366,
  "executionTime": 153
 }
]

[
 "TEST_STARTED",
 "ID#testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testGetMappingsWithBlocks(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
  "startTimestamp": 1459287054519,
  "executionTime": 248
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleGetMappings(org.elasticsearch.indices.mapping.SimpleGetMappingsIT)",
  "startTimestamp": 1459287054768,
  "executionTime": 336
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.mapping.SimpleGetMappingsIT",
  "startTimestamp": 1459287054350,
  "executionTime": 764
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
   "displayName": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
   "methodName": null,
   "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
   "children": [
    {
     "id": "ID#testNoShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testNoShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testNoShardSizeDouble",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testNoShardSizeTermOrderDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testNoShardSizeTermOrderDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testNoShardSizeTermOrderDouble",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testWithShardSizeDoubleSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testWithShardSizeDoubleSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testWithShardSizeDoubleSingleShard",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testShardSizeEqualsSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testShardSizeEqualsSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testShardSizeEqualsSizeString",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testShardSizeEqualsSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testShardSizeEqualsSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testShardSizeEqualsSizeDouble",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testWithShardSizeLongSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testWithShardSizeLongSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testWithShardSizeLongSingleShard",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testNoShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testNoShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testNoShardSizeLong",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testNoShardSizeTermOrderLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testNoShardSizeTermOrderLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testNoShardSizeTermOrderLong",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testNoShardSizeTermOrderString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testNoShardSizeTermOrderString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testNoShardSizeTermOrderString",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testWithShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testWithShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testWithShardSizeString",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testWithShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testWithShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testWithShardSizeLong",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testNoShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testNoShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testNoShardSizeString",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testShardSizeEqualsSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testShardSizeEqualsSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testShardSizeEqualsSizeLong",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testWithShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testWithShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testWithShardSizeDouble",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    },
    {
     "id": "ID#testWithShardSizeStringSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "displayName": "testWithShardSizeStringSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
     "methodName": "testWithShardSizeStringSingleShard",
     "className": "org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287055121
 }
]

[
 "TEST_STARTED",
 "ID#testNoShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287055128,
  "executionTime": 483
 }
]

[
 "TEST_STARTED",
 "ID#testNoShardSizeTermOrderDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoShardSizeTermOrderDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287055611,
  "executionTime": 341
 }
]

[
 "TEST_STARTED",
 "ID#testWithShardSizeDoubleSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithShardSizeDoubleSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287055953,
  "executionTime": 178
 }
]

[
 "TEST_STARTED",
 "ID#testShardSizeEqualsSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShardSizeEqualsSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287056131,
  "executionTime": 361
 }
]

[
 "TEST_STARTED",
 "ID#testShardSizeEqualsSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShardSizeEqualsSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287056492,
  "executionTime": 139
 }
]

[
 "TEST_STARTED",
 "ID#testWithShardSizeLongSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithShardSizeLongSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287056631,
  "executionTime": 417
 }
]

[
 "TEST_STARTED",
 "ID#testNoShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287057049,
  "executionTime": 205
 }
]

[
 "TEST_STARTED",
 "ID#testNoShardSizeTermOrderLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoShardSizeTermOrderLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287057254,
  "executionTime": 421
 }
]

[
 "TEST_STARTED",
 "ID#testNoShardSizeTermOrderString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoShardSizeTermOrderString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287057675,
  "executionTime": 191
 }
]

[
 "TEST_STARTED",
 "ID#testWithShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287057866,
  "executionTime": 311
 }
]

[
 "TEST_STARTED",
 "ID#testWithShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithShardSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287058177,
  "executionTime": 180
 }
]

[
 "TEST_STARTED",
 "ID#testNoShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNoShardSizeString(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287058357,
  "executionTime": 244
 }
]

[
 "TEST_STARTED",
 "ID#testShardSizeEqualsSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testShardSizeEqualsSizeLong(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287058601,
  "executionTime": 142
 }
]

[
 "TEST_STARTED",
 "ID#testWithShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithShardSizeDouble(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287058743,
  "executionTime": 207
 }
]

[
 "TEST_STARTED",
 "ID#testWithShardSizeStringSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testWithShardSizeStringSingleShard(org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT)",
  "startTimestamp": 1459287058951,
  "executionTime": 147
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.aggregations.bucket.ShardSizeTermsIT",
  "startTimestamp": 1459287055121,
  "executionTime": 4009
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
   "displayName": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
   "methodName": null,
   "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
   "children": [
    {
     "id": "ID#testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testFieldStatsIndexLevel",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testFieldStatsFiltering",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testIncompatibleFilter",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testIncompatibleFieldTypes",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    },
    {
     "id": "ID#testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "displayName": "testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
     "methodName": "testRandom",
     "className": "org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287059138
 }
]

[
 "TEST_STARTED",
 "ID#testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFieldStatsIndexLevel(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1459287059151,
  "executionTime": 4022
 }
]

[
 "TEST_STARTED",
 "ID#testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFieldStatsFiltering(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1459287063173,
  "executionTime": 1698
 }
]

[
 "TEST_STARTED",
 "ID#testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIncompatibleFilter(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1459287064872,
  "executionTime": 359
 }
]

[
 "TEST_STARTED",
 "ID#testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIncompatibleFieldTypes(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1459287065231,
  "executionTime": 388
 }
]

[
 "TEST_STARTED",
 "ID#testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRandom(org.elasticsearch.fieldstats.FieldStatsIntegrationIT)",
  "startTimestamp": 1459287065619,
  "executionTime": 1042
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.fieldstats.FieldStatsIntegrationIT",
  "startTimestamp": 1459287059138,
  "executionTime": 7537
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.indices.state.SimpleIndexStateIT",
   "displayName": "org.elasticsearch.indices.state.SimpleIndexStateIT",
   "methodName": null,
   "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
   "children": [
    {
     "id": "ID#testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "displayName": "testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "methodName": "testConsistencyAfterIndexCreationFailure",
     "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
     "children": []
    },
    {
     "id": "ID#testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "displayName": "testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "methodName": "testFastCloseAfterCreateContinuesCreateAfterOpen",
     "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
     "children": []
    },
    {
     "id": "ID#testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "displayName": "testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)",
     "methodName": "testSimpleOpenClose",
     "className": "org.elasticsearch.indices.state.SimpleIndexStateIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287066681
 }
]

[
 "TEST_STARTED",
 "ID#testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testConsistencyAfterIndexCreationFailure(org.elasticsearch.indices.state.SimpleIndexStateIT)",
  "startTimestamp": 1459287066698,
  "executionTime": 167
 }
]

[
 "TEST_STARTED",
 "ID#testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFastCloseAfterCreateContinuesCreateAfterOpen(org.elasticsearch.indices.state.SimpleIndexStateIT)",
  "startTimestamp": 1459287066865,
  "executionTime": 65
 }
]

[
 "TEST_STARTED",
 "ID#testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:07,049][WARN ][org.elasticsearch.action.index] [node_s2] unexpected error during the primary phase for action [indices:data/write/index], request [index {[test][type1][1], source[{\"field1\":\"value1\"}]}]%0A[test] IndexClosedException[closed]%0A%09at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:170)%0A%09at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:93)%0A%09at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteSingleIndex(IndexNameExpressionResolver.java:206)%0A%09at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:425)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:137)%0A%09at org.elasticsearch.action.index.TransportIndexAction.innerExecute(TransportIndexAction.java:133)%0A%09at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:117)%0A%09at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:64)%0A%09at org.elasticsearch.action.support.TransportAction.doExecute(TransportAction.java:113)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:101)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:65)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:57)%0A%09at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:387)%0A%09at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:86)%0A%09at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:60)%0A%09at org.elasticsearch.action.ActionRequestBuilder.get(ActionRequestBuilder.java:68)%0A%09at org.elasticsearch.indices.state.SimpleIndexStateIT.testSimpleOpenClose(SimpleIndexStateIT.java:76)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSimpleOpenClose(org.elasticsearch.indices.state.SimpleIndexStateIT)",
  "startTimestamp": 1459287066930,
  "executionTime": 226
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.indices.state.SimpleIndexStateIT",
  "startTimestamp": 1459287066681,
  "executionTime": 488
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.search.scroll.DuelScrollIT",
   "displayName": "org.elasticsearch.search.scroll.DuelScrollIT",
   "methodName": null,
   "className": "org.elasticsearch.search.scroll.DuelScrollIT",
   "children": [
    {
     "id": "ID#testDuelQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "displayName": "testDuelQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "methodName": "testDuelQueryAndFetch",
     "className": "org.elasticsearch.search.scroll.DuelScrollIT",
     "children": []
    },
    {
     "id": "ID#testDuelIndexOrderQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "displayName": "testDuelIndexOrderQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "methodName": "testDuelIndexOrderQueryThenFetch",
     "className": "org.elasticsearch.search.scroll.DuelScrollIT",
     "children": []
    },
    {
     "id": "ID#testDuelQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "displayName": "testDuelQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "methodName": "testDuelQueryThenFetch",
     "className": "org.elasticsearch.search.scroll.DuelScrollIT",
     "children": []
    },
    {
     "id": "ID#testDuelIndexOrderQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "displayName": "testDuelIndexOrderQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
     "methodName": "testDuelIndexOrderQueryAndFetch",
     "className": "org.elasticsearch.search.scroll.DuelScrollIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287067175
 }
]

[
 "TEST_STARTED",
 "ID#testDuelQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
  "startTimestamp": 1459287067182,
  "executionTime": 376
 }
]

[
 "TEST_STARTED",
 "ID#testDuelIndexOrderQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelIndexOrderQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
  "startTimestamp": 1459287067558,
  "executionTime": 231
 }
]

[
 "TEST_STARTED",
 "ID#testDuelQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelQueryThenFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
  "startTimestamp": 1459287067789,
  "executionTime": 208
 }
]

[
 "TEST_STARTED",
 "ID#testDuelIndexOrderQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testDuelIndexOrderQueryAndFetch(org.elasticsearch.search.scroll.DuelScrollIT)",
  "startTimestamp": 1459287067997,
  "executionTime": 110
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.search.scroll.DuelScrollIT",
  "startTimestamp": 1459287067175,
  "executionTime": 943
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.document.AliasedIndexDocumentActionsIT",
   "displayName": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
   "methodName": null,
   "className": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
   "children": [
    {
     "id": "ID#testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "displayName": "testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "methodName": "testIndexActions",
     "className": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
     "children": []
    },
    {
     "id": "ID#testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "displayName": "testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
     "methodName": "testBulk",
     "className": "org.elasticsearch.document.AliasedIndexDocumentActionsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287068126
 }
]

[
 "TEST_STARTED",
 "ID#testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexActions(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
  "startTimestamp": 1459287068134,
  "executionTime": 182
 }
]

[
 "TEST_STARTED",
 "ID#testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testBulk(org.elasticsearch.document.AliasedIndexDocumentActionsIT)",
  "startTimestamp": 1459287068316,
  "executionTime": 305
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.document.AliasedIndexDocumentActionsIT",
  "startTimestamp": 1459287068126,
  "executionTime": 512
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
   "displayName": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
   "methodName": null,
   "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
   "children": [
    {
     "id": "ID#testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testUnicastSinglePingResponseContainsMaster",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIndicesDeleted",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testAckedIndexing",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIsolateMasterAndVerifyClusterStateConsensus",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testClusterFormingWithASlowNode",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIsolatedUnicastNodes",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testNodeNotReachableFromMaster",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testFailWithMinimumMasterNodesConfigured",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testVerifyApiBlocksDuringPartition",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testClusterJoinDespiteOfPublishingIssues",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testSendingShardFailure",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testSearchWithRelocationAndSlowClusterStateProcessing",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testRejoinDocumentExistsInAllShardCopies",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testStaleMasterNotHijackingMajority",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testMasterNodeGCs",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    },
    {
     "id": "ID#testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "displayName": "testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
     "methodName": "testNodesFDAfterMasterReelection",
     "className": "org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287068668
 }
]

[
 "TEST_STARTED",
 "ID#testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:12,946][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t0}{w7mgH9ASTMSI3sall-e8vw}{127.0.0.1}{127.0.0.1:30200}[mode=>network],{node_t1}{iKWi1xKXQDOVBUyBVMXagA}{127.0.0.1}{127.0.0.1:30201}[mode=>network],{node_t3}{GlTjo2pdRHulZSjiWJkEUg}{127.0.0.1}{127.0.0.1:30203}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:16,007][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t3}{GlTjo2pdRHulZSjiWJkEUg}{127.0.0.1}{127.0.0.1:30203}[mode=>network],{node_t2}{D3YJHzcqSDClnVd4ewkQZg}{127.0.0.1}{127.0.0.1:30202}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:16,011][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = transport disconnected), current nodes: {{node_t1}{iKWi1xKXQDOVBUyBVMXagA}{127.0.0.1}{127.0.0.1:30201}[mode=>network],{node_t3}{GlTjo2pdRHulZSjiWJkEUg}{127.0.0.1}{127.0.0.1:30203}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testUnicastSinglePingResponseContainsMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287068684,
  "executionTime": 7333
 }
]

[
 "TEST_STARTED",
 "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287076018,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "message": "'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/11665))",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/11665))\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:766)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)\n\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)\n\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)\n\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)\n\tat java.lang.Thread.run(Thread.java:745)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=https://github.com/elastic/elasticsearch/issues/11665))",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndicesDeleted(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287076018,
  "executionTime": 0
 }
]

[
 "TEST_STARTED",
 "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "TEST_IGNORED",
 {
  "description": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287076018,
  "cause": "Unknown reason for ignore status."
 }
]

[
 "TEST_IGNORED_ASSUMPTION",
 {
  "description": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "message": "'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=needs some more work to stabilize))",
  "trace": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=needs some more work to stabilize))\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.isTestIgnored(RandomizedRunner.java:1236)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:140)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:766)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)\n\tat com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)\n\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)\n\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)\n\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)\n\tat java.lang.Thread.run(Thread.java:745)\n",
  "throwableString": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException: 'awaitsfix' test group is disabled (@AwaitsFix(bugUrl=needs some more work to stabilize))",
  "throwableClass": "com.carrotsearch.randomizedtesting.InternalAssumptionViolatedException",
  "assertionViolation": false,
  "assumptionViolation": true
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testAckedIndexing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287076018,
  "executionTime": 1
 }
]

[
 "TEST_STARTED",
 "ID#testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,253][WARN ][org.elasticsearch.cluster.service] [node_t2] failing [zen-disco-node_failed({node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,253][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = transport disconnected), current nodes: {{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network],{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,254][ERROR][org.elasticsearch.discovery.zen] [node_t2] unexpected failure during [zen-disco-node_failed({node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,256][WARN ][org.elasticsearch.cluster.service] [node_t2] failing [zen-disco-node_failed({node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,256][ERROR][org.elasticsearch.discovery.zen] [node_t2] unexpected failure during [zen-disco-node_failed({node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,258][WARN ][org.elasticsearch.cluster.service] [node_t2] failing [zen-disco-node_failed({node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]), reason transport disconnected]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,259][ERROR][org.elasticsearch.discovery.zen] [node_t2] unexpected failure during [zen-disco-node_failed({node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]), reason transport disconnected]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,259][WARN ][org.elasticsearch.discovery.zen] [node_t2] failed to publish to min_master_nodes, current nodes: {{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network],{node_t2}{2KnZmVE4RtyVNjZrqonhwA}{127.0.0.1}{127.0.0.1:30206}[mode=>network],{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,259][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30204}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,259][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,260][ERROR][org.elasticsearch.discovery.zen] [node_t2] unexpected failure during [zen-disco-failed-to-publish]%0Aorg.elasticsearch.cluster.NotMasterException: no longer master. source: [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,260][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network],{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,262][ERROR][org.elasticsearch.discovery.zen] [node_t2] unexpected failure during [zen-disco-failed-to-publish]%0Aorg.elasticsearch.cluster.NotMasterException: no longer master. source: [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,259][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30205}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:20,259][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:21,760][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30204}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:21,761][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:21,760][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30205}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:21,762][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,267][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30204}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,268][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30204}]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,268][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,268][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,267][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30205}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2$1.doRun(UnicastZenPing.java:253)%0A%09at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 7 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,269][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t0}{tkph-ZLDRhiLVKw01Yytcg}{127.0.0.1}{127.0.0.1:30204}[mode=>network]]%0ASendRequestTransportException[[node_t0][127.0.0.1:30204][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30204] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,269][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{node_t1}{nS9mZUmrQ5mj_QLEZRMoWw}{127.0.0.1}{127.0.0.1:30205}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:23,269][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30205}]%0ASendRequestTransportException[[node_t1][127.0.0.1:30205][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30205] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:26,390][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{2KnZmVE4RtyVNjZrqonhwA}{127.0.0.1}{127.0.0.1:30206}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIsolateMasterAndVerifyClusterStateConsensus(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287076019,
  "executionTime": 10378
 }
]

[
 "TEST_STARTED",
 "ID#testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:26,466][WARN ][org.elasticsearch.discovery] [node_t0] waited for 1ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:26,578][WARN ][org.elasticsearch.discovery] [node_t1] waited for 1ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:26,673][WARN ][org.elasticsearch.discovery] [node_t2] waited for 1ms and no initial state was set by the discovery%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,225][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{FjLJM74gTlyt77az81FgFQ}{127.0.0.1}{127.0.0.1:30209}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterFormingWithASlowNode(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287086397,
  "executionTime": 9835
 }
]

[
 "TEST_STARTED",
 "ID#testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,271][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t0] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,272][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] using initial hosts [127.0.0.1:30210], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,272][DEBUG][org.elasticsearch.discovery.zen] [node_t0] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,272][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,272][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[426], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,287][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[427], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,326][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t1] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,326][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] using initial hosts [127.0.0.1:30210], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,327][DEBUG][org.elasticsearch.discovery.zen] [node_t1] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,327][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,327][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,343][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]: [ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[429], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,344][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,344][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,345][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[430], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,390][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t2] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,390][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] using initial hosts [127.0.0.1:30210], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,390][DEBUG][org.elasticsearch.discovery.zen] [node_t2] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,390][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,390][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,406][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,406][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,406][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,406][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,406][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,407][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,407][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,407][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[432], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,407][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,407][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,409][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[433], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,438][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t3] using minimum_master_nodes [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,438][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] using initial hosts [127.0.0.1:30210], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,439][DEBUG][org.elasticsearch.discovery.zen] [node_t3] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,439][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,439][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,461][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,462][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[435], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,463][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,463][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:36,464][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[436], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[438], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,791][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] with temp node {#zen_unicast_2_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,792][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] with temp node {#zen_unicast_3_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,792][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_2_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,792][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,792][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[439], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,792][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_3_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,793][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network] with temp node {#zen_unicast_4_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,793][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,793][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_4_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,793][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_2_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,793][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,793][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_3_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,794][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,794][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_4_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,795][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_3_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[441], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,795][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_2_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]: [ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[440], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,804][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_4_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[442], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,853][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,854][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,854][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]: [ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[444], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,855][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,855][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,855][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[445], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,855][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,856][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,856][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[446], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,909][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,909][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,909][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[448], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,909][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,910][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,910][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[449], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,910][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,910][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,911][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[450], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,965][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,966][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,966][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,966][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connecting (light) to {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,966][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[452], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,967][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connected to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,967][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[453], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,967][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:37,968][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[454], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,297][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[456], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] with temp node {#zen_unicast_5_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] with temp node {#zen_unicast_6_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,298][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_5_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_6_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[457], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network] with temp node {#zen_unicast_7_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,299][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_7_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,300][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,300][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_6_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,300][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,300][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_5_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,300][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,300][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_7_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_6_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[459], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_7_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[460], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,301][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_5_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]: [ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[458], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,302][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_7_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,304][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[458], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[460], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[459], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,304][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_3_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,304][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[458], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[460], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[459], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,305][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_4_oczvfipLTr6a3WhOLDyYyg#}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,305][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,305][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_6_OFXtVNaKRe6VL9NvBc3e0g#}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,306][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_5_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,306][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_2_7mM6N0_eQxyn28mYxCpKrw#}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,307][TRACE][org.elasticsearch.discovery.zen] [node_t0] joining master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,355][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,355][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,355][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]: [ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[462], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,355][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,355][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[463], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,356][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[464], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,357][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,357][TRACE][org.elasticsearch.discovery.zen] [node_t1] full ping responses:%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[464], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,358][DEBUG][org.elasticsearch.discovery.zen] [node_t1] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[464], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,358][DEBUG][org.elasticsearch.discovery.zen] [node_t1] elected as master, waiting for incoming joins ([2] needed)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,358][TRACE][org.elasticsearch.discovery.zen] [node_t1] not enough joins for election. Got [1], required [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,358][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,411][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,412][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,412][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[466], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,412][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,412][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,413][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[467], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,413][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,413][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,414][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[468], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,415][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,415][TRACE][org.elasticsearch.discovery.zen] [node_t2] full ping responses:%0A%09--> ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[468], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,416][DEBUG][org.elasticsearch.discovery.zen] [node_t2] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[468], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,416][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,416][TRACE][org.elasticsearch.discovery.zen] [node_t2] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,419][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,421][TRACE][org.elasticsearch.discovery.zen] [node_t2] joining master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,423][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(elected_as_master, [2] joins received)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,424][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(elected_as_master, [2] joins received)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,424][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(elected_as_master, [2] joins received)]%0Aversion: 1%0Astate uuid: 3Kr9DLC_SWC4NiNFgJ_k5g%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], local, master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,424][INFO ][org.elasticsearch.cluster.service] [node_t1] new_master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], added {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network],}, reason: zen-disco-join(elected_as_master, [2] joins received)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,424][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,425][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received full cluster state version [1] with size [322]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,427][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received full cluster state version [1] with size [322]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,427][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] acked cluster state version [1]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] acked cluster state version [1]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [3Kr9DLC_SWC4NiNFgJ_k5g], version [1]) to [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [3Kr9DLC_SWC4NiNFgJ_k5g], version [1]) to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,428][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] restarting fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] restarting fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][DEBUG][org.elasticsearch.discovery.zen] [node_t2] got first state from fresh master [7mM6N0_eQxyn28mYxCpKrw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][DEBUG][org.elasticsearch.discovery.zen] [node_t0] got first state from fresh master [7mM6N0_eQxyn28mYxCpKrw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][TRACE][org.elasticsearch.discovery.zen] [node_t2] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][TRACE][org.elasticsearch.discovery.zen] [node_t0] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: 3Kr9DLC_SWC4NiNFgJ_k5g%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: 3Kr9DLC_SWC4NiNFgJ_k5g%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network], local%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][INFO ][org.elasticsearch.cluster.service] [node_t2] detected_master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], added {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,429][INFO ][org.elasticsearch.cluster.service] [node_t0] detected_master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], added {{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,432][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,432][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,432][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]: took 4ms done applying updated cluster_state (version: 1, uuid: 3Kr9DLC_SWC4NiNFgJ_k5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,432][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [1]])]: took 4ms done applying updated cluster_state (version: 1, uuid: 3Kr9DLC_SWC4NiNFgJ_k5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.discovery.zen] [node_t1] stopping join accumulation ([election closed])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.discovery.zen] [node_t1] cluster joins counter set to [1] (elected as master)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(elected_as_master, [2] joins received)]: took 9ms done applying updated cluster_state (version: 1, uuid: 3Kr9DLC_SWC4NiNFgJ_k5g)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,433][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,434][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [local-gateway-elected-state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,434][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [local-gateway-elected-state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,435][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [local-gateway-elected-state]%0Aversion: 2%0Astate uuid: X_D0sNJeR22tGBhMAa3gSQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], local, master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,435][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,435][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received diff cluster state version [2] with uuid [X_D0sNJeR22tGBhMAa3gSQ], diff size [172]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,435][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [2] with uuid [X_D0sNJeR22tGBhMAa3gSQ], diff size [172]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,435][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] acked cluster state version [2]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] acked cluster state version [2]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [X_D0sNJeR22tGBhMAa3gSQ], version [2]) to [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [X_D0sNJeR22tGBhMAa3gSQ], version [2]) to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: X_D0sNJeR22tGBhMAa3gSQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network], local%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: X_D0sNJeR22tGBhMAa3gSQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,436][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,438][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]: took 2ms done applying updated cluster_state (version: 2, uuid: X_D0sNJeR22tGBhMAa3gSQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,438][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [2]])]: took 1ms done applying updated cluster_state (version: 2, uuid: X_D0sNJeR22tGBhMAa3gSQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,438][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,440][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [local-gateway-elected-state]: took 5ms done applying updated cluster_state (version: 2, uuid: X_D0sNJeR22tGBhMAa3gSQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,467][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,467][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,467][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,467][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connecting (light) to {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,467][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[469], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[470], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,468][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[469], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[471], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,468][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] connected to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,468][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] sending to {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,469][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] received response from {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[425], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[428], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[431], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[434], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[437], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[443], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[447], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[451], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[455], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[469], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[469], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[472], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,470][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,470][TRACE][org.elasticsearch.discovery.zen] [node_t3] full ping responses:%0A%09--> ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[472], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,470][DEBUG][org.elasticsearch.discovery.zen] [node_t3] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], id[461], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[472], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[465], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,470][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] disconnecting from {#zen_unicast_3_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,470][TRACE][org.elasticsearch.discovery.zen] [node_t3] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,470][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [1] disconnecting from {#zen_unicast_2_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,472][TRACE][org.elasticsearch.discovery.zen] [node_t3] joining master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,474][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(join from node[{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,474][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,474][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(join from node[{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]])]%0Aversion: 3%0Astate uuid: TVRtncTZQ2KgTTomBzL8nw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], local, master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,474][INFO ][org.elasticsearch.cluster.service] [node_t1] added {{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],}, reason: zen-disco-join(join from node[{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,474][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received full cluster state version [3] with size [312]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received diff cluster state version [3] with uuid [TVRtncTZQ2KgTTomBzL8nw], diff size [331]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [3] with uuid [TVRtncTZQ2KgTTomBzL8nw], diff size [331]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network] acked cluster state version [3]. processing ... (current pending [3], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] acked cluster state version [3]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [TVRtncTZQ2KgTTomBzL8nw], version [3]) to [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [TVRtncTZQ2KgTTomBzL8nw], version [3]) to [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [TVRtncTZQ2KgTTomBzL8nw], version [3]) to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,475][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] restarting fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][DEBUG][org.elasticsearch.discovery.zen] [node_t3] got first state from fresh master [7mM6N0_eQxyn28mYxCpKrw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][TRACE][org.elasticsearch.discovery.zen] [node_t3] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: TVRtncTZQ2KgTTomBzL8nw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: TVRtncTZQ2KgTTomBzL8nw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], local%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][INFO ][org.elasticsearch.cluster.service] [node_t2] added {{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][INFO ][org.elasticsearch.cluster.service] [node_t3] detected_master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], added {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: TVRtncTZQ2KgTTomBzL8nw%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network], local%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,476][INFO ][org.elasticsearch.cluster.service] [node_t0] added {{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,479][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,479][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,479][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]: took 3ms done applying updated cluster_state (version: 3, uuid: TVRtncTZQ2KgTTomBzL8nw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,479][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]: took 3ms done applying updated cluster_state (version: 3, uuid: TVRtncTZQ2KgTTomBzL8nw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,481][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [3]])]: took 6ms done applying updated cluster_state (version: 3, uuid: TVRtncTZQ2KgTTomBzL8nw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]])]: took 8ms done applying updated cluster_state (version: 3, uuid: TVRtncTZQ2KgTTomBzL8nw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,482][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,483][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,484][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,484][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:39,484][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [master] [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] stopping fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [master failure, transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][TRACE][org.elasticsearch.discovery.zen.fd] [node_t1] [node  ] [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][INFO ][org.elasticsearch.discovery.zen] [node_t0] master_left [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-node_failed({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]), reason transport disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,432][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_failed({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]), reason transport disconnected]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = transport disconnected), current nodes: {{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-node_failed({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]), reason transport disconnected]%0Aversion: 4%0Astate uuid: MPudj16oR-W5YHnt-_9-vQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], local, master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-node_failed({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]), reason transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0Aversion: 3%0Astate uuid: TVRtncTZQ2KgTTomBzL8nw%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network], local%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][INFO ][org.elasticsearch.cluster.service] [node_t0] removed {{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[474], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]]%0ASendRequestTransportException[[node_t1][127.0.0.1:30211][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t1][127.0.0.1:30211] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t1][127.0.0.1:30211] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,434][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 1ms done applying updated cluster_state (version: 3, uuid: TVRtncTZQ2KgTTomBzL8nw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,434][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received diff cluster state version [4] with uuid [MPudj16oR-W5YHnt-_9-vQ], diff size [307]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,434][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [4] with uuid [MPudj16oR-W5YHnt-_9-vQ], diff size [307]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0ASendRequestTransportException[[node_t2][127.0.0.1:30212][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t2][127.0.0.1:30212] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t2][127.0.0.1:30212] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,433][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,435][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network] acked cluster state version [4]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[475], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] acked cluster state version [4]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [MPudj16oR-W5YHnt-_9-vQ], version [4]) to [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]]%0ASendRequestTransportException[[node_t3][127.0.0.1:30213][internal:discovery/zen/unicast]]; nested: ConnectTransportException[[node_t3][127.0.0.1:30213] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:240)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:106)%0A%09at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:84)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:888)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:394)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.access$4700(ZenDiscovery.java:90)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1221)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t3][127.0.0.1:30213] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 12 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,438][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,437][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [MPudj16oR-W5YHnt-_9-vQ], version [4]) to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: MPudj16oR-W5YHnt-_9-vQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], local%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][INFO ][org.elasticsearch.cluster.service] [node_t3] removed {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: MPudj16oR-W5YHnt-_9-vQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,439][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,440][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]: took 0s done applying updated cluster_state (version: 4, uuid: MPudj16oR-W5YHnt-_9-vQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,440][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [4]])]: took 0s done applying updated cluster_state (version: 4, uuid: MPudj16oR-W5YHnt-_9-vQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,440][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,441][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_failed({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]), reason transport disconnected]: took 8ms done applying updated cluster_state (version: 4, uuid: MPudj16oR-W5YHnt-_9-vQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,441][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,441][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:40,441][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[477], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[478], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,943][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[479], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:41,944][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[480], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,452][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,452][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[482], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,452][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,452][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,452][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[473], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[483], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,453][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,453][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[484], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,454][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[485], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,454][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[485], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[484], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,454][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[485], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A%09--> ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[484], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,454][TRACE][org.elasticsearch.discovery.zen] [node_t0] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,454][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,455][TRACE][org.elasticsearch.discovery.zen] [node_t0] joining master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,458][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-join(join from node[{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,458][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,458][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-join(join from node[{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]])]%0Aversion: 5%0Astate uuid: BsGkmbW7SHiaZdJhl9trvQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], local, master%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,458][INFO ][org.elasticsearch.cluster.service] [node_t1] added {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-join(join from node[{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,458][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received diff cluster state version [5] with uuid [BsGkmbW7SHiaZdJhl9trvQ], diff size [332]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [5] with uuid [BsGkmbW7SHiaZdJhl9trvQ], diff size [332]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received full cluster state version [5] with size [314]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network] acked cluster state version [5]. processing ... (current pending [3], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] acked cluster state version [5]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [BsGkmbW7SHiaZdJhl9trvQ], version [5]) to [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [BsGkmbW7SHiaZdJhl9trvQ], version [5]) to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [BsGkmbW7SHiaZdJhl9trvQ], version [5]) to [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: BsGkmbW7SHiaZdJhl9trvQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], local%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: BsGkmbW7SHiaZdJhl9trvQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][INFO ][org.elasticsearch.cluster.service] [node_t3] added {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,459][INFO ][org.elasticsearch.cluster.service] [node_t2] added {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] restarting fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][DEBUG][org.elasticsearch.discovery.zen] [node_t0] got first state from fresh master [7mM6N0_eQxyn28mYxCpKrw]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][TRACE][org.elasticsearch.discovery.zen] [node_t0] updated cluster join cluster to [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: BsGkmbW7SHiaZdJhl9trvQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0A   {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[UdumSPqySZq2FCkBl6pKIw][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][INFO ][org.elasticsearch.cluster.service] [node_t0] detected_master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], added {{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,460][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]: took 0s done applying updated cluster_state (version: 5, uuid: BsGkmbW7SHiaZdJhl9trvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]: took 2ms done applying updated cluster_state (version: 5, uuid: BsGkmbW7SHiaZdJhl9trvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [5]])]: took 2ms done applying updated cluster_state (version: 5, uuid: BsGkmbW7SHiaZdJhl9trvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-join(join from node[{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]])]: took 4ms done applying updated cluster_state (version: 5, uuid: BsGkmbW7SHiaZdJhl9trvQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,462][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,463][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,463][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,463][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,463][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,467][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [delete_repository [*]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,467][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,467][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [delete_repository [*]]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,470][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] stopping fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [zen disco stop]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,470][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-node_left({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,470][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_left({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,470][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-node_left({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network])]%0Aversion: 6%0Astate uuid: 7QvjTXCtQnSqNUdhWT0grQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], local, master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,471][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-node_left({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,471][DEBUG][org.elasticsearch.cluster.service] [node_t1] publishing cluster state version [6]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,471][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t3] received diff cluster state version [6] with uuid [7QvjTXCtQnSqNUdhWT0grQ], diff size [309]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,471][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] received diff cluster state version [6] with uuid [7QvjTXCtQnSqNUdhWT0grQ], diff size [309]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,472][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network] acked cluster state version [6]. processing ... (current pending [2], needed [2])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,472][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] master node {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network] acked cluster state version [6]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,472][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] committing version [6]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,472][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [7QvjTXCtQnSqNUdhWT0grQ], version [6]) to [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,472][TRACE][org.elasticsearch.discovery.zen.publish] [node_t1] sending commit for cluster state (uuid: [7QvjTXCtQnSqNUdhWT0grQ], version [6]) to [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: 7QvjTXCtQnSqNUdhWT0grQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], local%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][INFO ][org.elasticsearch.cluster.service] [node_t3] removed {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: 7QvjTXCtQnSqNUdhWT0grQ%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0A   {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network], master%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[7mM6N0_eQxyn28mYxCpKrw][V]%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]: took 0s done applying updated cluster_state (version: 6, uuid: 7QvjTXCtQnSqNUdhWT0grQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-receive(from master [master {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network] committed version [6]])]: took 0s done applying updated cluster_state (version: 6, uuid: 7QvjTXCtQnSqNUdhWT0grQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,473][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,474][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-node_left({node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network])]: took 3ms done applying updated cluster_state (version: 6, uuid: 7QvjTXCtQnSqNUdhWT0grQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][INFO ][org.elasticsearch.discovery.zen] [node_t2] master_left [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [shut_down]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][INFO ][org.elasticsearch.discovery.zen] [node_t3] master_left [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [shut_down]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] stopping fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [master left (reason = shut_down)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][TRACE][org.elasticsearch.cluster.service] [node_t3] will process [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0Aversion: 6%0Astate uuid: 7QvjTXCtQnSqNUdhWT0grQ%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[486], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[487], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_4_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,475][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = shut_down), current nodes: {{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network],{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t3] [master] stopping fault detection against master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], reason [master left (reason = shut_down)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,476][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.cluster.service] [node_t3] cluster state updated, source [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]%0Aversion: 6%0Astate uuid: 7QvjTXCtQnSqNUdhWT0grQ%0Afrom_diff: false%0Ameta data version: 1%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network], local%0A   {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[oczvfipLTr6a3WhOLDyYyg][V]%0A-----node_id[OFXtVNaKRe6VL9NvBc3e0g][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][INFO ][org.elasticsearch.cluster.service] [node_t3] removed {{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network],}, reason: zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][DEBUG][org.elasticsearch.cluster.service] [node_t3] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen] [node_t3] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 1ms done applying updated cluster_state (version: 6, uuid: 7QvjTXCtQnSqNUdhWT0grQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][DEBUG][org.elasticsearch.cluster.service] [node_t3] processing [zen-disco-master_failed ({node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network])]: took 1ms done applying updated cluster_state (version: 6, uuid: 7QvjTXCtQnSqNUdhWT0grQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0AConnectTransportException[[][127.0.0.1:30210] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30210];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30210%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_4_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to connect to {node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]%0ANodeDisconnectedException[[node_t1][127.0.0.1:30211][internal:discovery/zen/unicast] disconnected]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,477][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] replacing {node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network] with temp node {#zen_unicast_4_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_4_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0AConnectTransportException[[][127.0.0.1:30210] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30210];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30210%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] connecting (light) to {#zen_unicast_4_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] sending to {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[486], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[488], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[490], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[486], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[488], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[491], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30210}%0AConnectTransportException[[][127.0.0.1:30210] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30210];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30210%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]: [ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[476], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t0}{UdumSPqySZq2FCkBl6pKIw}{127.0.0.1}{127.0.0.1:30210}[mode=>network]], id[481], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t2}{OFXtVNaKRe6VL9NvBc3e0g}{127.0.0.1}{127.0.0.1:30212}[mode=>network]], id[486], master [{node_t1}{7mM6N0_eQxyn28mYxCpKrw}{127.0.0.1}{127.0.0.1:30211}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}, ping_response{node [{node_t3}{oczvfipLTr6a3WhOLDyYyg}{127.0.0.1}{127.0.0.1:30213}[mode=>network]], id[489], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[2111584377444976928]-HASH=[14406DE1E494B5C8]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,478][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t3] [2] failed to connect to {#zen_unicast_4_UdumSPqySZq2FCkBl6pKIw#}{127.0.0.1}{127.0.0.1:30210}[mode=>network]%0AConnectTransportException[[][127.0.0.1:30210] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30210];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30210%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,481][TRACE][org.elasticsearch.discovery.zen.ping] [node_t2] pingAndWait interrupted%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,481][TRACE][org.elasticsearch.discovery.zen] [node_t2] No full ping responses%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,481][TRACE][org.elasticsearch.discovery.zen] [node_t2] thread is no longer in currentJoinThread. Stopping.%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,485][TRACE][org.elasticsearch.discovery.zen.ping] [node_t3] pingAndWait interrupted%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,485][TRACE][org.elasticsearch.discovery.zen] [node_t3] No full ping responses%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,485][TRACE][org.elasticsearch.discovery.zen] [node_t3] thread is no longer in currentJoinThread. Stopping.%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIsolatedUnicastNodes(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287096232,
  "executionTime": 7255
 }
]

[
 "TEST_STARTED",
 "ID#testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,521][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t0] using minimum_master_nodes [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,521][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] using initial hosts [127.0.0.1:30214, 127.0.0.1:30215, 127.0.0.1:30216], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,521][DEBUG][org.elasticsearch.discovery.zen] [node_t0] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,521][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,521][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,535][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,535][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,535][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,535][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[493], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,535][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,536][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,536][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,536][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[494], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,536][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] failed to connect to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0AConnectTransportException[[][127.0.0.1:30216] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30216];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30216%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,536][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] failed to connect to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0AConnectTransportException[[][127.0.0.1:30215] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30215];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30215%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,560][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t1] using minimum_master_nodes [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,560][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] using initial hosts [127.0.0.1:30214, 127.0.0.1:30215, 127.0.0.1:30216], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,560][DEBUG][org.elasticsearch.discovery.zen] [node_t1] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,560][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,560][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,574][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,574][TRACE][org.elasticsearch.discovery.zen] [node_t1] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[496], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[497], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,575][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] failed to connect to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0AConnectTransportException[[][127.0.0.1:30216] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30216];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30216%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,577][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[498], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,606][DEBUG][org.elasticsearch.discovery.zen.elect] [node_t2] using minimum_master_nodes [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,606][DEBUG][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] using initial hosts [127.0.0.1:30214, 127.0.0.1:30215, 127.0.0.1:30216], with concurrent_connects [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,606][DEBUG][org.elasticsearch.discovery.zen] [node_t2] using ping_timeout [3s], join.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,606][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [master] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,606][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t2] [node  ] uses ping_interval [1s], ping_timeout [1s], ping_retries [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[500], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,616][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[501], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,617][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,617][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,617][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,617][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,618][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[503], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:43,618][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[502], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,038][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,038][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[505], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network] with temp node {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network] with temp node {#zen_unicast_5_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[506], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_5_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,039][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,040][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,040][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,040][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,040][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,040][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,040][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_5_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,041][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[508], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,052][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_5_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[507], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,053][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[509], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,053][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[510], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,080][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,080][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,080][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[512], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,081][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,081][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network] with temp node {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,081][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[513], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,081][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,081][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,081][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[514], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network] with temp node {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,082][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[515], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,083][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[516], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,083][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[517], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[519], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[522], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[521], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[520], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,123][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network] with temp node {#zen_unicast_4_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,124][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_4_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,124][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network] with temp node {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,124][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connecting (light) to {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,124][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,124][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] connected to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,125][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_4_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,125][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,125][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[524], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:45,125][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_4_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[523], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[526], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network] with temp node {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] replacing {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network] with temp node {#zen_unicast_7_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connecting (light) to {#zen_unicast_7_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,542][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[529], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[528], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[527], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_7_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] connected to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,543][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] sending to {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,544][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_7_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[530], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,544][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] received response from {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[531], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,544][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,544][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[531], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[530], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[531], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[530], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_5_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_7_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,545][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [1] disconnecting from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,546][TRACE][org.elasticsearch.discovery.zen] [node_t0] joining master {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[533], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network] with temp node {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[534], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,582][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,583][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[535], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,583][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,583][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[536], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,583][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,583][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] replacing {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network] with temp node {#zen_unicast_7_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,584][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connecting (light) to {#zen_unicast_7_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,584][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] connected to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,584][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[537], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,584][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] sending to {#zen_unicast_7_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,585][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] received response from {#zen_unicast_7_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[538], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,585][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_4_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,585][TRACE][org.elasticsearch.discovery.zen] [node_t1] full ping responses:%0A%09--> ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[537], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[538], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,585][DEBUG][org.elasticsearch.discovery.zen] [node_t1] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[537], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[538], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,585][TRACE][org.elasticsearch.discovery.zen] [node_t1] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,586][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_7_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,586][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_6_7W0K19VeQ3mWkmMayGn_-g#}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,586][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,586][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,587][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] [1] disconnecting from {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,587][TRACE][org.elasticsearch.discovery.zen] [node_t1] joining master {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,625][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,625][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,625][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,625][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[540], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,626][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,626][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[542], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,626][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[543], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,626][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[541], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,626][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,627][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,627][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[544], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,627][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[492], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[495], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[499], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[504], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[511], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[518], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[525], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[532], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[539], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[545], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][TRACE][org.elasticsearch.discovery.zen] [node_t2] full ping responses:%0A%09--> ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[544], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[545], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][DEBUG][org.elasticsearch.discovery.zen] [node_t2] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[544], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[545], master [null], hasJoinedOnce [false], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][DEBUG][org.elasticsearch.discovery.zen] [node_t2] elected as master, waiting for incoming joins ([1] needed)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_4_bsMpG1IsShyUTBhL24QIAA#}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,628][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [1] disconnecting from {#zen_unicast_5_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received full cluster state version [1] with size [323]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received full cluster state version [1] with size [323]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network] acked cluster state version [1]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [9BuJekOHTDyqo0shzWBGfQ], version [1]) to [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [9BuJekOHTDyqo0shzWBGfQ], version [1]) to [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,629][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] restarting fault detection against master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,630][DEBUG][org.elasticsearch.discovery.zen] [node_t1] got first state from fresh master [7W0K19VeQ3mWkmMayGn_-g]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,630][TRACE][org.elasticsearch.discovery.zen] [node_t1] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,630][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] restarting fault detection against master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,630][DEBUG][org.elasticsearch.discovery.zen] [node_t0] got first state from fresh master [7W0K19VeQ3mWkmMayGn_-g]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,630][TRACE][org.elasticsearch.discovery.zen] [node_t0] updated cluster join cluster to [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,632][TRACE][org.elasticsearch.discovery.zen] [node_t2] stopping join accumulation ([election closed])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,632][TRACE][org.elasticsearch.discovery.zen] [node_t2] cluster joins counter set to [1] (elected as master)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,632][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,633][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,633][TRACE][org.elasticsearch.action.admin.indices.stats] [node_t2] Error during transport action execution.%0AClusterBlockException[blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];]%0A%09at org.elasticsearch.cluster.block.ClusterBlocks.globalBlockedException(ClusterBlocks.java:157)%0A%09at org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction.checkGlobalBlock(TransportIndicesStatsAction.java:70)%0A%09at org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction.checkGlobalBlock(TransportIndicesStatsAction.java:47)%0A%09at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction$AsyncAction.<init>(TransportBroadcastByNodeAction.java:230)%0A%09at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction.doExecute(TransportBroadcastByNodeAction.java:210)%0A%09at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction.doExecute(TransportBroadcastByNodeAction.java:77)%0A%09at org.elasticsearch.action.support.TransportAction.doExecute(TransportAction.java:113)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:101)%0A%09at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:74)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.updateIndicesStats(InternalClusterInfoService.java:269)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:320)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:276)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService.lambda$onMaster$155(InternalClusterInfoService.java:135)%0A%09at org.elasticsearch.cluster.InternalClusterInfoService$$Lambda$771/606592313.run(Unknown Source)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,633][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t2] Serving cluster state request using version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,633][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received diff cluster state version [2] with uuid [gs77TZ_vSjesVc9AvE1v-Q], diff size [174]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,633][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [2] with uuid [gs77TZ_vSjesVc9AvE1v-Q], diff size [174]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,634][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network] acked cluster state version [2]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,634][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,634][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [gs77TZ_vSjesVc9AvE1v-Q], version [2]) to [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,634][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [gs77TZ_vSjesVc9AvE1v-Q], version [2]) to [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,634][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t2] failed to commit cluster state (uuid [gs77TZ_vSjesVc9AvE1v-Q], version [2]) to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0ASendRequestTransportException[[node_t0][127.0.0.1:30214][internal:discovery/zen/publish/commit]]; nested: ConnectTransportException[[node_t0][127.0.0.1:30214] DISCONNECT: simulated];%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:315)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.sendCommitToNode(PublishClusterStateAction.java:304)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.access$1200(PublishClusterStateAction.java:70)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.checkForCommitOrFailIfNoPending(PublishClusterStateAction.java:563)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.onNodeSendAck(PublishClusterStateAction.java:543)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$1.handleResponse(PublishClusterStateAction.java:278)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$1.handleResponse(PublishClusterStateAction.java:271)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.handleResponse(MessageChannelHandler.java:199)%0A%09at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:152)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)%0A%09at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)%0A%09at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)%0A%09at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)%0A%09at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)%0A%09at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: ConnectTransportException[[node_t0][127.0.0.1:30214] DISCONNECT: simulated]%0A%09at org.elasticsearch.test.transport.MockTransportService$1.sendRequest(MockTransportService.java:162)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.sendRequest(MockTransportService.java:423)%0A%09at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:304)%0A%09... 30 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,638][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,638][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: sampled state rejected by predicate (version [2], status [APPLIED]). adding listener to ClusterService%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:46,638][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: postAdded - predicate rejected state (version [2], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,630][TRACE][org.elasticsearch.discovery.zen.fd] [node_t2] [node  ] [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]] transport disconnected%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,631][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [3] with uuid [7BD9lZmPTMGjyIUv4Nzj8w], diff size [281]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,631][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network] acked cluster state version [3]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,631][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,631][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [7BD9lZmPTMGjyIUv4Nzj8w], version [3]) to [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,632][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,632][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] observer: accepting cluster state change (version [3], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,632][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,632][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t0] Serving cluster state request using version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,634][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t0] Serving cluster state request using version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,634][TRACE][org.elasticsearch.discovery.zen.fd] [node_t2] checking ping from [qTbdcgJeRh2Uy6bs6C1q4w] under a cluster state thread%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,636][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t0] Serving cluster state request using version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][TRACE][org.elasticsearch.discovery.zen.fd] [node_t0] [master] failed to ping [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], retry [1] out of [1]%0ARemoteTransportException[[node_t2][127.0.0.1:30216][internal:discovery/zen/fd/master_ping]]; nested: IllegalStateException;%0ACaused by: java.lang.IllegalStateException%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] failed to ping [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], tried [1] times, each with maximum [1s] timeout%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] stopping fault detection against master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [master failure, failed to ping, tried [1] times, each with  maximum [1s] timeout]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][INFO ][org.elasticsearch.discovery.zen] [node_t0] master_left [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [failed to ping, tried [1] times, each with  maximum [1s] timeout]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network],{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][TRACE][org.elasticsearch.discovery.zen] [node_t0] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,637][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[547], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] connecting (light) to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[548], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[549], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,638][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[550], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] connected to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[551], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,649][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t0] Serving cluster state request using version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,649][DEBUG][org.elasticsearch.action.admin.cluster.health] [node_t0] no known master node, scheduling a retry%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,649][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t0] observer: sampled state rejected by predicate (version [1], status [APPLIED]). adding listener to ClusterService%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:47,649][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t0] observer: postAdded - predicate rejected state (version [1], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,143][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,143][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[553], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,143][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,143][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,143][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,143][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,144][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[554], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,144][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[555], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,144][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[557], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:49,144][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[556], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,644][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,644][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[559], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] sending to {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[560], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[562], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[563], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,645][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] received response from {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[561], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,646][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] [2] disconnecting from {#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30216}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,646][TRACE][org.elasticsearch.discovery.zen] [node_t0] full ping responses:%0A%09--> ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[562], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[563], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,646][DEBUG][org.elasticsearch.discovery.zen] [node_t0] filtered ping responses: (filter_client[true], filter_data[false])%0A%09--> ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[562], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A%09--> ping_response{node [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]], id[563], master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,646][TRACE][org.elasticsearch.discovery.zen] [node_t0] adding local node to the list of active nodes who has previously joined the cluster (joins counter is [1})%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,646][TRACE][org.elasticsearch.discovery.zen] [node_t0] stopping join accumulation ([not master])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,647][TRACE][org.elasticsearch.discovery.zen] [node_t0] joining master {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,650][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t0] received full cluster state version [4] with size [285]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,650][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [4] with uuid [u0GNR0NyR9WDh_jLBD0zhQ], diff size [307]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,650][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network] acked cluster state version [4]. processing ... (current pending [2], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,650][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,651][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [u0GNR0NyR9WDh_jLBD0zhQ], version [4]) to [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,651][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [u0GNR0NyR9WDh_jLBD0zhQ], version [4]) to [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,651][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] restarting fault detection against master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [new cluster state received and we are monitoring the wrong master [null]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,651][DEBUG][org.elasticsearch.discovery.zen] [node_t0] got first state from fresh master [7W0K19VeQ3mWkmMayGn_-g]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,651][TRACE][org.elasticsearch.discovery.zen] [node_t0] updated cluster join cluster to [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,652][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t0] observer: accepting cluster state change (version [4], status [APPLIED])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,653][TRACE][org.elasticsearch.action.admin.indices.stats] [node_t2] resolving shards for [indices:monitor/stats] based on cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,653][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,653][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,654][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,654][TRACE][org.elasticsearch.action.admin.cluster.health] [node_t2] Calculating health based on state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,654][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t2] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,663][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t0] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,664][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t1] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,664][TRACE][org.elasticsearch.action.admin.cluster.state] [node_t2] Serving cluster state request using version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,665][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t0] [master] stopping fault detection against master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [zen disco stop]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,666][DEBUG][org.elasticsearch.discovery.zen.publish] [node_t1] received diff cluster state version [5] with uuid [KFYo6zIrRTyzFugvipP5HA], diff size [282]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,667][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] master node {node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network] acked cluster state version [5]. processing ... (current pending [1], needed [1])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,667][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] committing version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,667][TRACE][org.elasticsearch.discovery.zen.publish] [node_t2] sending commit for cluster state (uuid: [KFYo6zIrRTyzFugvipP5HA], version [5]) to [{node_t1}{bsMpG1IsShyUTBhL24QIAA}{127.0.0.1}{127.0.0.1:30215}[mode=>network]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,669][DEBUG][org.elasticsearch.discovery.zen.fd] [node_t1] [master] stopping fault detection against master [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], reason [zen disco stop]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to accumulate joins%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen] [node_t2] starting to ping%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[564], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[565], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,670][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] sending to {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,671][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] received response from {node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]: [ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[546], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[552], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network]], id[558], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[564], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[564], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}, ping_response{node [{node_t2}{7W0K19VeQ3mWkmMayGn_-g}{127.0.0.1}{127.0.0.1:30216}[mode=>network]], id[566], master [null], hasJoinedOnce [true], cluster_name[TEST-CHILD_VM=[1]-CLUSTER_SEED=[-679292691564915143]-HASH=[14406DE394EC7950]-cluster]}]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,671][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] replacing {node_t0}{qTbdcgJeRh2Uy6bs6C1q4w}{127.0.0.1}{127.0.0.1:30214}[mode=>network] with temp node {#zen_unicast_6_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,671][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] connecting (light) to {#zen_unicast_6_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,671][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30214}%0AConnectTransportException[[][127.0.0.1:30214] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30214];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30214%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,671][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_2#}{127.0.0.1}{127.0.0.1:30215}%0AConnectTransportException[[][127.0.0.1:30215] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30215];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30215%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,671][TRACE][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] [2] failed to connect to {#zen_unicast_6_qTbdcgJeRh2Uy6bs6C1q4w#}{127.0.0.1}{127.0.0.1:30214}[mode=>network]%0AConnectTransportException[[][127.0.0.1:30214] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:30214];%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:954)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:918)%0A%09at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:890)%0A%09at org.elasticsearch.test.transport.MockTransportService$LookupTestTransport.connectToNodeLight(MockTransportService.java:413)%0A%09at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:242)%0A%09at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$3.run(UnicastZenPing.java:395)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0ACaused by: java.net.ConnectException: Connection refused: /127.0.0.1:30214%0A%09at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)%0A%09at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:712)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)%0A%09at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)%0A%09at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)%0A%09at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)%0A%09at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)%0A%09... 3 more%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,673][TRACE][org.elasticsearch.discovery.zen.ping] [node_t2] pingAndWait interrupted%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,673][TRACE][org.elasticsearch.discovery.zen] [node_t2] No full ping responses%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:50,673][TRACE][org.elasticsearch.discovery.zen] [node_t2] thread is no longer in currentJoinThread. Stopping.%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNodeNotReachableFromMaster(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287103487,
  "executionTime": 7189
 }
]

[
 "TEST_STARTED",
 "ID#testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:54,806][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t2}{J-fXXvtWTpSZ3JZ4IHn8yA}{127.0.0.1}{127.0.0.1:30219}[mode=>network],{node_t1}{z7lbRzr1TP6HqMWy_IPP2g}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:57,822][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{J-fXXvtWTpSZ3JZ4IHn8yA}{127.0.0.1}{127.0.0.1:30219}[mode=>network],{node_t1}{z7lbRzr1TP6HqMWy_IPP2g}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:31:57,822][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t2}{J-fXXvtWTpSZ3JZ4IHn8yA}{127.0.0.1}{127.0.0.1:30219}[mode=>network],{node_t1}{z7lbRzr1TP6HqMWy_IPP2g}{127.0.0.1}{127.0.0.1:30218}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testFailWithMinimumMasterNodesConfigured(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287110676,
  "executionTime": 7155
 }
]

[
 "TEST_STARTED",
 "ID#testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:02,941][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network],{node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:02,993][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network],{node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:03,948][WARN ][org.elasticsearch.cluster.service] [node_t1] failing [zen-disco-node_failed({node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:03,949][ERROR][org.elasticsearch.discovery.zen] [node_t1] unexpected failure during [zen-disco-node_failed({node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:04,950][WARN ][org.elasticsearch.cluster.service] [node_t1] failing [zen-disco-node_failed({node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]: failed to commit cluster state version [8]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:04,950][ERROR][org.elasticsearch.discovery.zen] [node_t1] unexpected failure during [zen-disco-node_failed({node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]%0AFailedToCommitClusterStateException[timed out while waiting for enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:04,951][WARN ][org.elasticsearch.discovery.zen] [node_t1] failed to publish to min_master_nodes, current nodes: {{node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network],{node_t1}{FU1XbroGSSuY4WFBZrO0TQ}{127.0.0.1}{127.0.0.1:30221}[mode=>network],{node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:04,951][ERROR][org.elasticsearch.discovery.zen] [node_t1] unexpected failure during [zen-disco-failed-to-publish]%0Aorg.elasticsearch.cluster.NotMasterException: no longer master. source: [zen-disco-failed-to-publish]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:08,705][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network]]%0AReceiveTimeoutTransportException[[node_t0][127.0.0.1:30220][internal:discovery/zen/unicast] request_id [62] timed out after [3754ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:08,705][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network]]%0AReceiveTimeoutTransportException[[node_t2][127.0.0.1:30222][internal:discovery/zen/unicast] request_id [61] timed out after [3754ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:08,705][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30220}]%0AReceiveTimeoutTransportException[[node_t0][127.0.0.1:30220][internal:discovery/zen/unicast] request_id [57] timed out after [3754ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:08,705][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30222}]%0AReceiveTimeoutTransportException[[node_t2][127.0.0.1:30222][internal:discovery/zen/unicast] request_id [59] timed out after [3754ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:08,970][WARN ][org.elasticsearch.discovery.zen.publish] [node_t2] timed out waiting for all nodes to process published state [11] (timeout [1s], pending nodes: [{node_t1}{FU1XbroGSSuY4WFBZrO0TQ}{127.0.0.1}{127.0.0.1:30221}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:09,968][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{wTodaoNZTgWKHYXSUnnIYg}{127.0.0.1}{127.0.0.1:30220}[mode=>network],{node_t1}{FU1XbroGSSuY4WFBZrO0TQ}{127.0.0.1}{127.0.0.1:30221}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:13,010][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{XBHpx8flSI-R3JHeRcTX2w}{127.0.0.1}{127.0.0.1:30222}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testVerifyApiBlocksDuringPartition(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287117831,
  "executionTime": 15185
 }
]

[
 "TEST_STARTED",
 "ID#testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:17,131][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = transport disconnected), current nodes: {{node_t0}{XP69uFDDSUifyfWJYZAnqw}{127.0.0.1}{127.0.0.1:30223}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testClusterJoinDespiteOfPublishingIssues(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287133017,
  "executionTime": 10142
 }
]

[
 "TEST_STARTED",
 "ID#testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:28,218][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t0}{7IJxWLCwRUSJDaBkNNQIig}{127.0.0.1}{127.0.0.1:30225}[mode=>network],{node_t2}{zZWVW4-NSgShjF0VDFw_Bg}{127.0.0.1}{127.0.0.1:30227}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:31,241][WARN ][org.elasticsearch.cluster.action.shard] [node_t1] [test][2] received shard failed for [test][2], node[7IJxWLCwRUSJDaBkNNQIig], [R], v[3], s[STARTED], a[id=0mIC4c4zTjGxHimTQm_i-Q], indexUUID [D_PKZTa-QSuGDDANg1Sy8A], message [simulated], failure [CorruptIndexException[simulated (resource=null)]]%0Aorg.apache.lucene.index.CorruptIndexException: simulated (resource=null)%0A%09at org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT.testSendingShardFailure(DiscoveryWithServiceDisruptionsIT.java:917)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)%0A%09at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816)%0A%09at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827)%0A%09at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54)%0A%09at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)%0A%09at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65)%0A%09at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)%0A%09at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)%0A%09at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:31,278][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{#zen_unicast_3#}{127.0.0.1}{127.0.0.1:30227}]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:31,278][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t0] failed to send ping to [{node_t2}{zZWVW4-NSgShjF0VDFw_Bg}{127.0.0.1}{127.0.0.1:30227}[mode=>network]]%0ATransportException[transport stopped, action: internal:discovery/zen/unicast]%0A%09at org.elasticsearch.transport.TransportService$2.run(TransportService.java:190)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:31,280][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = shut_down), current nodes: {{node_t2}{zZWVW4-NSgShjF0VDFw_Bg}{127.0.0.1}{127.0.0.1:30227}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSendingShardFailure(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287143159,
  "executionTime": 8126
 }
]

[
 "TEST_STARTED",
 "ID#testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,547][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = transport disconnected), current nodes: {{node_t1}{DUAtENE-S4yHTIb7q13Q3w}{127.0.0.1}{127.0.0.1:30229}[master=>false, mode=>network],{node_t2}{R6lXLSIVT5iP2nBObYa7Hg}{127.0.0.1}{127.0.0.1:30230}[master=>false, mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,547][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{DUAtENE-S4yHTIb7q13Q3w}{127.0.0.1}{127.0.0.1:30229}[master=>false, mode=>network],{node_t2}{R6lXLSIVT5iP2nBObYa7Hg}{127.0.0.1}{127.0.0.1:30230}[master=>false, mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSearchWithRelocationAndSlowClusterStateProcessing(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287151285,
  "executionTime": 6270
 }
]

[
 "TEST_STARTED",
 "ID#testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,581][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,581][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,581][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,608][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,608][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,609][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,628][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [initial_join]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,628][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:37,629][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [initial_join]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,640][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-join(elected_as_master, [2] joins received)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,640][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-join(elected_as_master, [2] joins received)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,640][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-join(elected_as_master, [2] joins received)]%0Aversion: 1%0Astate uuid: M3BSJu6QRXOzaHXYMmyZlQ%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,640][INFO ][org.elasticsearch.cluster.service] [node_t2] new_master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network],}, reason: zen-disco-join(elected_as_master, [2] joins received)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,640][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [1]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,641][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,641][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,641][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,641][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,642][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: M3BSJu6QRXOzaHXYMmyZlQ%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,642][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]%0Aversion: 1%0Astate uuid: M3BSJu6QRXOzaHXYMmyZlQ%0Afrom_diff: false%0Ameta data version: 0%0Ablocks: %0A   _global_:%0A      1,state not recovered / initialized, blocks READ,WRITE,METADATA_READ,METADATA_WRITE%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 0):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,642][INFO ][org.elasticsearch.cluster.service] [node_t0] detected_master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network],{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,642][INFO ][org.elasticsearch.cluster.service] [node_t1] detected_master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network],{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: took 2ms done applying updated cluster_state (version: 1, uuid: M3BSJu6QRXOzaHXYMmyZlQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [1]])]: took 2ms done applying updated cluster_state (version: 1, uuid: M3BSJu6QRXOzaHXYMmyZlQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 1%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-join(elected_as_master, [2] joins received)]: took 3ms done applying updated cluster_state (version: 1, uuid: M3BSJu6QRXOzaHXYMmyZlQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [gateway_initial_state_recovery]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [gateway_initial_state_recovery]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,644][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [local-gateway-elected-state]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [local-gateway-elected-state]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [local-gateway-elected-state]%0Aversion: 2%0Astate uuid: 0vkqPvQBRUubu_WL2Kfkzg%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [2]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,645][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: 0vkqPvQBRUubu_WL2Kfkzg%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,646][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,646][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]%0Aversion: 2%0Astate uuid: 0vkqPvQBRUubu_WL2Kfkzg%0Afrom_diff: false%0Ameta data version: 1%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 1):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,646][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,647][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: took 1ms done applying updated cluster_state (version: 2, uuid: 0vkqPvQBRUubu_WL2Kfkzg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,647][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [2]])]: took 1ms done applying updated cluster_state (version: 2, uuid: 0vkqPvQBRUubu_WL2Kfkzg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,647][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 2%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,647][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [local-gateway-elected-state]: took 2ms done applying updated cluster_state (version: 2, uuid: 0vkqPvQBRUubu_WL2Kfkzg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,647][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [create-index [test], cause [api]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,647][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [create-index [test], cause [api]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,648][TRACE][org.elasticsearch.cluster.service] expecting 3 acknowledgements for cluster_state update (version: 3)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,648][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [create-index [test], cause [api]]%0Aversion: 3%0Astate uuid: KtcvDQ4_QpOShLE9ayifEQ%0Afrom_diff: false%0Ameta data version: 2%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 2):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,648][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [3]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: KtcvDQ4_QpOShLE9ayifEQ%0Afrom_diff: false%0Ameta data version: 2%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 2):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]%0Aversion: 3%0Astate uuid: KtcvDQ4_QpOShLE9ayifEQ%0Afrom_diff: false%0Ameta data version: 2%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 2):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[null], [R], v[1], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,650][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,649][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,651][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: took 2ms done applying updated cluster_state (version: 3, uuid: KtcvDQ4_QpOShLE9ayifEQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,651][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]], cluster_state update (version: 3)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,651][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [3]])]: took 2ms done applying updated cluster_state (version: 3, uuid: KtcvDQ4_QpOShLE9ayifEQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,651][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]], cluster_state update (version: 3)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,651][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 3%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,654][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], cluster_state update (version: 3)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,654][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 3)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,654][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [create-index [test], cause [api]]: took 6ms done applying updated cluster_state (version: 3, uuid: KtcvDQ4_QpOShLE9ayifEQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,655][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,655][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,655][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,656][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [shard-started ([test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery from store]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery from store]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,656][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [shard-started ([test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery from store]]%0Aversion: 4%0Astate uuid: H09RsiRXR_Gq51M_1oUKag%0Afrom_diff: false%0Ameta data version: 3%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 3):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[2], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[2], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [4]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: H09RsiRXR_Gq51M_1oUKag%0Afrom_diff: false%0Ameta data version: 3%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 3):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[2], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[2], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,657][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]%0Aversion: 4%0Astate uuid: H09RsiRXR_Gq51M_1oUKag%0Afrom_diff: false%0Ameta data version: 3%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 3):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[2], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[2], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,658][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,660][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]: took 3ms done applying updated cluster_state (version: 4, uuid: H09RsiRXR_Gq51M_1oUKag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,660][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [4]])]: took 3ms done applying updated cluster_state (version: 4, uuid: H09RsiRXR_Gq51M_1oUKag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,661][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 4%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,662][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[1], s[INITIALIZING], a[id=2jrC3AGWRM2UAyPrxL-RFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery from store]]: took 6ms done applying updated cluster_state (version: 4, uuid: H09RsiRXR_Gq51M_1oUKag)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,696][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,696][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,697][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]%0Aversion: 5%0Astate uuid: RtZaGEL3T5OOo6BGIkwiYQ%0Afrom_diff: false%0Ameta data version: 4%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 4):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[3], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[3], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[3], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[3], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,697][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [5]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: RtZaGEL3T5OOo6BGIkwiYQ%0Afrom_diff: false%0Ameta data version: 4%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 4):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[3], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[3], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[3], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[3], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]%0Aversion: 5%0Astate uuid: RtZaGEL3T5OOo6BGIkwiYQ%0Afrom_diff: false%0Ameta data version: 4%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 4):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[3], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[3], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[3], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[3], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,698][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,700][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]: took 2ms done applying updated cluster_state (version: 5, uuid: RtZaGEL3T5OOo6BGIkwiYQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,701][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [5]])]: took 3ms done applying updated cluster_state (version: 5, uuid: RtZaGEL3T5OOo6BGIkwiYQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,701][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 5%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,703][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[2], s[INITIALIZING], a[id=KMGyHr2ZRfOlOuHb9WiGDQ], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]: took 6ms done applying updated cluster_state (version: 5, uuid: RtZaGEL3T5OOo6BGIkwiYQ)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,703][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,703][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,703][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]],shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,703][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]],shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]%0Aversion: 6%0Astate uuid: DlRw5l1nQwacpBU7hBkbNw%0Afrom_diff: false%0Ameta data version: 5%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [6]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: DlRw5l1nQwacpBU7hBkbNw%0Afrom_diff: false%0Ameta data version: 5%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]%0Aversion: 6%0Astate uuid: DlRw5l1nQwacpBU7hBkbNw%0Afrom_diff: false%0Ameta data version: 5%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,704][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,707][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]: took 2ms done applying updated cluster_state (version: 6, uuid: DlRw5l1nQwacpBU7hBkbNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,707][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [6]])]: took 2ms done applying updated cluster_state (version: 6, uuid: DlRw5l1nQwacpBU7hBkbNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,707][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,709][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[2], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]],shard-started ([test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[3], s[INITIALIZING], a[id=EBU2X1UMQbW2myGSwMCqFw], unassigned_info[[reason=INDEX_CREATED], at[2016-03-29T21:32:40.648Z]]), reason [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]: took 5ms done applying updated cluster_state (version: 6, uuid: DlRw5l1nQwacpBU7hBkbNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,709][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,709][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:40,709][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,644][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-master_failed ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,644][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-master_failed ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,645][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,645][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-master_failed ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0Aversion: 6%0Astate uuid: DlRw5l1nQwacpBU7hBkbNw%0Afrom_diff: false%0Ameta data version: 5%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 5):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][X]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[4], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[4], s[STARTED], a[id=KMGyHr2ZRfOlOuHb9WiGDQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[4], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,645][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-master_failed ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,645][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 6%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,646][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-master_failed ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 1ms done applying updated cluster_state (version: 6, uuid: DlRw5l1nQwacpBU7hBkbNw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,646][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-node_failed({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,646][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-node_failed({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,647][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-node_failed({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]%0Aversion: 7%0Astate uuid: nmoxPBbKQl2Bh6bz_9t2xw%0Afrom_diff: false%0Ameta data version: 6%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,647][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],}, reason: zen-disco-node_failed({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,647][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [7]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,648][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [7]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,648][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [7]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,648][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [7]])]%0Aversion: 7%0Astate uuid: nmoxPBbKQl2Bh6bz_9t2xw%0Afrom_diff: false%0Ameta data version: 6%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,648][INFO ][org.elasticsearch.cluster.service] [node_t0] removed {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [7]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,648][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 7%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,651][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [7]])]: took 3ms done applying updated cluster_state (version: 7, uuid: nmoxPBbKQl2Bh6bz_9t2xw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,651][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 7%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,654][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-node_failed({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]), reason failed to ping, tried [1] times, each with maximum [1s] timeout]: took 7ms done applying updated cluster_state (version: 7, uuid: nmoxPBbKQl2Bh6bz_9t2xw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,655][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [put-mapping [type]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,655][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [put-mapping [type]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,655][TRACE][org.elasticsearch.cluster.service] expecting 2 acknowledgements for cluster_state update (version: 8)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,655][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [put-mapping [type]]%0Aversion: 8%0Astate uuid: DfHFilLpTUic0tO9P7vg9Q%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,655][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [8]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,656][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [8]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,656][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [8]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,656][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [8]])]%0Aversion: 8%0Astate uuid: DfHFilLpTUic0tO9P7vg9Q%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,656][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 8%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,658][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [8]])]: took 1ms done applying updated cluster_state (version: 8, uuid: DfHFilLpTUic0tO9P7vg9Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,658][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]], cluster_state update (version: 8)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,658][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 8%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,659][TRACE][org.elasticsearch.cluster.service] ack received from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]], cluster_state update (version: 8)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,659][TRACE][org.elasticsearch.cluster.service] all expected nodes acknowledged cluster_state update (version: 8)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,659][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [put-mapping [type]]: took 4ms done applying updated cluster_state (version: 8, uuid: DfHFilLpTUic0tO9P7vg9Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,662][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,662][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:42,662][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,651][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-join(join from node[{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,651][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-join(join from node[{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,651][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-join(join from node[{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]])]%0Aversion: 9%0Astate uuid: PZKb0-KUSGKB22xyLmQ2Vw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,651][INFO ][org.elasticsearch.cluster.service] [node_t2] added {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],}, reason: zen-disco-join(join from node[{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,651][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [9]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,652][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,652][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,652][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]%0Aversion: 9%0Astate uuid: PZKb0-KUSGKB22xyLmQ2Vw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,652][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,652][INFO ][org.elasticsearch.cluster.service] [node_t0] added {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,652][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,653][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]%0Aversion: 9%0Astate uuid: PZKb0-KUSGKB22xyLmQ2Vw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 6):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[5], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[5], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A--------[test][0], node[null], [R], v[5], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]]%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,653][INFO ][org.elasticsearch.cluster.service] [node_t1] detected_master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], added {{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,653][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 9%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,654][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 9%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,654][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]: took 2ms done applying updated cluster_state (version: 9, uuid: PZKb0-KUSGKB22xyLmQ2Vw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,655][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [9]])]: took 2ms done applying updated cluster_state (version: 9, uuid: PZKb0-KUSGKB22xyLmQ2Vw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,655][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 9%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-join(join from node[{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]])]: took 4ms done applying updated cluster_state (version: 9, uuid: PZKb0-KUSGKB22xyLmQ2Vw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_reroute(post_node_add)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_reroute(post_node_add)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [finalize_join ({node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_reroute(post_node_add)]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_health (wait_for_events [LANGUID])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,656][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_health (wait_for_events [LANGUID])]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,657][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [cluster_reroute(async_shard_fetch)]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,657][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_reroute(async_shard_fetch)]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [cluster_reroute(async_shard_fetch)]%0Aversion: 10%0Astate uuid: y3937JVuTJG7aDAxJCtERw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 7):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[6], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[6], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[6], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[6], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [10]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,658][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]%0Aversion: 10%0Astate uuid: y3937JVuTJG7aDAxJCtERw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 7):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[6], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[6], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[6], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[6], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,659][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 10%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,659][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]%0Aversion: 10%0Astate uuid: y3937JVuTJG7aDAxJCtERw%0Afrom_diff: false%0Ameta data version: 7%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 7):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[6], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[6], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[6], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[6], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,659][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 10%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,660][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]: took 1ms done applying updated cluster_state (version: 10, uuid: y3937JVuTJG7aDAxJCtERw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,661][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [10]])]: took 2ms done applying updated cluster_state (version: 10, uuid: y3937JVuTJG7aDAxJCtERw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,661][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 10%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,662][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [cluster_reroute(async_shard_fetch)]: took 4ms done applying updated cluster_state (version: 10, uuid: y3937JVuTJG7aDAxJCtERw)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,676][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,676][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,677][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]%0Aversion: 11%0Astate uuid: DpAM1h0vRt2ZZJE0Q2o9eg%0Afrom_diff: false%0Ameta data version: 8%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 8):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[7], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[7], s[STARTED], a[id=B9wHPM1wSBKO0DadZ_nSFQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[7], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[7], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[7], s[STARTED], a[id=B9wHPM1wSBKO0DadZ_nSFQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[7], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,677][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [11]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,677][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,677][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,677][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,677][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,678][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]%0Aversion: 11%0Astate uuid: DpAM1h0vRt2ZZJE0Q2o9eg%0Afrom_diff: false%0Ameta data version: 8%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 8):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[7], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[7], s[STARTED], a[id=B9wHPM1wSBKO0DadZ_nSFQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[7], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[7], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[7], s[STARTED], a[id=B9wHPM1wSBKO0DadZ_nSFQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[7], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,678][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 11%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,678][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]%0Aversion: 11%0Astate uuid: DpAM1h0vRt2ZZJE0Q2o9eg%0Afrom_diff: false%0Ameta data version: 8%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 8):%0A-- index [test]%0A----shard_id [test][0]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[7], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[7], s[STARTED], a[id=B9wHPM1wSBKO0DadZ_nSFQ]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[7], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A--------[test][0], node[DI3rNxqOQJ6kN5NVd00lUg], [P], v[7], s[STARTED], a[id=2jrC3AGWRM2UAyPrxL-RFw]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A--------[test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[7], s[STARTED], a[id=B9wHPM1wSBKO0DadZ_nSFQ]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A--------[test][0], node[iXpKQXiYTIS7h8XdSLn8aQ], [R], v[7], s[STARTED], a[id=EBU2X1UMQbW2myGSwMCqFw]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,678][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 11%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,680][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]: took 2ms done applying updated cluster_state (version: 11, uuid: DpAM1h0vRt2ZZJE0Q2o9eg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,681][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [11]])]: took 3ms done applying updated cluster_state (version: 11, uuid: DpAM1h0vRt2ZZJE0Q2o9eg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,681][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 11%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,683][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [shard-started ([test][0], node[jG1mjILaTQmnObJNOoAMbQ], [R], v[6], s[INITIALIZING], a[id=B9wHPM1wSBKO0DadZ_nSFQ], unassigned_info[[reason=NODE_LEFT], at[2016-03-29T21:32:42.646Z], details[node_left[jG1mjILaTQmnObJNOoAMbQ]]], expected_shard_size[3046]), reason [after recovery (replica) from node [{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network]]]]: took 6ms done applying updated cluster_state (version: 11, uuid: DpAM1h0vRt2ZZJE0Q2o9eg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,687][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [delete-index [test]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,687][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [delete-index [test]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,687][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [delete-index [test]]%0Aversion: 12%0Astate uuid: vvhmpix-TVCp1lW1ZH8h5Q%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,687][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [12]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][TRACE][org.elasticsearch.cluster.service] [node_t0] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][TRACE][org.elasticsearch.cluster.service] [node_t0] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]%0Aversion: 12%0Astate uuid: vvhmpix-TVCp1lW1ZH8h5Q%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network], local%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]%0Aversion: 12%0Astate uuid: vvhmpix-TVCp1lW1ZH8h5Q%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0A   {node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network]%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A-----node_id[iXpKQXiYTIS7h8XdSLn8aQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][DEBUG][org.elasticsearch.cluster.service] [node_t0] set local cluster state to version 12%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,688][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 12%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,691][DEBUG][org.elasticsearch.cluster.service] [node_t0] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]: took 3ms done applying updated cluster_state (version: 12, uuid: vvhmpix-TVCp1lW1ZH8h5Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,692][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [12]])]: took 4ms done applying updated cluster_state (version: 12, uuid: vvhmpix-TVCp1lW1ZH8h5Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,692][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 12%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [delete-index [test]]: took 7ms done applying updated cluster_state (version: 12, uuid: vvhmpix-TVCp1lW1ZH8h5Q)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [delete_repository [*]]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [delete_repository [*]]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [delete_repository [*]]: took 0s no change in cluster_state%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-node_left({node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-node_left({node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,695][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-node_left({node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network])]%0Aversion: 13%0Astate uuid: 5FySkZvqS0OFi4t3uW6lgg%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local, master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network]%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,696][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network],}, reason: zen-disco-node_left({node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,696][DEBUG][org.elasticsearch.cluster.service] [node_t2] publishing cluster state version [13]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][TRACE][org.elasticsearch.cluster.service] [node_t1] will process [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [13]])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [13]])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][TRACE][org.elasticsearch.cluster.service] [node_t1] cluster state updated, source [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [13]])]%0Aversion: 13%0Astate uuid: 5FySkZvqS0OFi4t3uW6lgg%0Afrom_diff: false%0Ameta data version: 9%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], master%0A   {node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network], local%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A-----node_id[jG1mjILaTQmnObJNOoAMbQ][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][INFO ][org.elasticsearch.cluster.service] [node_t1] removed {{node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network],}, reason: zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [13]])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][DEBUG][org.elasticsearch.cluster.service] [node_t1] set local cluster state to version 13%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][DEBUG][org.elasticsearch.cluster.service] [node_t1] processing [zen-disco-receive(from master [master {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network] committed version [13]])]: took 0s done applying updated cluster_state (version: 13, uuid: 5FySkZvqS0OFi4t3uW6lgg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,697][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 13%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,698][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-node_left({node_t0}{iXpKQXiYTIS7h8XdSLn8aQ}{127.0.0.1}{127.0.0.1:30231}[mode=>network])]: took 2ms done applying updated cluster_state (version: 13, uuid: 5FySkZvqS0OFi4t3uW6lgg)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,699][TRACE][org.elasticsearch.cluster.service] [node_t2] will process [zen-disco-node_left({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network])]%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,699][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-node_left({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network])]: execute%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,699][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,699][TRACE][org.elasticsearch.cluster.service] [node_t2] cluster state updated, source [zen-disco-node_left({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network])]%0Aversion: 13%0Astate uuid: 5FySkZvqS0OFi4t3uW6lgg%0Afrom_diff: false%0Ameta data version: 9%0Ablocks: %0A   _global_:%0A      2,no master, blocks WRITE,METADATA_WRITE%0Anodes: %0A   {node_t2}{DI3rNxqOQJ6kN5NVd00lUg}{127.0.0.1}{127.0.0.1:30233}[mode=>network], local%0Arouting_table (version 9):%0Arouting_nodes:%0A-----node_id[DI3rNxqOQJ6kN5NVd00lUg][V]%0A---- unassigned%0A%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,699][INFO ][org.elasticsearch.cluster.service] [node_t2] removed {{node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network],}, reason: zen-disco-node_left({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,699][DEBUG][org.elasticsearch.cluster.service] [node_t2] set local cluster state to version 13%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:45,700][DEBUG][org.elasticsearch.cluster.service] [node_t2] processing [zen-disco-node_left({node_t1}{jG1mjILaTQmnObJNOoAMbQ}{127.0.0.1}{127.0.0.1:30232}[mode=>network])]: took 0s done applying updated cluster_state (version: 13, uuid: 5FySkZvqS0OFi4t3uW6lgg)%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testRejoinDocumentExistsInAllShardCopies(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287157555,
  "executionTime": 8149
 }
]

[
 "TEST_STARTED",
 "ID#testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:51,834][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{G4q_YzDQSPmfGlYuQpvWzA}{127.0.0.1}{127.0.0.1:30235}[master=>false, mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:32:54,942][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = transport disconnected), current nodes: {{node_t1}{G4q_YzDQSPmfGlYuQpvWzA}{127.0.0.1}{127.0.0.1:30235}[master=>false, mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testIndexImportedFromDataOnlyNodesIfMasterLostDataFolder(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287165704,
  "executionTime": 9241
 }
]

[
 "TEST_STARTED",
 "ID#testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:00,034][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t1}{QCob6uQXQmSsMAP4_f6ynA}{127.0.0.1}{127.0.0.1:30237}[mode=>network],{node_t2}{7a3u8EttTDmPlHcusdHpkA}{127.0.0.1}{127.0.0.1:30238}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:00,106][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t1}{QCob6uQXQmSsMAP4_f6ynA}{127.0.0.1}{127.0.0.1:30237}[mode=>network],{node_t2}{7a3u8EttTDmPlHcusdHpkA}{127.0.0.1}{127.0.0.1:30238}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:03,790][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30236}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30236][internal:discovery/zen/unicast] request_id [22] timed out after [3755ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:03,862][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30236}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30236][internal:discovery/zen/unicast] request_id [24] timed out after [3755ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:05,258][WARN ][org.elasticsearch.discovery.zen.publish] [node_t2] received a cluster state from a different master than the current one, rejecting (received {node_t0}{2pAxv25zQ6Kj-6wnxlxRPg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], current {node_t2}{7a3u8EttTDmPlHcusdHpkA}{127.0.0.1}{127.0.0.1:30238}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:05,259][WARN ][org.elasticsearch.discovery.zen.publish] [node_t1] received a cluster state from a different master than the current one, rejecting (received {node_t0}{2pAxv25zQ6Kj-6wnxlxRPg}{127.0.0.1}{127.0.0.1:30236}[mode=>network], current {node_t2}{7a3u8EttTDmPlHcusdHpkA}{127.0.0.1}{127.0.0.1:30238}[mode=>network])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:05,260][WARN ][org.elasticsearch.cluster.service] [node_t0] failing [sneaky-update]: failed to commit cluster state version [4]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:05,260][WARN ][org.elasticsearch.discovery] failure [sneaky-update]%0AFailedToCommitClusterStateException[failed to get enough masters to ack sent cluster state. [1] left]%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction$SendingController.waitForCommit(PublishClusterStateAction.java:525)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.innerPublish(PublishClusterStateAction.java:189)%0A%09at org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.publish(PublishClusterStateAction.java:154)%0A%09at org.elasticsearch.discovery.zen.ZenDiscovery.publish(ZenDiscovery.java:345)%0A%09at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)%0A%09at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)%0A%09at java.lang.reflect.Method.invoke(Method.java:483)%0A%09at org.elasticsearch.common.inject.internal.ConstructionContext$DelegatingInvocationHandler.invoke(ConstructionContext.java:111)%0A%09at com.sun.proxy.$Proxy35.publish(Unknown Source)%0A%09at org.elasticsearch.discovery.DiscoveryService.publish(DiscoveryService.java:130)%0A%09at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:574)%0A%09at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:761)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)%0A%09at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:05,260][WARN ][org.elasticsearch.discovery.zen] [node_t0] failed to publish to min_master_nodes, current nodes: {{node_t1}{QCob6uQXQmSsMAP4_f6ynA}{127.0.0.1}{127.0.0.1:30237}[mode=>network],{node_t2}{7a3u8EttTDmPlHcusdHpkA}{127.0.0.1}{127.0.0.1:30238}[mode=>network],{node_t0}{2pAxv25zQ6Kj-6wnxlxRPg}{127.0.0.1}{127.0.0.1:30236}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:08,346][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{7a3u8EttTDmPlHcusdHpkA}{127.0.0.1}{127.0.0.1:30238}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testStaleMasterNotHijackingMajority(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287174945,
  "executionTime": 13505
 }
]

[
 "TEST_STARTED",
 "ID#testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:13,519][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t2}{TE4CDgC2Q7S0R9lYmbKVGg}{127.0.0.1}{127.0.0.1:30241}[mode=>network],{node_t1}{xbkweRqlQr2bT030hcjfuQ}{127.0.0.1}{127.0.0.1:30240}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:13,548][WARN ][org.elasticsearch.discovery.zen] [node_t2] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t2}{TE4CDgC2Q7S0R9lYmbKVGg}{127.0.0.1}{127.0.0.1:30241}[mode=>network],{node_t1}{xbkweRqlQr2bT030hcjfuQ}{127.0.0.1}{127.0.0.1:30240}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:17,275][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t1] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30239}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30239][internal:discovery/zen/unicast] request_id [21] timed out after [3755ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:17,309][WARN ][org.elasticsearch.discovery.zen.ping.unicast] [node_t2] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:30239}]%0AReceiveTimeoutTransportException[[][127.0.0.1:30239][internal:discovery/zen/unicast] request_id [23] timed out after [3758ms]]%0A%09at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:626)%0A%09at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)%0A%09at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)%0A%09at java.lang.Thread.run(Thread.java:745)%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:20,086][WARN ][org.elasticsearch.discovery.zen] [node_t2] discovered [{node_t0}{BhUmwsZ0QH2HUuBz0g16uw}{127.0.0.1}{127.0.0.1:30239}[mode=>network]] which is also master but with an older cluster_state, telling [{node_t0}{BhUmwsZ0QH2HUuBz0g16uw}{127.0.0.1}{127.0.0.1:30239}[mode=>network]] to rejoin the cluster ([node fd ping])%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:20,090][WARN ][org.elasticsearch.discovery.zen] [node_t0] received a request to rejoin the cluster from [TE4CDgC2Q7S0R9lYmbKVGg], current nodes: {{node_t2}{TE4CDgC2Q7S0R9lYmbKVGg}{127.0.0.1}{127.0.0.1:30241}[mode=>network],{node_t0}{BhUmwsZ0QH2HUuBz0g16uw}{127.0.0.1}{127.0.0.1:30239}[mode=>network],{node_t1}{xbkweRqlQr2bT030hcjfuQ}{127.0.0.1}{127.0.0.1:30240}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:23,107][WARN ][org.elasticsearch.discovery.zen] [node_t2] not enough master nodes, current nodes: {{node_t2}{TE4CDgC2Q7S0R9lYmbKVGg}{127.0.0.1}{127.0.0.1:30241}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMasterNodeGCs(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287188451,
  "executionTime": 14661
 }
]

[
 "TEST_STARTED",
 "ID#testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)"
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:26,231][WARN ][org.elasticsearch.discovery.zen] [node_t0] master left (reason = shut_down), current nodes: {{node_t1}{nXE-bpDEQKuDQNwu5Fs8IQ}{127.0.0.1}{127.0.0.1:30243}[mode=>network],{node_t3}{Pmf9ekCmSI-8mohtOCVOlg}{127.0.0.1}{127.0.0.1:30245}[mode=>network],{node_t0}{vBfGKf5-QRmXd0WmP2Y4-Q}{127.0.0.1}{127.0.0.1:30242}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:26,231][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = shut_down), current nodes: {{node_t1}{nXE-bpDEQKuDQNwu5Fs8IQ}{127.0.0.1}{127.0.0.1:30243}[mode=>network],{node_t3}{Pmf9ekCmSI-8mohtOCVOlg}{127.0.0.1}{127.0.0.1:30245}[mode=>network],{node_t0}{vBfGKf5-QRmXd0WmP2Y4-Q}{127.0.0.1}{127.0.0.1:30242}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:26,231][WARN ][org.elasticsearch.discovery.zen] [node_t3] master left (reason = shut_down), current nodes: {{node_t1}{nXE-bpDEQKuDQNwu5Fs8IQ}{127.0.0.1}{127.0.0.1:30243}[mode=>network],{node_t3}{Pmf9ekCmSI-8mohtOCVOlg}{127.0.0.1}{127.0.0.1:30245}[mode=>network],{node_t0}{vBfGKf5-QRmXd0WmP2Y4-Q}{127.0.0.1}{127.0.0.1:30242}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:31,251][WARN ][org.elasticsearch.discovery.zen] [node_t1] master left (reason = failed to ping, tried [1] times, each with  maximum [1s] timeout), current nodes: {{node_t1}{nXE-bpDEQKuDQNwu5Fs8IQ}{127.0.0.1}{127.0.0.1:30243}[mode=>network],{node_t0}{vBfGKf5-QRmXd0WmP2Y4-Q}{127.0.0.1}{127.0.0.1:30242}[mode=>network],}%0A"
 }
]

[
 "APPEND_STDOUT",
 {
  "chunk": "[2016-03-29 17:33:34,282][WARN ][org.elasticsearch.discovery.zen] [node_t3] not enough master nodes, current nodes: {{node_t3}{Pmf9ekCmSI-8mohtOCVOlg}{127.0.0.1}{127.0.0.1:30245}[mode=>network],}%0A"
 }
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testNodesFDAfterMasterReelection(org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT)",
  "startTimestamp": 1459287203112,
  "executionTime": 11173
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.discovery.DiscoveryWithServiceDisruptionsIT",
  "startTimestamp": 1459287068668,
  "executionTime": 145667
 }
]

[
 "SUITE_STARTED",
 {
  "description": {
   "id": "ID#org.elasticsearch.update.UpdateNoopIT",
   "displayName": "org.elasticsearch.update.UpdateNoopIT",
   "methodName": null,
   "className": "org.elasticsearch.update.UpdateNoopIT",
   "children": [
    {
     "id": "ID#testArrayField(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testArrayField(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testArrayField",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testTotallyEmpty",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testSingleField(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testSingleField(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testSingleField",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testMapAndField(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testMapAndField(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testMapAndField",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testMap(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testMap(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testMap",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    },
    {
     "id": "ID#testTwoFields(org.elasticsearch.update.UpdateNoopIT)",
     "displayName": "testTwoFields(org.elasticsearch.update.UpdateNoopIT)",
     "methodName": "testTwoFields",
     "className": "org.elasticsearch.update.UpdateNoopIT",
     "children": []
    }
   ]
  },
  "startTimestamp": 1459287214340
 }
]

[
 "TEST_STARTED",
 "ID#testArrayField(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testArrayField(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1459287214349,
  "executionTime": 182
 }
]

[
 "TEST_STARTED",
 "ID#testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTotallyEmpty(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1459287214531,
  "executionTime": 141
 }
]

[
 "TEST_STARTED",
 "ID#testSingleField(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testSingleField(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1459287214672,
  "executionTime": 114
 }
]

[
 "TEST_STARTED",
 "ID#testMapAndField(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMapAndField(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1459287214786,
  "executionTime": 74
 }
]

[
 "TEST_STARTED",
 "ID#testMap(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testMap(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1459287214860,
  "executionTime": 153
 }
]

[
 "TEST_STARTED",
 "ID#testTwoFields(org.elasticsearch.update.UpdateNoopIT)"
]

[
 "TEST_FINISHED",
 {
  "description": "ID#testTwoFields(org.elasticsearch.update.UpdateNoopIT)",
  "startTimestamp": 1459287215013,
  "executionTime": 49
 }
]

[
 "SUITE_COMPLETED",
 {
  "description": "ID#org.elasticsearch.update.UpdateNoopIT",
  "startTimestamp": 1459287214340,
  "executionTime": 732
 }
]

[
 "IDLE",
 {}
]

[
 "QUIT",
 {}
]

